{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-14T14:15:23.759183Z",
     "start_time": "2018-11-14T14:15:22.715861Z"
    },
    "autopy": 2
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adryw/miniconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/adryw/miniconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Model, load_model, clone_model\n",
    "from keras.utils import multi_gpu_model\n",
    "from keras.layers import *\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.regularizers import l2\n",
    "from keras.losses import binary_crossentropy\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import random\n",
    "sys.path.append('src')  # Fix for jupyter\n",
    "import src.emulator as emulator\n",
    "import src.emulator_utils as emulator_utils\n",
    "import src.emulator_vis as emulator_vis\n",
    "%matplotlib inline\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "import multiprocessing\n",
    "from multiprocessing import Event, Queue, Pipe\n",
    "from multiprocessing import Process as Thread\n",
    "import os\n",
    "import logging\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autopy": 0
   },
   "source": [
    "# Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-14T14:15:23.763665Z",
     "start_time": "2018-11-14T14:15:23.760939Z"
    },
    "autopy": 0
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(filename='logging.log', level=logging.INFO, format='%(asctime)s %(message)s', filemode='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autopy": 0
   },
   "source": [
    "# Model Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-14T14:15:23.783480Z",
     "start_time": "2018-11-14T14:15:23.780168Z"
    },
    "autopy": 0
   },
   "outputs": [],
   "source": [
    "INPUT_SIZE = (16, 16, 4) # Map size fixed to 16x16 (2 to 3 players)\n",
    "N_ACTIONS = 4\n",
    "gpus = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autopy": 0
   },
   "source": [
    "# Define the Layers Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-14T14:15:24.909231Z",
     "start_time": "2018-11-14T14:15:24.845672Z"
    },
    "autopy": 0
   },
   "outputs": [],
   "source": [
    "filters = 64\n",
    "\n",
    "# Convolutional Block\n",
    "def conv_block(in_layer, name, filters=filters, kernel_size=(3,3), bn=True, relu=True):\n",
    "    l = Conv2D(filters, kernel_size, padding='same', name = name, kernel_regularizer=l2(1e-4),\n",
    "              kernel_initializer='random_uniform')(in_layer)\n",
    "    if bn:\n",
    "        l = BatchNormalization(name = name + '_bn')(l)\n",
    "    if relu:\n",
    "        l = Activation('relu', name = name + '_relu')(l)\n",
    "    return l\n",
    "\n",
    "# Residual Block\n",
    "def residual_conv(in_layer, idx, filters=filters, kernel_size=(3,3), bn=True, relu=True):\n",
    "    name = 'res_' + str(idx)\n",
    "    # Full conv block of pre-defined shape\n",
    "    l = conv_block(in_layer, name + '_conv1', filters, kernel_size=(3,3), bn=True, relu=True)\n",
    "    # Second block with skip connection\n",
    "    l = Conv2D(filters, kernel_size, padding='same', name = name + '_conv2', kernel_regularizer=l2(1e-4),\n",
    "              kernel_initializer='random_uniform')(l)\n",
    "    if bn:\n",
    "        l = BatchNormalization(name = name + '_conv2_bn')(l)\n",
    "    l = Concatenate()([in_layer, l]) # Skip conn.\n",
    "    if relu:\n",
    "        l = Activation('relu', name = name + '_relu')(l)\n",
    "    return l\n",
    "\n",
    "def value_head(in_layer):\n",
    "    l = conv_block(in_layer, 'value_head', filters=1, kernel_size=(1,1))\n",
    "    l = Flatten(name = 'value_flatten')(l)\n",
    "    l = Dense(64, name = 'value_dense', kernel_regularizer=l2(1e-4),\n",
    "             kernel_initializer='random_uniform')(l)\n",
    "    l = Activation('relu', name = 'value_relu')(l)\n",
    "    l = Dense(1, name = 'value', activation='tanh')(l) # Value output\n",
    "    return l\n",
    "\n",
    "def policy_head(in_layer):\n",
    "    l = conv_block(in_layer, 'policy_head', filters=2, kernel_size=(1,1))\n",
    "    l = Flatten(name = 'policy_flatten')(l)\n",
    "    l = Dense(N_ACTIONS, name = 'policy')(l) # Policy output\n",
    "    return l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autopy": 0
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-14T14:15:25.842886Z",
     "start_time": "2018-11-14T14:15:25.838438Z"
    },
    "autopy": 0
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    def declare_model():\n",
    "        n_residual = 12\n",
    "\n",
    "        input_layer = Input(INPUT_SIZE)\n",
    "        l = conv_block(input_layer, 'conv')\n",
    "        for i in range(n_residual):\n",
    "            l = residual_conv(l, idx=i + 1)\n",
    "\n",
    "        policy = policy_head(l)\n",
    "        value = value_head(l)\n",
    "\n",
    "        alphabot = Model(input_layer, [policy, value])\n",
    "        return alphabot\n",
    "    \n",
    "    if gpus > 1:\n",
    "        with tf.device('/cpu:0'):\n",
    "            alphabot = declare_model()\n",
    "        alphabot_multi = multi_gpu_model(alphabot, gpus=gpus)\n",
    "        return alphabot_multi, alphabot\n",
    "    \n",
    "    alphabot = declare_model()\n",
    "    return alphabot, alphabot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-14T14:15:26.994505Z",
     "start_time": "2018-11-14T14:15:26.991014Z"
    },
    "autopy": 0
   },
   "outputs": [],
   "source": [
    "def softmax(z):\n",
    "    assert len(z.shape) == 2\n",
    "    s = np.max(z, axis=1)\n",
    "    s = s[:, np.newaxis] # necessary step to do broadcasting\n",
    "    e_x = np.exp(z - s)\n",
    "    div = np.sum(e_x, axis=1)\n",
    "    div = div[:, np.newaxis]\n",
    "    return e_x / div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-11-14T14:24:41.028Z"
    },
    "autopy": 0
   },
   "outputs": [],
   "source": [
    "alphabot_training, alphabot = create_model()\n",
    "alphabot_training.compile(optimizer=SGD(1e-4, momentum=0.6), \n",
    "                          loss={'value' : 'mse', 'policy' : 'mse'},\n",
    "                          loss_weights={'value' : 0.6, 'policy' : 1.0})\n",
    "alphabot.summary(line_length=112)\n",
    "\n",
    "alphabot_best, _ = create_model()\n",
    "alphabot_best.set_weights(alphabot.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-14T14:15:34.122323Z",
     "start_time": "2018-11-14T14:15:34.119174Z"
    },
    "autopy": 0
   },
   "outputs": [],
   "source": [
    "# History of games for training\n",
    "complete_history = []\n",
    "\n",
    "# Game Params\n",
    "n_players = 2\n",
    "n_games = 10_000 # Simulate N games before each training\n",
    "k = 10 # Games to be stored n_games * K\n",
    "\n",
    "# Simulation Params\n",
    "num_threads = 30\n",
    "\n",
    "# Training Params\n",
    "t_steps = 1000 * 2 # Steps of training\n",
    "eval_steps = 250 # How many steps before evaluation\n",
    "eval_games = 350 # How many games to play to evaluate how's best model\n",
    "win_percent = 0.55 # Ratio of game won to become best model\n",
    "BATCH_SIZE = 300\n",
    "total_improv = 0\n",
    "pretrain_steps = 1_000\n",
    "pretrain_games = 30_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-14T14:24:38.261907Z",
     "start_time": "2018-11-14T14:18:46.362180Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process MemTimer-2:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/adryw/miniconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/adryw/miniconda3/lib/python3.6/site-packages/memory_profiler.py\", line 233, in run\n",
      "    stop = self.pipe.poll(self.interval)\n",
      "  File \"/home/adryw/miniconda3/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/adryw/miniconda3/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/adryw/miniconda3/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/adryw/miniconda3/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-338d30e794c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'memit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pre_train()'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2283\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2284\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2285\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2286\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-126>\u001b[0m in \u001b[0;36mmemit\u001b[0;34m(self, line, cell)\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/memory_profiler.py\u001b[0m in \u001b[0;36mmemit\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m   1015\u001b[0m                                \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m                                \u001b[0mmax_usage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1017\u001b[0;31m                                include_children=include_children)\n\u001b[0m\u001b[1;32m   1018\u001b[0m             \u001b[0mmem_usage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/memory_profiler.py\u001b[0m in \u001b[0;36mmemory_usage\u001b[0;34m(proc, interval, timeout, timestamps, include_children, multiprocess, max_usage, retval, stream, backend)\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0;31m# Therefore, the whole process hangs indefinitely. Here, we are ensuring that the process gets killed!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m                 \u001b[0mreturned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m                 \u001b[0mparent_conn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# finish timing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m                 \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparent_conn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/memory_profiler.py\u001b[0m in \u001b[0;36m_func_exec\u001b[0;34m(stmt, ns)\u001b[0m\n\u001b[1;32m    788\u001b[0m     \u001b[0;31m# helper for magic_memit, just a function proxy for the exec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m     \u001b[0;31m# statement\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 790\u001b[0;31m     \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstmt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    791\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<string>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-4c8d20481b07>\u001b[0m in \u001b[0;36mpre_train\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0msum_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrain_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0msum_losses\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Pretrain losses: %s'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msum_losses\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-f2643e0b23b6>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions_taken\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malphabot_training\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%memit pre_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-14T14:18:41.187531Z",
     "start_time": "2018-11-14T14:18:41.175227Z"
    },
    "autopy": 1
   },
   "outputs": [],
   "source": [
    "def pre_train():\n",
    "    logging.info('Starting pretraining')\n",
    "    for i in range(pretrain_games):\n",
    "        if i % n_games == 0 and i > 0:\n",
    "            logging.info('Simulated %s pretrain-games', n_games)\n",
    "            \n",
    "        games_buffer = [GameRecorder() for player in range(n_players)] # Create a place to store games\n",
    "        game = emulator.Game(n_players) # TODO: Wrap the following lines in a function\n",
    "        gmap = game.map # Access map manually on first step\n",
    "        gmap_old = None # First frame has no older map\n",
    "        p_alive = game.players_alive # Players alive\n",
    "        n_alive = game.count_alive()\n",
    "\n",
    "        def take_action_brain(game):\n",
    "            actions = []\n",
    "            for idx, s in enumerate(game.players_alive):\n",
    "                player_idx = idx\n",
    "                p_x, p_y = game.history[player_idx][-1]\n",
    "                empty = -1\n",
    "                size = INPUT_SIZE[0]\n",
    "                liberties = np.array([0, 0, 0, 0]) # Right, Down, Left, Up\n",
    "                liberties[0] = int(game.map[p_x % size, (p_y + 1) % size] == empty)\n",
    "                liberties[1] = int(game.map[(p_x + 1) % size, p_y % size] == empty)\n",
    "                liberties[2] = int(game.map[p_x % size, (p_y - 1) % size] == empty)\n",
    "                liberties[3] = int(game.map[(p_x - 1) % size, p_y % size] == empty)\n",
    "                if liberties.any() == 0:\n",
    "                    actions.append(np.random.randint(0, len(liberties)))\n",
    "                else:\n",
    "                    while True:\n",
    "                        x = np.random.randint(0, len(liberties))\n",
    "                        if np.random.random() < 0.35: # A small chance of getting the action without even trying\n",
    "                            actions.append(x)\n",
    "                            break\n",
    "                        if liberties[x] == 1:\n",
    "                            actions.append(x)\n",
    "                            break\n",
    "            return actions\n",
    "                \n",
    "        while True:\n",
    "            state = map_to_state(gmap, gmap_old, p_alive) # State for each player alive\n",
    "            chosen_action = take_action_brain(game)\n",
    "            \n",
    "            gmap_old = copy.copy(gmap)\n",
    "            gmap, p_alive_new, n_alive, reward, game_end = game.step(chosen_action)\n",
    "        \n",
    "            idx_alive = 0\n",
    "            for alive in p_alive: # Players which were alive at the start of the step\n",
    "                if alive == 0: # Player is dead, skip it\n",
    "                    continue\n",
    "                \n",
    "                games_buffer[idx_alive].store(state[idx_alive], reward[idx_alive], chosen_action[idx_alive])\n",
    "                idx_alive += 1\n",
    "            p_alive = copy.copy(p_alive_new)\n",
    "            \n",
    "            if game_end:\n",
    "                logging.debug('Game ended, rewards %s', reward)\n",
    "                break\n",
    "        \n",
    "        for g in games_buffer:\n",
    "            if len(g.actions_taken) == 0:\n",
    "                logging.debug('WHAT A 0 STEPS GAME')\n",
    "                continue\n",
    "\n",
    "            complete_history.append(g)\n",
    "    \n",
    "    sum_losses = 0\n",
    "    for i in range(pretrain_steps):\n",
    "        sum_losses += train_model()[0]\n",
    "        if i % 100 == 0 and i > 0:\n",
    "            logging.info('Pretrain step %s losses: %s', i, sum_losses / (i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-14T14:15:46.826220Z",
     "start_time": "2018-11-14T14:15:46.820122Z"
    },
    "autopy": 0
   },
   "outputs": [],
   "source": [
    "def simulate_games():\n",
    "    logging.debug('Starting Threads for parallel Games')\n",
    "    \n",
    "    parallel_sim() # Parallel Games\n",
    "    while not history_buffer.full():\n",
    "        indices, states = [], []\n",
    "        if processable_buffer.qsize() < (num_threads-1) * 2: # Wait until a bunch of requests are queued\n",
    "            continue\n",
    "\n",
    "        for i in range(processable_buffer.qsize()):\n",
    "            index, state = processable_buffer.get()\n",
    "            indices.append(index)\n",
    "            states.append(state)\n",
    "            \n",
    "        predictions = alphabot.predict(np.array(states, dtype=np.float64))\n",
    "        for i, pred in enumerate(tuple(zip(predictions[0], predictions[1]))):\n",
    "            pipes[indices[i]].send(dict(zip(alphabot.output_names, pred)))\n",
    "        # We have to predict until buffer is full\n",
    "    logging.info('Finished Simulating %s games', n_games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-14T14:15:46.414252Z",
     "start_time": "2018-11-14T14:15:46.405825Z"
    },
    "autopy": 0
   },
   "outputs": [],
   "source": [
    "def play_eval(log_game=False):\n",
    "    game = emulator.Game(n_players) # TODO: Wrap the following lines in a function\n",
    "    gmap = game.map # Access map manually on first step\n",
    "\n",
    "    gmap_old = None # First frame has no older map\n",
    "    p_alive = game.players_alive # Players alive\n",
    "    n_alive = game.count_alive()\n",
    "    \n",
    "    maps = [] # Initialise buffer for log\n",
    "    maps.append(copy.copy(gmap))\n",
    "    \n",
    "    while True:\n",
    "        assert n_alive == 2, 'Multi player eval is not implemented yet'\n",
    "        state = map_to_state(gmap, gmap_old, p_alive) # State for each player alive\n",
    "        \n",
    "        # The predictions from the candidate and the best bot\n",
    "        p0 = alphabot.predict(state[0][np.newaxis])\n",
    "        p1 = alphabot_best.predict(state[1][np.newaxis])\n",
    "        \n",
    "        # Split in value and policy\n",
    "        candidate_policy = p0[0]\n",
    "        candidate_value = p0[1]\n",
    "        best_policy = p1[0]\n",
    "        best_value = p1[1]\n",
    "        \n",
    "        logging.debug('Candidate Policy: %s Candidate Value: %s', candidate_policy, candidate_value)\n",
    "        logging.debug('Best Bot Policy: %s Best Bot Value: %s', best_policy, best_value)\n",
    "        \n",
    "        policy = [candidate_policy[0], best_policy[0]]\n",
    "        policy = softmax(np.array(policy)) # We softmax the policy logits\n",
    "        chosen_action = np.argmax(policy, axis=-1)\n",
    "        \n",
    "        gmap_old = copy.copy(gmap)\n",
    "        gmap, p_alive, n_alive, reward, game_end = game.step(chosen_action)\n",
    "        maps.append(copy.copy(gmap))\n",
    "        \n",
    "        if game_end:\n",
    "            winner = np.where(np.array(p_alive) == 1)[0][0]\n",
    "            if log_game:\n",
    "                return maps\n",
    "\n",
    "            return winner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-14T14:15:45.240738Z",
     "start_time": "2018-11-14T14:15:45.232081Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_model():\n",
    "        # Get a BATCH_SIZE of games\n",
    "        picked_data = random.sample(complete_history, k=min(BATCH_SIZE, len(complete_history)))\n",
    "        # Get a State from each game selected\n",
    "        x = np.empty((len(picked_data), 16, 16, 4), dtype=np.float64)\n",
    "        actions_taken = []\n",
    "        rewards = []\n",
    "        for j, game in enumerate(picked_data):\n",
    "            index = np.random.randint(0, len(game.actions_taken)) # Get game length and generate index\n",
    "            x[j] = np.array(game.states[index], dtype=np.float64)\n",
    "            actions_taken.append(game.actions_taken[index])    \n",
    "            rewards.append(np.array(game.rewards[-1], dtype=np.float64))\n",
    "            \n",
    "        #rewards = np.array(rewards)\n",
    "        actions_taken = np.array(actions_taken)\n",
    "        y = alphabot_training.predict(x)\n",
    "        for idx, action in enumerate(actions_taken):\n",
    "            y[0][idx, actions_taken[idx]] = rewards[idx]\n",
    "            y[1][idx, 0] = rewards[idx]    \n",
    "        losses = alphabot_training.train_on_batch(x, y)\n",
    "        return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-14T14:15:44.778527Z",
     "start_time": "2018-11-14T14:15:44.770092Z"
    },
    "autopy": 0
   },
   "outputs": [],
   "source": [
    "def training_cycle(): \n",
    "    global alphabot\n",
    "    global alphabot_best\n",
    "    global total_improv\n",
    "    \n",
    "    # Simulate n_games (exception made by first interaction)\n",
    "    logging.info('Starting Training Cycle')\n",
    "    while len(complete_history) < k * n_games:\n",
    "        simulate_games()\n",
    "        # history_buffer contains the games, we store them inside complete history    \n",
    "        for g in range(history_buffer.qsize()):\n",
    "            complete_history.append(history_buffer.get())\n",
    "        stop_simulation() # We can now stop the simulation (will free the memory)\n",
    "    logging.debug('Complete history should be full, it contains %s elements', len(complete_history))\n",
    "    # Now we are ready for the training process\n",
    "    logging.info('Starting Model Training')\n",
    "    losses = [None, None, None] # For debug purpose\n",
    "    sum_loss = 0\n",
    "    cc = 1\n",
    "    for i in range(t_steps + 1):\n",
    "        if i % 100 == 0:\n",
    "            logging.info('Training Interaction: %s losses: %s', i, \n",
    "                         round(sum_loss / cc, 2)) # Works?\n",
    "\n",
    "        losses = train_model()\n",
    "        sum_loss += losses[0]\n",
    "        logging.debug('Losses: %s', losses)\n",
    "        \n",
    "        improved = False\n",
    "        evalued_step = False\n",
    "        cc += 1\n",
    "        if i % eval_steps == 0 and i > 0:\n",
    "            evalued_step = True\n",
    "            cc = 1 # Reset loss counter\n",
    "            sum_loss = 0\n",
    "            wins = {'candidate' : 0, 'best' : 0}\n",
    "            n_c = {0 : 'candidate', 1 : 'best'}\n",
    "            \n",
    "            logging.info('Starting self-play evaluation')    \n",
    "            for j in range(eval_games):\n",
    "                # 0 is Candidate, 1 is the (soon to be old) best\n",
    "                wins[n_c[play_eval()]] += 1 # add a win to the winner\n",
    "                if j % 100 == 0:\n",
    "                    logging.info('Win state Candidate: %s Best: %s', wins['candidate'], wins['best'])\n",
    "            win_ratio = wins['candidate'] / eval_games\n",
    "            if win_ratio > win_percent:\n",
    "                logging.info('Great! Our candidate won %s percent of games', round(win_ratio * 100, 2))\n",
    "                total_improv += 1\n",
    "                logging.info('Our bot got better %s times', total_improv)\n",
    "                improved = True\n",
    "                alphabot_best.set_weights(alphabot.get_weights())\n",
    "            else:\n",
    "                logging.info('Damn! Our candidate only won %s percent of games', round(win_ratio * 100, 2))\n",
    "        if not improved and evalued_step:\n",
    "            logging.info('Not improved, cloning to best')\n",
    "            alphabot.set_weights(alphabot_best.get_weights())\n",
    "    del complete_history[:n_games] # Delete n oldest games from history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-14T14:15:34.629049Z",
     "start_time": "2018-11-14T14:15:34.622888Z"
    },
    "autopy": 0
   },
   "outputs": [],
   "source": [
    "def load_best(best_model):\n",
    "    global alphabot\n",
    "    global alphabot_best\n",
    "    alphabot_best = load_model(best_model)\n",
    "    alphabot.set_weights(alphabot_best.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-14T14:15:42.985205Z",
     "start_time": "2018-11-14T14:15:42.981974Z"
    },
    "autopy": 0
   },
   "outputs": [],
   "source": [
    "def train(cycles, best_model = None):\n",
    "    global alphabot_best\n",
    "    global alphabot\n",
    "    \n",
    "    if best_model != None:\n",
    "        alphabot_best = load_model(best_model)\n",
    "        alphabot.set_weights(alphabot_best.get_weights())\n",
    "    else:\n",
    "        alphabot_best.set_weights(alphabot.get_weights())\n",
    "\n",
    "    for i in range(cycles):\n",
    "        training_cycle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "autopy": 0,
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to open file (unable to open file: name = '/data/rw/cp_bot/best_first_run.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-9f07ffde99c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mload_best\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/data/rw/cp_bot/best_first_run.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-64f925175ef6>\u001b[0m in \u001b[0;36mload_best\u001b[0;34m(best_model)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0malphabot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0malphabot_best\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0malphabot_best\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0malphabot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malphabot_best\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    415\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m     \u001b[0mopened_new_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deserialize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/keras/utils/io_utils.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, mode)\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, **kwds)\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mphil\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Unable to open file (unable to open file: name = '/data/rw/cp_bot/best_first_run.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "load_best('/data/rw/cp_bot/best_first_run.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-13T22:25:17.962058Z",
     "start_time": "2018-11-13T22:22:31.142982Z"
    },
    "autopy": 0
   },
   "outputs": [],
   "source": [
    "#complete_history = []\n",
    "cycles = 1000\n",
    "\n",
    "train(cycles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-14T14:15:39.441141Z",
     "start_time": "2018-11-14T14:15:39.432082Z"
    },
    "autopy": 0
   },
   "outputs": [],
   "source": [
    "def map_to_state(gmap, gmap_old, p_alive):\n",
    "    if type(gmap_old) != np.ndarray:\n",
    "        gmap_old = np.full_like(gmap, -1)\n",
    "    \n",
    "    n_alive = sum(p_alive == 1)\n",
    "    states = np.empty((n_alive, *INPUT_SIZE), dtype=np.int)\n",
    "    \n",
    "    idx_alive = 0\n",
    "    for idx, alive in enumerate(p_alive):\n",
    "        if alive == 0: # Skip dead player\n",
    "            continue\n",
    "            \n",
    "        # Player is alive, we collect its state\n",
    "        states[idx_alive] = process_map(idx, gmap, gmap_old)\n",
    "        idx_alive += 1\n",
    "        \n",
    "    return states\n",
    "\n",
    "def process_map(idx, gmap, gmap_old):\n",
    "    pov_me = np.zeros((*INPUT_SIZE[:2], 1), dtype=np.int)\n",
    "    pov_me_last = np.zeros((*INPUT_SIZE[:2], 1), dtype=np.int)\n",
    "    pov_not_me = np.zeros((*INPUT_SIZE[:2], 1), dtype=np.int)\n",
    "    pov_not_me_last = np.zeros((*INPUT_SIZE[:2], 1), dtype=np.int)\n",
    "    \n",
    "    pov_me[np.where(gmap == idx)] = 1 # Set to 1 where bot is\n",
    "    pov_me_last[np.where(gmap_old == idx)] = 1\n",
    "    \n",
    "    pov_not_me[np.where(~np.isin(gmap, [idx, -1]))] = 1 # Set to 1 where bot is not\n",
    "    pov_not_me_last[np.where(~np.isin(gmap_old, [idx, -1]))] = 1\n",
    "    \n",
    "    return np.concatenate([pov_me, pov_me_last, pov_not_me, pov_not_me_last], axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-14T14:15:39.837874Z",
     "start_time": "2018-11-14T14:15:39.832894Z"
    },
    "autopy": 0
   },
   "outputs": [],
   "source": [
    "class GameRecorder():\n",
    "    def __init__(self):\n",
    "        self.states = []\n",
    "        self.rewards = []\n",
    "        self.actions_taken = []\n",
    "        \n",
    "    def store(self, state, reward, action_taken):\n",
    "        self.states.append(state)\n",
    "        self.rewards.append(reward)\n",
    "        self.actions_taken.append(action_taken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-14T14:15:40.282705Z",
     "start_time": "2018-11-14T14:15:40.267235Z"
    },
    "autopy": 0
   },
   "outputs": [],
   "source": [
    "def ask_predict(id, x):\n",
    "    # Adds to queue id and data from process\n",
    "    [processable_buffer.put((id, xi)) for xi in x]\n",
    "\n",
    "def sim(process_id, pipe):    \n",
    "    while True:\n",
    "        games_buffer = [GameRecorder() for player in range(n_players)] # Create a place to store games\n",
    "        \n",
    "        # Simulate the game, if a prediction is needed use ask_predict\n",
    "        game = emulator.Game(n_players) # TODO: Wrap the following lines in a function\n",
    "        gmap = game.map # Access map manually on first step\n",
    "        gmap_old = None # First frame has no older map\n",
    "        p_alive = game.players_alive # Players alive\n",
    "        n_alive = game.count_alive()\n",
    "\n",
    "        while True:\n",
    "            state = map_to_state(gmap, gmap_old, p_alive) # State for each player alive\n",
    "            ask_predict(process_id, state)\n",
    "            policy, value = [], []\n",
    "            for i in range(n_alive):\n",
    "                raw_prediction = pipe.recv() # Receive actions from main\n",
    "                policy.append(raw_prediction['policy'])\n",
    "                value.append(raw_prediction['value'])\n",
    "            \n",
    "            policy = softmax(np.array(policy)) # We softmax the policy logits\n",
    "            #chosen_action = [np.random.choice(N_ACTIONS, p=act) for act in policy]\n",
    "            chosen_action = np.argmax(policy, axis=-1)\n",
    "            logging.debug('Choosen Actions %s Raw Actions %s', chosen_action, policy)\n",
    "            \n",
    "            gmap_old = copy.copy(gmap)\n",
    "            gmap, p_alive_new, n_alive, reward, game_end = game.step(chosen_action)\n",
    "        \n",
    "            idx_alive = 0\n",
    "            for alive in p_alive: # Players which were alive at the start of the step\n",
    "                if alive == 0: # Player is dead, skip it\n",
    "                    continue\n",
    "                \n",
    "                games_buffer[idx_alive].store(state[idx_alive], reward[idx_alive], chosen_action[idx_alive])\n",
    "                idx_alive += 1\n",
    "            p_alive = copy.copy(p_alive_new)\n",
    "            \n",
    "            if game_end:\n",
    "                logging.debug('Game ended, rewards %s', reward)\n",
    "                break\n",
    "        try:\n",
    "            for g in games_buffer:\n",
    "                # I didn't find a bug yet that makes some games be of 0 steps, gonna skip them for now\n",
    "                if len(g.actions_taken) == 0:\n",
    "                    logging.debug('WHAT A 0 STEPS GAME')\n",
    "                    continue\n",
    "                    \n",
    "                history_buffer.put_nowait(g)\n",
    "        except:\n",
    "            break\n",
    "                    \n",
    "def stop_simulation():\n",
    "    global workers\n",
    "    global history_buffer\n",
    "    global processable_buffer\n",
    "    global pipes\n",
    "    global child_pipes\n",
    "    \n",
    "    if 'workers' in globals() and len(workers) != 0:\n",
    "        for worker in workers:\n",
    "            worker.terminate()\n",
    "    workers = []\n",
    "    \n",
    "    for pipe in pipes:\n",
    "        pipe.close()\n",
    "    \n",
    "    for pipe in child_pipes:\n",
    "        pipe.close()\n",
    "        \n",
    "    for _ in history_buffer.qsize():\n",
    "        history_buffer.get()\n",
    "    \n",
    "    for _ in processable_buffer.qsize():\n",
    "        processable_buffer.get()\n",
    "    \n",
    "        \n",
    "    history_buffer.close()\n",
    "    processable_buffer.close()\n",
    "    \n",
    "    # Then we empty the queues\n",
    "    del history_buffer\n",
    "    del processable_buffer\n",
    "    del pipes\n",
    "    del child_pipes\n",
    "\n",
    "def parallel_sim():\n",
    "    global workers\n",
    "    global history_buffer\n",
    "    global processable_buffer\n",
    "    global pipes\n",
    "    global child_pipes\n",
    "    \n",
    "    if 'workers' in globals() and len(workers) != 0:\n",
    "        stop_simulation()\n",
    "    \n",
    "    history_buffer = Queue(n_games) # This numbers can be tweaked\n",
    "    processable_buffer = Queue(num_threads * n_players)\n",
    "    pipes = []\n",
    "    child_pipes = []\n",
    "    \n",
    "    workers = []\n",
    "    for i in range(num_threads):\n",
    "        parent_pipe, child_pipe = Pipe() # Pipe to communicate with childs\n",
    "        pipes.append(parent_pipe)\n",
    "        child_pipes.append(child_pipe)\n",
    "        \n",
    "        worker = Thread(target=sim, args=[i, child_pipe])\n",
    "        worker.daemon = False\n",
    "        worker.start()\n",
    "        workers.append(worker)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
