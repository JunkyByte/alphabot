{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T15:34:58.530788Z",
     "start_time": "2019-02-12T15:34:55.402832Z"
    },
    "autopy": 2
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adryw/miniconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/adryw/miniconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pickle\n",
    "import keras\n",
    "from keras.models import Model, load_model, clone_model\n",
    "from keras.utils import multi_gpu_model\n",
    "from keras.layers import *\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.regularizers import l2\n",
    "from keras.losses import binary_crossentropy\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import random\n",
    "sys.path.append('src')  # Fix for jupyter\n",
    "import src.emulator as emulator\n",
    "import src.emulator_utils as emulator_utils\n",
    "import src.emulator_vis as emulator_vis\n",
    "%matplotlib inline\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "import multiprocessing\n",
    "from multiprocessing import Event, Queue, Pipe\n",
    "from multiprocessing import Process as Thread\n",
    "import os\n",
    "import logging\n",
    "from mcts import *\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autopy": 0
   },
   "source": [
    "# Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T15:34:58.534884Z",
     "start_time": "2019-02-12T15:34:58.532293Z"
    },
    "autopy": 0
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(filename='logging.log', level=logging.INFO, format='%(asctime)s %(message)s', filemode='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autopy": 0
   },
   "source": [
    "# Model Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T15:34:58.538698Z",
     "start_time": "2019-02-12T15:34:58.536418Z"
    },
    "autopy": 0
   },
   "outputs": [],
   "source": [
    "INPUT_SIZE = (None, None, 5) # Map size fixed to 16x16 (2 to 3 players)\n",
    "#INPUT_SIZE = (13, 13, 5) # Map size fixed to 16x16 (2 to 3 players)\n",
    "N_ACTIONS = 4\n",
    "gpus = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autopy": 0
   },
   "source": [
    "# Define the Layers Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T15:34:58.550352Z",
     "start_time": "2019-02-12T15:34:58.540064Z"
    },
    "autopy": 0
   },
   "outputs": [],
   "source": [
    "filters = 64\n",
    "\n",
    "# Convolutional Block\n",
    "def conv_block(in_layer, name, filters=filters, kernel_size=(3,3), bn=True, relu=True):\n",
    "    l = Conv2D(filters, kernel_size, use_bias = False, \n",
    "               padding='same', name = name, kernel_regularizer=l2(1e-4))(in_layer)\n",
    "    if bn:\n",
    "        l = BatchNormalization(axis=3, name = name + '_bn')(l)\n",
    "    if relu:\n",
    "        #l = Activation('relu', name = name + '_relu')(l)\n",
    "        l = LeakyReLU(name = name + '_lkrelu')(l)\n",
    "\n",
    "    return l\n",
    "\n",
    "# Residual Block\n",
    "def residual_conv(in_layer, idx, filters=filters, kernel_size=(3,3), bn=True, relu=True):\n",
    "    name = 'res_' + str(idx)\n",
    "    # Full conv block of pre-defined shape\n",
    "    l = conv_block(in_layer, name + '_conv1', filters, kernel_size=(3,3), bn=True, relu=True)\n",
    "    # Second block with skip connection\n",
    "    l = Conv2D(filters, kernel_size, use_bias = False, padding='same', \n",
    "               name = name + '_conv2', kernel_regularizer=l2(1e-4))(l)\n",
    "    if bn:\n",
    "        l = BatchNormalization(axis=3, name = name + '_conv2_bn')(l)\n",
    "    \n",
    "    l = Concatenate()([in_layer, l]) # Skip conn.\n",
    "    #l = Add()([in_layer, l]) # Skip conn.\n",
    "    \n",
    "    if relu:\n",
    "        #l = Activation('relu', name = name + '_relu')(l)\n",
    "        l = LeakyReLU(name = name + '_lkrelu')(l)\n",
    "        \n",
    "    return l\n",
    "\n",
    "def value_head(in_layer):\n",
    "    l = conv_block(in_layer, 'value_conv', filters=64)\n",
    "    l = Conv2D(name='value_head', filters=1, kernel_size=(1,1), activation='tanh', \n",
    "               kernel_regularizer=l2(1e-4), use_bias=False)(l)\n",
    "\n",
    "    l = Lambda(lambda x : x / tf.math.square(tf.cast(tf.shape(x)[1], dtype=tf.float32)), name='value_rescaled')(l)\n",
    "    l = Lambda(lambda x : tf.reduce_sum(x, axis=[1, 2]), name='value_h')(l)\n",
    "    l = Lambda(lambda x : x * 2, name='value_rescale')(l)\n",
    "    l = Lambda(lambda x : tf.clip_by_value(x, -1., 1.), name='value')(l)\n",
    "    return l\n",
    "\n",
    "def policy_head(in_layer):\n",
    "    l = conv_block(in_layer, 'policy_conv', filters=64)\n",
    "    l = Conv2D(name='policy_head', filters=4, kernel_size=(1,1), \n",
    "               kernel_regularizer=l2(1e-4), activation='sigmoid')(l)\n",
    "    \n",
    "    l = Lambda(lambda x : tf.reduce_sum(x, axis=[1, 2]), name='sum_policy')(l)\n",
    "    l = Activation('softmax', name='policy')(l)\n",
    "    \n",
    "    return l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autopy": 0
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T15:34:58.877848Z",
     "start_time": "2019-02-12T15:34:58.871575Z"
    },
    "autopy": 0
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    def declare_model():\n",
    "        n_residual = 8\n",
    "\n",
    "        input_layer = Input(INPUT_SIZE)\n",
    "        l = conv_block(input_layer, 'conv')\n",
    "        for i in range(n_residual):\n",
    "            l = residual_conv(l, idx=i + 1)\n",
    "\n",
    "        policy = policy_head(l)\n",
    "        value = value_head(l)\n",
    "\n",
    "        alphabot = Model(input_layer, [policy, value])\n",
    "        return alphabot\n",
    "    \n",
    "    if gpus > 1:\n",
    "        with tf.device('/cpu:0'):\n",
    "            alphabot = declare_model()\n",
    "        alphabot_multi = multi_gpu_model(alphabot, gpus=gpus)\n",
    "        return alphabot_multi, alphabot\n",
    "    \n",
    "    alphabot = declare_model()\n",
    "    return alphabot, alphabot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T15:35:00.361587Z",
     "start_time": "2019-02-12T15:35:00.354340Z"
    },
    "autopy": 0
   },
   "outputs": [],
   "source": [
    "def policy_rot90(policy, k = 1):\n",
    "    k = k % 4\n",
    "    policy = np.array(policy)\n",
    "    for i in range(k):\n",
    "        policy = policy[..., [1, 2, 3, 0]]\n",
    "    \n",
    "    return policy\n",
    "\n",
    "def policy_flip(policy, vert=False):\n",
    "    policy = np.array(policy)\n",
    "    if vert:\n",
    "        return policy[..., [0, 3, 2, 1]]\n",
    "    \n",
    "    return policy[..., [2, 1, 0, 3]]\n",
    "\n",
    "def state_flip(state, vert=False):\n",
    "    state = np.array(state)\n",
    "    \n",
    "    if vert:\n",
    "        return state[:, ::-1]\n",
    "    return state[:, :, ::-1]\n",
    "\n",
    "def apply_simmetries(train_steps):\n",
    "    # 90;180:270 degrees rotations\n",
    "    # 0 right, 1 down, 2 left, 3 up\n",
    "    # Flips\n",
    "    \n",
    "    t_s = []\n",
    "    t_p = []\n",
    "    value = []\n",
    "    for step in train_steps:\n",
    "        t_s.append(step.state)\n",
    "        t_p.append(step.policy)\n",
    "        value.append(step.value)\n",
    "    \n",
    "    for i in range(1, 4):\n",
    "        for j in range(0, 2):\n",
    "            state = np.rot90(t_s, k=i, axes=(1, 2))\n",
    "            policy = policy_rot90(t_p, k=i)\n",
    "    \n",
    "            if j == 0: # Horizontal flip\n",
    "                state = state_flip(state, vert=False)\n",
    "                policy = policy_flip(policy, vert=False)\n",
    "            elif j == 1: # Vertical flip\n",
    "                state = state_flip(state, vert=True)\n",
    "                policy = policy_flip(policy, vert=True)\n",
    "\n",
    "            train_steps.extend([TrainStep(s, v, p) for s, p, v in zip(state, policy, value)])\n",
    "    \n",
    "    return train_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T15:35:00.992213Z",
     "start_time": "2019-02-12T15:35:00.981410Z"
    },
    "autopy": 0,
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def manage_predictions():\n",
    "    t = 0\n",
    "    \n",
    "    while not winner_buffer.full():\n",
    "        indices1, states1 = [], []\n",
    "        indices2, states2 = [], []\n",
    "        \n",
    "        if processable_buffer.qsize() < min(num_threads, num_threads//3): # Wait until a bunch of requests are queued\n",
    "            continue\n",
    "\n",
    "        net0, net1 = [], []\n",
    "        for i in range(processable_buffer.qsize()):\n",
    "            index, state, net = processable_buffer.get()\n",
    "            if net == False:\n",
    "                if state[..., -1].all() == 0:\n",
    "                    net = 'alphabot'\n",
    "                else:\n",
    "                    net = 'alphabot_best'\n",
    "            else:\n",
    "                if state[..., -1].all() == 0:\n",
    "                    net = 'alphabot_best'\n",
    "                else:\n",
    "                    net = 'alphabot'\n",
    "                \n",
    "            if net == 'alphabot':\n",
    "                indices1.append(index)\n",
    "                states1.append(state)\n",
    "            elif net == 'alphabot_best':\n",
    "                indices2.append(index)\n",
    "                states2.append(state)\n",
    "        \n",
    "        predictions1, predictions2 = [], []\n",
    "        if len(states1) > 0:\n",
    "            states1 = np.array(states1, dtype=np.float32)\n",
    "            predictions1 = alphabot.predict(states1)\n",
    "        if len(states2) > 0:\n",
    "            states2 = np.array(states2, dtype=np.float32)\n",
    "            predictions2 = alphabot_best.predict(states2)\n",
    "\n",
    "        if len(predictions1) > 0:\n",
    "            for i, pred in enumerate(tuple(zip(predictions1[0], predictions1[1]))):\n",
    "                pipes[indices1[i]].send(dict(zip(alphabot.output_names, pred)))\n",
    "        \n",
    "        if len(predictions2) > 0:\n",
    "            for i, pred in enumerate(tuple(zip(predictions2[0], predictions2[1]))):\n",
    "                pipes[indices2[i]].send(dict(zip(alphabot.output_names, pred)))\n",
    "        \n",
    "        if time.time() - t > 30: # Every 30 secs\n",
    "            t = time.time()\n",
    "            logging.info('Finished evaluation %d games' % winner_buffer.qsize())\n",
    "        \n",
    "def simulate_games():\n",
    "    logging.debug('Starting Threads for parallel Games')\n",
    "    \n",
    "    parallel_sim(evaluation=False) # Parallel Games\n",
    "    \n",
    "    while not history_buffer.full():\n",
    "        indices, states = [], []\n",
    "        if processable_buffer.qsize() < min(num_threads, 2): # Wait until a bunch of requests are queued\n",
    "            continue\n",
    "\n",
    "        for i in range(processable_buffer.qsize()):\n",
    "            index, state, _ = processable_buffer.get()\n",
    "            indices.append(index)\n",
    "            states.append(state)\n",
    "            \n",
    "        states = np.array(states, dtype=np.float32)\n",
    "        predictions = alphabot.predict(states)\n",
    "        for i, pred in enumerate(tuple(zip(predictions[0], predictions[1]))):\n",
    "            pipes[indices[i]].send(dict(zip(alphabot.output_names, pred)))\n",
    "\n",
    "    logging.info('Finished Simulating %s games', n_games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T15:35:01.460418Z",
     "start_time": "2019-02-12T15:35:01.440752Z"
    },
    "autopy": 0,
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def play_eval(reverted=False, pipe=None, process_id=None):\n",
    "    global alphabot_best\n",
    "    global alphabot\n",
    "    \n",
    "    game = emulator.Game(2)\n",
    "    mapp = game.reset()\n",
    "  \n",
    "    tree_player0 = MCTS()\n",
    "    tree_player0.alpha = MCTS_eval_alpha\n",
    "  \n",
    "    tree_player1 = MCTS()\n",
    "    tree_player1.alpha = MCTS_eval_alpha\n",
    "\n",
    "    old_mapp = None\n",
    "    head = None\n",
    "    turn = 0\n",
    "    s = map_to_state(mapp, old_mapp, None, 0)\n",
    "    old_mapp = copy.deepcopy(mapp)\n",
    "  \n",
    "    policies = []    \n",
    "    while True:\n",
    "        if turn == 0:\n",
    "            policy = do_search(MCTS_eval_steps, s, mapp, game, tree_player0, pipe=pipe, process_id=process_id, ask_predict=ask_predict, alphabot=reverted, allow_move=allow_move)\n",
    "        else:\n",
    "            policy = do_search(MCTS_eval_steps2, s, mapp, game, tree_player1, pipe=pipe, process_id=process_id, ask_predict=ask_predict, alphabot=reverted, allow_move=allow_move)\n",
    "\n",
    "        if not use_eval_choice:\n",
    "            choosen = np.argmax(policy)\n",
    "        else :\n",
    "            choosen = np.random.choice(4, p=policy)\n",
    "\n",
    "        policies.append(np.array(policy))\n",
    "        mapp, tmp_head = game.step(mapp, s, choosen, turn, mcts=True)\n",
    "\n",
    "        turn = 1 - turn\n",
    "        if turn == 0:  # We update the state\n",
    "            s = map_to_state(mapp, old_mapp, s, 0, head)  # TODO: Map to state\n",
    "        else:\n",
    "            head = tmp_head\n",
    "            s[..., -1] = 1\n",
    "\n",
    "        if turn == 0:\n",
    "            old_mapp = np.array(mapp)\n",
    "        \n",
    "        if game.game_ended():\n",
    "            logging.debug('GAME ENDED, %s won, %s <- reverted' % (turn, reverted))\n",
    "            if not reverted:\n",
    "                return turn\n",
    "            else:\n",
    "                return  1 - turn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T15:35:01.898999Z",
     "start_time": "2019-02-12T15:35:01.890089Z"
    },
    "autopy": 0
   },
   "outputs": [],
   "source": [
    "def train_model():        \n",
    "        picked_data = random.sample(complete_history, k=min(BATCH_SIZE, len(complete_history))) \n",
    "        \n",
    "        state = []\n",
    "        policy = []\n",
    "        value = []\n",
    "        for step in picked_data:\n",
    "            policy.append(step.policy)\n",
    "            state.append(step.state)\n",
    "            value.append(step.value)\n",
    "            \n",
    "        y = [np.zeros((len(state), 4)), np.zeros((len(state), 1))]\n",
    "        y[0] = policy\n",
    "        y[1] = value\n",
    "        \n",
    "        losses = alphabot.train_on_batch(np.array(state, dtype=np.float32), y)\n",
    "        return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T15:35:02.358326Z",
     "start_time": "2019-02-12T15:35:02.343827Z"
    },
    "autopy": 0,
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def training_cycle():\n",
    "    global alphabot\n",
    "    global alphabot_best\n",
    "    global total_improv\n",
    "    \n",
    "    logging.info('Starting Training Cycle')\n",
    "    simulate_games()\n",
    "    \n",
    "    # history_buffer contains the games, we store them inside complete history    \n",
    "    tmp_buffer = []\n",
    "    for g in range(history_buffer.qsize()):\n",
    "        tmp_buffer.append(history_buffer.get())\n",
    "    tmp_buffer = apply_simmetries(tmp_buffer)\n",
    "    complete_history.extend(tmp_buffer)\n",
    "    stop_simulation() # We can now stop the simulation (will free the memory)\n",
    "    \n",
    "    logging.info('Starting Model Training')\n",
    "    losses = [0, 0, 0] # For debug purpose\n",
    "    sum_loss = 0\n",
    "    cc = 1\n",
    "    for i in range(t_steps + 1):\n",
    "        if i % 100 == 0:\n",
    "            logging.info('Training Interaction: %s losses: %s %s', i, \n",
    "                         round(sum_loss / cc, 2), np.round(losses, 2))\n",
    "        \n",
    "        losses = train_model()\n",
    "        sum_loss += losses[0]\n",
    "        logging.debug('Losses: %s', losses)\n",
    "        \n",
    "        cc += 1\n",
    "        if i % eval_steps == 0 and i > 0:\n",
    "            cc = 1 # Reset loss counter\n",
    "            sum_loss = 0\n",
    "            wins = {'candidate' : 0, 'best' : 0}\n",
    "            n_c = {0 : 'candidate', 1 : 'best'}\n",
    "            \n",
    "            logging.info('Starting self-play evaluation')    \n",
    "            parallel_sim(evaluation=True) # Start Parallel Games\n",
    "            manage_predictions()\n",
    "            for i in range(winner_buffer.qsize()):\n",
    "                w = winner_buffer.get()\n",
    "                wins[n_c[w]] += 1 # add a win to the winner\n",
    "            stop_simulation()\n",
    "            \n",
    "            win_ratio = round(wins['candidate'] / eval_games, 2)\n",
    "            if win_ratio >= win_percent:\n",
    "                logging.info('Great! Our candidate won %s percent of games', round(win_ratio * 100))\n",
    "                total_improv += 1\n",
    "                logging.info('Our bot got better %s times', total_improv)\n",
    "                alphabot.save('alphabot_best.pickle')\n",
    "                replace_best()    \n",
    "            else:\n",
    "                logging.info('Damn! Our candidate only won %s percent of games', round(win_ratio * 100, 2))         \n",
    "                logging.info('Cloning to best')\n",
    "                reload_best()\n",
    "            \n",
    "    if len(complete_history) >= k * n_games * 7:\n",
    "        logging.info('Removing oldest games')\n",
    "        del complete_history[:n_games * 7] # Delete n oldest games from history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T15:35:02.837227Z",
     "start_time": "2019-02-12T15:35:02.829529Z"
    },
    "autopy": 0
   },
   "outputs": [],
   "source": [
    "def load_best(best_model):\n",
    "    global alphabot\n",
    "    global alphabot_best\n",
    "    alphabot_best = load_model(best_model, \n",
    "                               custom_objects={'softmax_cross_entropy_with_logits' : softmax_cross_entropy_with_logits,\n",
    "                                          'categorical_weighted' : categorical_weighted})\n",
    "    alphabot = load_model(best_model, \n",
    "                               custom_objects={'softmax_cross_entropy_with_logits' : softmax_cross_entropy_with_logits,\n",
    "                                          'categorical_weighted' : categorical_weighted})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T15:35:03.302943Z",
     "start_time": "2019-02-12T15:35:03.300431Z"
    },
    "autopy": 0
   },
   "outputs": [],
   "source": [
    "def reload_best():\n",
    "    global alphabot\n",
    "    global alphabot_best\n",
    "    \n",
    "    alphabot.set_weights(alphabot_best.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T15:35:03.816720Z",
     "start_time": "2019-02-12T15:35:03.814409Z"
    },
    "autopy": 0
   },
   "outputs": [],
   "source": [
    "def replace_best():\n",
    "    global alphabot\n",
    "    global alphabot_best\n",
    "    \n",
    "    alphabot_best.set_weights(alphabot.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T15:35:04.338612Z",
     "start_time": "2019-02-12T15:35:04.330838Z"
    },
    "autopy": 0
   },
   "outputs": [],
   "source": [
    "def train(cycles):\n",
    "    global alphabot_best\n",
    "    global alphabot\n",
    "    \n",
    "    #replace_best()\n",
    "    \n",
    "    complete_history = []\n",
    "    for i in range(cycles):\n",
    "        logging.info('Training cycle: %s', i)\n",
    "        training_cycle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T15:35:04.857970Z",
     "start_time": "2019-02-12T15:35:04.831163Z"
    },
    "autopy": 0,
    "code_folding": [
     43
    ]
   },
   "outputs": [],
   "source": [
    "def ask_predict(idi, x, net=None):\n",
    "    # Adds to queue id and data from process\n",
    "    processable_buffer.put((idi, x, net))\n",
    "\n",
    "def sim(process_id, pipe, evaluation=False):\n",
    "    np.random.seed()\n",
    "    random.seed()\n",
    "    \n",
    "    if evaluation:\n",
    "        while True:\n",
    "            reverted = np.random.random() >= 0.5\n",
    "            winner = play_eval(reverted, pipe, process_id)\n",
    "            \n",
    "            try:\n",
    "                winner_buffer.put_nowait(winner)\n",
    "            except:\n",
    "                break\n",
    "    \n",
    "    else:\n",
    "        while True:\n",
    "            train_steps = simulate_game(MCTS_steps, MCTS_alpha, pipe, ask_predict, process_id)    \n",
    "        \n",
    "            try:\n",
    "                for step in train_steps:\n",
    "                    history_buffer.put_nowait(step)\n",
    "            except:\n",
    "                break\n",
    "                    \n",
    "def stop_simulation():\n",
    "    global workers\n",
    "    global history_buffer\n",
    "    global processable_buffer\n",
    "    global winner_buffer\n",
    "    global pipes\n",
    "    global child_pipes\n",
    "    \n",
    "    if 'workers' in globals() and len(workers) != 0:\n",
    "        for worker in workers:\n",
    "            worker.terminate()\n",
    "    workers = []\n",
    "    \n",
    "    for pipe in pipes:\n",
    "        pipe.close()\n",
    "\n",
    "    for pipe in child_pipes:\n",
    "        pipe.close()\n",
    "    \n",
    "    #for _ in range(history_buffer.qsize()):\n",
    "    #    try:\n",
    "    #        history_buffer.get_nowait()\n",
    "    #    except:\n",
    "    #        break\n",
    "            \n",
    "    #for _ in range(processable_buffer.qsize()):\n",
    "    #    try:\n",
    "    #        processable_buffer.get_nowait()\n",
    "    #    except:\n",
    "    #        break\n",
    "        \n",
    "    history_buffer.close()\n",
    "    processable_buffer.close()\n",
    "    winner_buffer.close()\n",
    "    \n",
    "    # Then we empty the queues\n",
    "    del history_buffer\n",
    "    del processable_buffer\n",
    "    del pipes\n",
    "    del child_pipes\n",
    "    del winner_buffer\n",
    "\n",
    "def parallel_sim(evaluation=False):\n",
    "    global workers\n",
    "    global history_buffer\n",
    "    global processable_buffer\n",
    "    global winner_buffer\n",
    "    global pipes\n",
    "    global child_pipes\n",
    "    \n",
    "    if 'workers' in globals() and len(workers) != 0:\n",
    "        stop_simulation()\n",
    "    \n",
    "    history_buffer = Queue(n_games) # This numbers can be tweaked\n",
    "    winner_buffer = Queue(eval_games)\n",
    "    processable_buffer = Queue(num_threads)\n",
    "    pipes = []\n",
    "    child_pipes = []\n",
    "    \n",
    "    workers = []\n",
    "    for i in range(num_threads):\n",
    "        parent_pipe, child_pipe = Pipe() # Pipe to communicate with childs\n",
    "        pipes.append(parent_pipe)\n",
    "        child_pipes.append(child_pipe)\n",
    "        \n",
    "        worker = Thread(target=sim, args=[i, child_pipe, evaluation])\n",
    "        worker.daemon = False\n",
    "        worker.start()\n",
    "        workers.append(worker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T15:35:05.364348Z",
     "start_time": "2019-02-12T15:35:05.360472Z"
    },
    "autopy": 0
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def softmax_cross_entropy_with_logits(y_true, y_pred):\n",
    "\n",
    "    p = y_pred\n",
    "    pi = y_true\n",
    "\n",
    "    zero = tf.zeros(shape = tf.shape(pi), dtype=tf.float32)\n",
    "    where = tf.equal(pi, zero)\n",
    "\n",
    "    negatives = tf.fill(tf.shape(pi), -100.0) \n",
    "    p = tf.where(where, negatives, p)\n",
    "\n",
    "    loss = tf.maximum(0., tf.nn.softmax_cross_entropy_with_logits(labels = pi, logits = p) - 1)\n",
    "\n",
    "    return loss\n",
    "\n",
    "def categorical_weighted(y_true, y_pred):\n",
    "    return tf.maximum(0., keras.losses.categorical_crossentropy(y_true, y_pred) - 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T15:35:09.858003Z",
     "start_time": "2019-02-12T15:35:06.630069Z"
    },
    "autopy": 0,
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________________________________________\n",
      "Layer (type)                        Output Shape             Param #       Connected to                         \n",
      "================================================================================================================\n",
      "input_1 (InputLayer)                (None, None, None, 5)    0                                                  \n",
      "________________________________________________________________________________________________________________\n",
      "conv (Conv2D)                       (None, None, None, 64)   2880          input_1[0][0]                        \n",
      "________________________________________________________________________________________________________________\n",
      "conv_bn (BatchNormalization)        (None, None, None, 64)   256           conv[0][0]                           \n",
      "________________________________________________________________________________________________________________\n",
      "conv_lkrelu (LeakyReLU)             (None, None, None, 64)   0             conv_bn[0][0]                        \n",
      "________________________________________________________________________________________________________________\n",
      "res_1_conv1 (Conv2D)                (None, None, None, 64)   36864         conv_lkrelu[0][0]                    \n",
      "________________________________________________________________________________________________________________\n",
      "res_1_conv1_bn (BatchNormalization) (None, None, None, 64)   256           res_1_conv1[0][0]                    \n",
      "________________________________________________________________________________________________________________\n",
      "res_1_conv1_lkrelu (LeakyReLU)      (None, None, None, 64)   0             res_1_conv1_bn[0][0]                 \n",
      "________________________________________________________________________________________________________________\n",
      "res_1_conv2 (Conv2D)                (None, None, None, 64)   36864         res_1_conv1_lkrelu[0][0]             \n",
      "________________________________________________________________________________________________________________\n",
      "res_1_conv2_bn (BatchNormalization) (None, None, None, 64)   256           res_1_conv2[0][0]                    \n",
      "________________________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)         (None, None, None, 128)  0             conv_lkrelu[0][0]                    \n",
      "                                                                           res_1_conv2_bn[0][0]                 \n",
      "________________________________________________________________________________________________________________\n",
      "res_1_lkrelu (LeakyReLU)            (None, None, None, 128)  0             concatenate_1[0][0]                  \n",
      "________________________________________________________________________________________________________________\n",
      "res_2_conv1 (Conv2D)                (None, None, None, 64)   73728         res_1_lkrelu[0][0]                   \n",
      "________________________________________________________________________________________________________________\n",
      "res_2_conv1_bn (BatchNormalization) (None, None, None, 64)   256           res_2_conv1[0][0]                    \n",
      "________________________________________________________________________________________________________________\n",
      "res_2_conv1_lkrelu (LeakyReLU)      (None, None, None, 64)   0             res_2_conv1_bn[0][0]                 \n",
      "________________________________________________________________________________________________________________\n",
      "res_2_conv2 (Conv2D)                (None, None, None, 64)   36864         res_2_conv1_lkrelu[0][0]             \n",
      "________________________________________________________________________________________________________________\n",
      "res_2_conv2_bn (BatchNormalization) (None, None, None, 64)   256           res_2_conv2[0][0]                    \n",
      "________________________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)         (None, None, None, 192)  0             res_1_lkrelu[0][0]                   \n",
      "                                                                           res_2_conv2_bn[0][0]                 \n",
      "________________________________________________________________________________________________________________\n",
      "res_2_lkrelu (LeakyReLU)            (None, None, None, 192)  0             concatenate_2[0][0]                  \n",
      "________________________________________________________________________________________________________________\n",
      "res_3_conv1 (Conv2D)                (None, None, None, 64)   110592        res_2_lkrelu[0][0]                   \n",
      "________________________________________________________________________________________________________________\n",
      "res_3_conv1_bn (BatchNormalization) (None, None, None, 64)   256           res_3_conv1[0][0]                    \n",
      "________________________________________________________________________________________________________________\n",
      "res_3_conv1_lkrelu (LeakyReLU)      (None, None, None, 64)   0             res_3_conv1_bn[0][0]                 \n",
      "________________________________________________________________________________________________________________\n",
      "res_3_conv2 (Conv2D)                (None, None, None, 64)   36864         res_3_conv1_lkrelu[0][0]             \n",
      "________________________________________________________________________________________________________________\n",
      "res_3_conv2_bn (BatchNormalization) (None, None, None, 64)   256           res_3_conv2[0][0]                    \n",
      "________________________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)         (None, None, None, 256)  0             res_2_lkrelu[0][0]                   \n",
      "                                                                           res_3_conv2_bn[0][0]                 \n",
      "________________________________________________________________________________________________________________\n",
      "res_3_lkrelu (LeakyReLU)            (None, None, None, 256)  0             concatenate_3[0][0]                  \n",
      "________________________________________________________________________________________________________________\n",
      "res_4_conv1 (Conv2D)                (None, None, None, 64)   147456        res_3_lkrelu[0][0]                   \n",
      "________________________________________________________________________________________________________________\n",
      "res_4_conv1_bn (BatchNormalization) (None, None, None, 64)   256           res_4_conv1[0][0]                    \n",
      "________________________________________________________________________________________________________________\n",
      "res_4_conv1_lkrelu (LeakyReLU)      (None, None, None, 64)   0             res_4_conv1_bn[0][0]                 \n",
      "________________________________________________________________________________________________________________\n",
      "res_4_conv2 (Conv2D)                (None, None, None, 64)   36864         res_4_conv1_lkrelu[0][0]             \n",
      "________________________________________________________________________________________________________________\n",
      "res_4_conv2_bn (BatchNormalization) (None, None, None, 64)   256           res_4_conv2[0][0]                    \n",
      "________________________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)         (None, None, None, 320)  0             res_3_lkrelu[0][0]                   \n",
      "                                                                           res_4_conv2_bn[0][0]                 \n",
      "________________________________________________________________________________________________________________\n",
      "res_4_lkrelu (LeakyReLU)            (None, None, None, 320)  0             concatenate_4[0][0]                  \n",
      "________________________________________________________________________________________________________________\n",
      "res_5_conv1 (Conv2D)                (None, None, None, 64)   184320        res_4_lkrelu[0][0]                   \n",
      "________________________________________________________________________________________________________________\n",
      "res_5_conv1_bn (BatchNormalization) (None, None, None, 64)   256           res_5_conv1[0][0]                    \n",
      "________________________________________________________________________________________________________________\n",
      "res_5_conv1_lkrelu (LeakyReLU)      (None, None, None, 64)   0             res_5_conv1_bn[0][0]                 \n",
      "________________________________________________________________________________________________________________\n",
      "res_5_conv2 (Conv2D)                (None, None, None, 64)   36864         res_5_conv1_lkrelu[0][0]             \n",
      "________________________________________________________________________________________________________________\n",
      "res_5_conv2_bn (BatchNormalization) (None, None, None, 64)   256           res_5_conv2[0][0]                    \n",
      "________________________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)         (None, None, None, 384)  0             res_4_lkrelu[0][0]                   \n",
      "                                                                           res_5_conv2_bn[0][0]                 \n",
      "________________________________________________________________________________________________________________\n",
      "res_5_lkrelu (LeakyReLU)            (None, None, None, 384)  0             concatenate_5[0][0]                  \n",
      "________________________________________________________________________________________________________________\n",
      "res_6_conv1 (Conv2D)                (None, None, None, 64)   221184        res_5_lkrelu[0][0]                   \n",
      "________________________________________________________________________________________________________________\n",
      "res_6_conv1_bn (BatchNormalization) (None, None, None, 64)   256           res_6_conv1[0][0]                    \n",
      "________________________________________________________________________________________________________________\n",
      "res_6_conv1_lkrelu (LeakyReLU)      (None, None, None, 64)   0             res_6_conv1_bn[0][0]                 \n",
      "________________________________________________________________________________________________________________\n",
      "res_6_conv2 (Conv2D)                (None, None, None, 64)   36864         res_6_conv1_lkrelu[0][0]             \n",
      "________________________________________________________________________________________________________________\n",
      "res_6_conv2_bn (BatchNormalization) (None, None, None, 64)   256           res_6_conv2[0][0]                    \n",
      "________________________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)         (None, None, None, 448)  0             res_5_lkrelu[0][0]                   \n",
      "                                                                           res_6_conv2_bn[0][0]                 \n",
      "________________________________________________________________________________________________________________\n",
      "res_6_lkrelu (LeakyReLU)            (None, None, None, 448)  0             concatenate_6[0][0]                  \n",
      "________________________________________________________________________________________________________________\n",
      "res_7_conv1 (Conv2D)                (None, None, None, 64)   258048        res_6_lkrelu[0][0]                   \n",
      "________________________________________________________________________________________________________________\n",
      "res_7_conv1_bn (BatchNormalization) (None, None, None, 64)   256           res_7_conv1[0][0]                    \n",
      "________________________________________________________________________________________________________________\n",
      "res_7_conv1_lkrelu (LeakyReLU)      (None, None, None, 64)   0             res_7_conv1_bn[0][0]                 \n",
      "________________________________________________________________________________________________________________\n",
      "res_7_conv2 (Conv2D)                (None, None, None, 64)   36864         res_7_conv1_lkrelu[0][0]             \n",
      "________________________________________________________________________________________________________________\n",
      "res_7_conv2_bn (BatchNormalization) (None, None, None, 64)   256           res_7_conv2[0][0]                    \n",
      "________________________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)         (None, None, None, 512)  0             res_6_lkrelu[0][0]                   \n",
      "                                                                           res_7_conv2_bn[0][0]                 \n",
      "________________________________________________________________________________________________________________\n",
      "res_7_lkrelu (LeakyReLU)            (None, None, None, 512)  0             concatenate_7[0][0]                  \n",
      "________________________________________________________________________________________________________________\n",
      "res_8_conv1 (Conv2D)                (None, None, None, 64)   294912        res_7_lkrelu[0][0]                   \n",
      "________________________________________________________________________________________________________________\n",
      "res_8_conv1_bn (BatchNormalization) (None, None, None, 64)   256           res_8_conv1[0][0]                    \n",
      "________________________________________________________________________________________________________________\n",
      "res_8_conv1_lkrelu (LeakyReLU)      (None, None, None, 64)   0             res_8_conv1_bn[0][0]                 \n",
      "________________________________________________________________________________________________________________\n",
      "res_8_conv2 (Conv2D)                (None, None, None, 64)   36864         res_8_conv1_lkrelu[0][0]             \n",
      "________________________________________________________________________________________________________________\n",
      "res_8_conv2_bn (BatchNormalization) (None, None, None, 64)   256           res_8_conv2[0][0]                    \n",
      "________________________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)         (None, None, None, 576)  0             res_7_lkrelu[0][0]                   \n",
      "                                                                           res_8_conv2_bn[0][0]                 \n",
      "________________________________________________________________________________________________________________\n",
      "res_8_lkrelu (LeakyReLU)            (None, None, None, 576)  0             concatenate_8[0][0]                  \n",
      "________________________________________________________________________________________________________________\n",
      "value_conv (Conv2D)                 (None, None, None, 64)   331776        res_8_lkrelu[0][0]                   \n",
      "________________________________________________________________________________________________________________\n",
      "value_conv_bn (BatchNormalization)  (None, None, None, 64)   256           value_conv[0][0]                     \n",
      "________________________________________________________________________________________________________________\n",
      "policy_conv (Conv2D)                (None, None, None, 64)   331776        res_8_lkrelu[0][0]                   \n",
      "________________________________________________________________________________________________________________\n",
      "value_conv_lkrelu (LeakyReLU)       (None, None, None, 64)   0             value_conv_bn[0][0]                  \n",
      "________________________________________________________________________________________________________________\n",
      "policy_conv_bn (BatchNormalization) (None, None, None, 64)   256           policy_conv[0][0]                    \n",
      "________________________________________________________________________________________________________________\n",
      "value_head (Conv2D)                 (None, None, None, 1)    64            value_conv_lkrelu[0][0]              \n",
      "________________________________________________________________________________________________________________\n",
      "policy_conv_lkrelu (LeakyReLU)      (None, None, None, 64)   0             policy_conv_bn[0][0]                 \n",
      "________________________________________________________________________________________________________________\n",
      "value_rescaled (Lambda)             (None, None, None, 1)    0             value_head[0][0]                     \n",
      "________________________________________________________________________________________________________________\n",
      "policy_head (Conv2D)                (None, None, None, 4)    260           policy_conv_lkrelu[0][0]             \n",
      "________________________________________________________________________________________________________________\n",
      "value_h (Lambda)                    (None, 1)                0             value_rescaled[0][0]                 \n",
      "________________________________________________________________________________________________________________\n",
      "sum_policy (Lambda)                 (None, 4)                0             policy_head[0][0]                    \n",
      "________________________________________________________________________________________________________________\n",
      "value_rescale (Lambda)              (None, 1)                0             value_h[0][0]                        \n",
      "________________________________________________________________________________________________________________\n",
      "policy (Activation)                 (None, 4)                0             sum_policy[0][0]                     \n",
      "________________________________________________________________________________________________________________\n",
      "value (Lambda)                      (None, 1)                0             value_rescale[0][0]                  \n",
      "================================================================================================================\n",
      "Total params: 2,293,636\n",
      "Trainable params: 2,291,204\n",
      "Non-trainable params: 2,432\n",
      "________________________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "alphabot, _ = create_model()\n",
    "alphabot.compile(optimizer=Adam(1e-4), # SGD(1e-3, momentum=0.9)\n",
    "                          loss={'value' : 'mse', 'policy': categorical_weighted},\n",
    "                          loss_weights={'value' : 0.5, 'policy' : 0.5})\n",
    "alphabot.summary(line_length=112)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T15:35:17.231885Z",
     "start_time": "2019-02-12T15:35:11.532281Z"
    },
    "autopy": 0
   },
   "outputs": [],
   "source": [
    "#alphabot.save('alphabot_best.pickle')\n",
    "alphabot_best = load_model('alphabot_best.pickle', \n",
    "                           custom_objects={'categorical_weighted' : categorical_weighted, 'tf': tf})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T15:38:53.761738Z",
     "start_time": "2019-02-12T15:38:53.742623Z"
    },
    "autopy": 0
   },
   "outputs": [],
   "source": [
    "reload_best()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T19:46:48.003607Z",
     "start_time": "2019-02-06T19:46:34.203931Z"
    },
    "autopy": 0,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "load_best('alphabot_best.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T15:39:08.758229Z",
     "start_time": "2019-02-12T15:39:08.754743Z"
    },
    "autopy": 0,
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# History of games for training\n",
    "complete_history = []\n",
    "\n",
    "# Game Params\n",
    "n_players = 2\n",
    "n_games = 8_000 #10_000 # Simulate N games before each training\n",
    "k = 5 # Games to be stored n_games * K\n",
    "\n",
    "# Eval options\n",
    "allow_move = False\n",
    "use_eval_choice = False\n",
    "\n",
    "# Simulation Params\n",
    "num_threads = 6\n",
    "\n",
    "MCTS_steps = 70\n",
    "MCTS_eval_steps = 40\n",
    "MCTS_eval_steps2 = MCTS_eval_steps\n",
    "MCTS_alpha = 1.\n",
    "MCTS_eval_alpha = 1.\n",
    "\n",
    "# Training Params\n",
    "t_steps = 2000 # Steps of training\n",
    "eval_steps = 500 # How many steps before evaluation\n",
    "eval_games = 200 # How many games to play to evaluate who's best model\n",
    "win_percent = 0.55 # Ratio of game won to become best model\n",
    "BATCH_SIZE = 512\n",
    "total_improv = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T15:41:39.422928Z",
     "start_time": "2019-02-12T15:39:10.203707Z"
    },
    "autopy": 0,
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-d07c56b67da1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcycles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcycles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-b151e5fc8e5e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(cycles)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcycles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training cycle: %s'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mtraining_cycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-d041ba4650f6>\u001b[0m in \u001b[0;36mtraining_cycle\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m                          round(sum_loss / cc, 2), np.round(losses, 2))\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0msum_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Losses: %s'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-56b10828676c>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malphabot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#complete_history = []\n",
    "cycles = 1000\n",
    "\n",
    "train(cycles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T11:15:12.427486Z",
     "start_time": "2019-02-04T11:15:11.964793Z"
    },
    "autopy": 0
   },
   "outputs": [],
   "source": [
    "K.set_value(alphabot.optimizer.lr, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T16:21:10.184859Z",
     "start_time": "2019-02-08T16:21:10.181018Z"
    },
    "autopy": 0
   },
   "outputs": [],
   "source": [
    "game = emulator.Game(2)\n",
    "mapp = game.reset()\n",
    "\n",
    "tree = MCTS()\n",
    "tree.alpha = 1\n",
    "\n",
    "old_mapp = None\n",
    "turn = 0\n",
    "s = map_to_state(mapp, old_mapp, None, 0)\n",
    "old_mapp = copy.deepcopy(mapp)\n",
    "head = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-09T01:41:54.058121Z",
     "start_time": "2019-02-09T01:41:48.760088Z"
    },
    "autopy": 0,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8292602, 0.3044496, 0.98979956]\n",
      "[0.8159536, 0.29261062, 0.9810097]\n",
      "[0.80330974, 0.27280754, 0.9854906]\n",
      "[0.79731065, 0.27124688, 0.9758969]\n",
      "[0.80080616, 0.27958468, 0.97044516]\n",
      "[0.7920474, 0.24840118, 0.99976754]\n",
      "[0.83949023, 0.3147953, 0.9951276]\n",
      "[0.8497128, 0.3317, 0.990282]\n",
      "[0.84304434, 0.31689027, 0.9992264]\n",
      "[0.8196093, 0.2841468, 1.0015377]\n",
      "[0.8135063, 0.2901465, 0.9803965]\n",
      "[0.78683156, 0.25361547, 0.98190707]\n",
      "[0.79597783, 0.27031085, 0.97521883]\n",
      "[0.82310975, 0.29202205, 0.9969781]\n",
      "[0.822308, 0.29671633, 0.988396]\n",
      "[0.8125647, 0.28423315, 0.9876971]\n",
      "[0.82579094, 0.28991738, 1.0056865]\n",
      "[0.82539934, 0.30539665, 0.9817473]\n",
      "[0.78835404, 0.26108143, 0.9741919]\n",
      "[0.8077688, 0.27207044, 0.9966002]\n",
      "[0.79170793, 0.2560571, 0.98855996]\n",
      "[0.7959459, 0.26164576, 0.988714]\n",
      "[0.7756249, 0.24004437, 0.9805358]\n",
      "[0.8076964, 0.27125594, 0.99792296]\n",
      "[0.78949535, 0.2605843, 0.97758955]\n",
      "[0.7810649, 0.24758412, 0.98029137]\n",
      "[0.8175474, 0.28866205, 0.99170226]\n",
      "[0.7787319, 0.2460186, 0.9781015]\n",
      "[0.79473454, 0.24994616, 1.0042814]\n",
      "[0.7847405, 0.24610375, 0.9901232]\n",
      "[0.7829663, 0.25071558, 0.9797244]\n",
      "[0.7937341, 0.26204193, 0.98433787]\n",
      "[0.7961237, 0.2621144, 0.9890752]\n",
      "[0.81725836, 0.28863576, 0.9916303]\n",
      "[0.80146086, 0.26990345, 0.9882017]\n",
      "[0.77588826, 0.24429405, 0.97553915]\n",
      "[0.789704, 0.2625084, 0.9759175]\n",
      "[0.78151387, 0.24086775, 0.99206495]\n",
      "[0.7730296, 0.23681559, 0.9812408]\n",
      "[0.80843407, 0.2767101, 0.99227315]\n",
      "[0.8327582, 0.30529642, 0.9981068]\n",
      "[0.7919998, 0.27179056, 0.96691346]\n",
      "[0.8402636, 0.31668234, 0.9961674]\n",
      "[0.79577786, 0.26736343, 0.9812375]\n",
      "[0.8102497, 0.27670714, 0.9962279]\n",
      "[0.8031363, 0.2730249, 0.98758596]\n",
      "[0.7653287, 0.24323046, 0.9567225]\n",
      "[0.78412056, 0.24321713, 0.99438614]\n",
      "[0.7969849, 0.25975826, 0.9953635]\n",
      "[0.81822985, 0.29070413, 0.9914956]\n",
      "[0.82586586, 0.2885805, 1.0100147]\n",
      "[0.8027189, 0.2789994, 0.97815365]\n",
      "[0.77280205, 0.24529023, 0.96894485]\n",
      "[0.81049395, 0.289359, 0.9782855]\n",
      "[0.8097087, 0.27586478, 0.9970155]\n",
      "[0.78578526, 0.2558328, 0.97927433]\n",
      "[0.7841454, 0.23677097, 1.0046458]\n",
      "[0.8100544, 0.26489154, 1.0143397]\n",
      "[0.7897842, 0.26745713, 0.97000694]\n",
      "[0.7848686, 0.23464148, 1.0094558]\n",
      "[0.7661628, 0.22490932, 0.986698]\n",
      "[0.79475796, 0.2703576, 0.9757722]\n",
      "[0.81517166, 0.29843602, 0.9745385]\n",
      "[0.75451267, 0.21536864, 0.9778786]\n",
      "[0.75692976, 0.21273029, 0.9867274]\n",
      "[0.7760114, 0.23771697, 0.98746854]\n",
      "[0.78878266, 0.25778872, 0.9829629]\n",
      "[0.7631992, 0.23737906, 0.96247053]\n",
      "[0.7853419, 0.24005878, 1.002797]\n",
      "[0.7982951, 0.26616257, 0.9896092]\n",
      "[0.7862891, 0.25854582, 0.9770841]\n",
      "[0.7983221, 0.26986292, 0.98423415]\n",
      "[0.7786585, 0.25643107, 0.96511406]\n",
      "[0.76412785, 0.23375379, 0.9701271]\n",
      "[0.774734, 0.24549316, 0.973788]\n",
      "[0.7740192, 0.23686583, 0.98535794]\n",
      "[0.7940077, 0.25913963, 0.9919824]\n",
      "[0.7710678, 0.23087673, 0.98855615]\n",
      "[0.8090677, 0.2711945, 1.0041388]\n",
      "[0.7744245, 0.23947221, 0.9824957]\n",
      "[0.76409864, 0.2361267, 0.9669232]\n",
      "[0.76758003, 0.23035963, 0.9825979]\n",
      "[0.7784816, 0.2471075, 0.979341]\n",
      "[0.7751678, 0.24342893, 0.97829276]\n",
      "[0.7660623, 0.21876703, 0.9971354]\n",
      "[0.753905, 0.2171744, 0.9752701]\n",
      "[0.79905653, 0.27906457, 0.9727976]\n",
      "[0.76263106, 0.21822989, 0.9912575]\n",
      "[0.77280116, 0.23952788, 0.9797106]\n",
      "[0.7743418, 0.2444635, 0.97544956]\n",
      "[0.7783014, 0.24856268, 0.9772794]\n",
      "[0.7575475, 0.22488241, 0.9713516]\n",
      "[0.7807326, 0.24574189, 0.9864915]\n",
      "[0.81261826, 0.28290358, 0.99457735]\n",
      "[0.7818243, 0.24010573, 0.9972429]\n",
      "[0.7639656, 0.21872373, 0.99365515]\n",
      "[0.79689336, 0.25622225, 1.0033199]\n",
      "[0.74010193, 0.20072629, 0.97303843]\n",
      "[0.76536614, 0.22778605, 0.9830354]\n",
      "[0.75755143, 0.22305442, 0.97456074]\n",
      "[0.77946144, 0.253512, 0.9727514]\n",
      "[0.7649624, 0.22027619, 0.9936628]\n",
      "[0.80660313, 0.28135487, 0.9853832]\n",
      "[0.76943505, 0.230771, 0.9869792]\n",
      "[0.7827433, 0.25223133, 0.981462]\n",
      "[0.7725951, 0.23275858, 0.9904317]\n",
      "[0.8035462, 0.27252296, 0.9927452]\n",
      "[0.7918559, 0.24861725, 1.0052801]\n",
      "[0.738909, 0.1971276, 0.9766781]\n",
      "[0.7545314, 0.20938838, 0.98958874]\n",
      "[0.78520983, 0.2563771, 0.9805191]\n",
      "[0.7574627, 0.21884285, 0.9813824]\n",
      "[0.8211556, 0.2979398, 0.99018043]\n",
      "[0.7804747, 0.25004038, 0.98072654]\n",
      "[0.78273195, 0.24464054, 0.9933974]\n",
      "[0.76012504, 0.22104287, 0.98363715]\n",
      "[0.7543168, 0.21797018, 0.9766874]\n",
      "[0.789325, 0.2527552, 0.99458534]\n",
      "[0.77564454, 0.23704712, 0.99084634]\n",
      "[0.75453615, 0.21778679, 0.97757936]\n",
      "[0.778257, 0.2364018, 0.9971588]\n",
      "[0.75763375, 0.22005759, 0.9804893]\n",
      "[0.7578114, 0.22331291, 0.9760227]\n",
      "[0.76468754, 0.22133988, 0.99279493]\n",
      "[0.7644467, 0.23041843, 0.97875595]\n",
      "[0.77900153, 0.2436676, 0.98805207]\n",
      "[0.7736474, 0.23544483, 0.9897384]\n",
      "[0.73515844, 0.19412935, 0.9747935]\n",
      "[0.7919424, 0.2568675, 0.9943145]\n",
      "[0.7679444, 0.22175996, 0.9990391]\n",
      "[0.76351845, 0.2274251, 0.9817486]\n",
      "[0.753797, 0.21604227, 0.97943807]\n",
      "[0.7899618, 0.25765827, 0.98940104]\n",
      "[0.75248957, 0.20605801, 0.9919136]\n",
      "[0.7830395, 0.25405705, 0.98107046]\n",
      "[0.768745, 0.23130353, 0.986667]\n",
      "[0.7642531, 0.22224277, 0.99132985]\n",
      "[0.7644133, 0.22479229, 0.98788184]\n",
      "[0.7586675, 0.21215753, 0.9954005]\n",
      "[0.7608145, 0.21599086, 0.9940038]\n",
      "[0.75739264, 0.20698947, 1.0007216]\n",
      "[0.7494784, 0.2131015, 0.97578454]\n",
      "[0.7483715, 0.2165714, 0.968426]\n",
      "[0.76048887, 0.20934641, 1.0035574]\n",
      "[0.77887136, 0.24738061, 0.9833307]\n",
      "[0.74558306, 0.20956163, 0.97354037]\n",
      "[0.7437686, 0.20887722, 0.9709943]\n",
      "[0.73568505, 0.1997431, 0.9685855]\n",
      "[0.765132, 0.22726028, 0.9862609]\n",
      "[0.7464243, 0.2029391, 0.9853844]\n",
      "[0.7593981, 0.2313978, 0.96870136]\n",
      "[0.76959646, 0.23119824, 0.98945504]\n",
      "[0.7360042, 0.18376899, 0.9934724]\n",
      "[0.7600072, 0.20600934, 1.0081755]\n",
      "[0.7830295, 0.25256354, 0.98444337]\n",
      "[0.7696208, 0.23832595, 0.97903633]\n",
      "[0.7937776, 0.25386718, 1.0040907]\n",
      "[0.7568105, 0.19951136, 1.011742]\n",
      "[0.763328, 0.2314833, 0.9768695]\n",
      "[0.76272434, 0.2223016, 0.98948437]\n",
      "[0.7311201, 0.1972034, 0.96397066]\n",
      "[0.78248566, 0.24253893, 0.9987452]\n",
      "[0.764267, 0.23237012, 0.97760725]\n",
      "[0.75975436, 0.21371408, 0.9966131]\n",
      "[0.74287343, 0.20528491, 0.9755418]\n",
      "[0.747184, 0.2060812, 0.98301643]\n",
      "[0.7314669, 0.18342783, 0.98561233]\n",
      "[0.78502524, 0.241615, 1.0054984]\n",
      "[0.7596194, 0.22038317, 0.9865854]\n",
      "[0.74486357, 0.20091283, 0.9863305]\n",
      "[0.76524025, 0.23289078, 0.9791693]\n",
      "[0.76132077, 0.22678708, 0.98054004]\n",
      "[0.78878766, 0.26159528, 0.9833157]\n",
      "[0.7282191, 0.18418288, 0.97835165]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-023922430e30>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malphabot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(10_000):\n",
    "    picked_data = random.sample(complete_history, k=min(BATCH_SIZE, len(complete_history)))\n",
    "    #picked_data = complete_history[0:50]\n",
    "    picked_data = apply_simmetries(picked_data)\n",
    "    \n",
    "    state = []\n",
    "    policy = []\n",
    "    value = []\n",
    "    for step in picked_data:\n",
    "        policy.append(step.policy)\n",
    "        state.append(step.state)\n",
    "        value.append(step.value)\n",
    "\n",
    "    y = [np.zeros((len(state), 4)), np.zeros((len(state), 1))]\n",
    "    y[0] = policy\n",
    "    y[1] = value\n",
    "    \n",
    "    losses = alphabot.train_on_batch(np.array(state, dtype=np.float32), y)\n",
    "    print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T15:42:47.923647Z",
     "start_time": "2019-02-12T15:42:47.913682Z"
    },
    "autopy": 0
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.40908018, 0.        , 0.59091985, 0.        ], dtype=float32),\n",
       " array([0.05668016, 0.        , 0.94331984, 0.        ]),\n",
       " 1,\n",
       " array([[0.4654884]], dtype=float32))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step = complete_history[58]\n",
    "state = step.state\n",
    "value = step.value\n",
    "pol = step.policy\n",
    "policy, v = alphabot.predict(state[np.newaxis])\n",
    "policy = policy[0]\n",
    "\n",
    "mapp = np.full((5, 5), -1)\n",
    "mapp[state[..., 0] == 1] = 1\n",
    "mapp[state[..., 2] == 1] = 1\n",
    "\n",
    "valid_actions = emulator.Game(2).valid_actions(mapp, state, state[..., -1].all() == 1)\n",
    "if len(valid_actions) < 4:\n",
    "    missing_idx = [v for v in [0, 1, 2, 3] if v not in valid_actions]\n",
    "    policy[missing_idx] = 0\n",
    "             \n",
    "if sum(policy) > 0:\n",
    "    policy = policy / sum(policy)\n",
    "\n",
    "\n",
    "policy, pol, value, v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T22:43:56.318486Z",
     "start_time": "2019-02-06T22:43:52.215683Z"
    },
    "autopy": 0,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(1):\n",
    "    states = simulate_game(10, 0.8, alphabot=alphabot, eval_g=True, return_state=True)\n",
    "\n",
    "maps = []\n",
    "for state in states:\n",
    "    mapp = state[..., 0]\n",
    "    mapp += state[..., 2] * 2\n",
    "    mapp[np.where(state[..., 1] == 1)] = 3\n",
    "    mapp[np.where(state[..., 3] == 1)] = 4\n",
    "    mapp = np.expand_dims(mapp, axis=-1)\n",
    "    mapp = np.tile(mapp, [1, 1, 3])\n",
    "        \n",
    "    idx, cols, c = np.where(mapp == 1)\n",
    "    mapp[idx, cols, :] = 0\n",
    "    mapp[idx, cols, 0] = 128\n",
    "    \n",
    "    idx, cols, c = np.where(mapp == 2)\n",
    "    mapp[idx, cols, :] = 0\n",
    "    mapp[idx, cols, 1] = 128\n",
    "    \n",
    "    idx, cols, c = np.where(mapp == 3)\n",
    "    mapp[idx, cols, :] = 0\n",
    "    mapp[idx, cols, 0] = 255\n",
    "    \n",
    "    idx, cols, c = np.where(mapp == 4)\n",
    "    mapp[idx, cols, :] = 0\n",
    "    mapp[idx, cols, 1] = 255\n",
    "    \n",
    "    mapp = cv2.resize(mapp.astype(np.uint8), (480, 480), interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    maps.append(mapp)\n",
    "    \n",
    "maps = np.array(maps)\n",
    "\n",
    "#write_gif(maps, './test.gif', fps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T19:45:40.867286Z",
     "start_time": "2019-02-08T19:45:40.852540Z"
    },
    "autopy": 0
   },
   "outputs": [],
   "source": [
    "logging.getLogger().setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-10T18:26:02.001605Z",
     "start_time": "2019-02-10T18:26:01.982160Z"
    },
    "autopy": 0
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T15:38:45.792154Z",
     "start_time": "2019-02-12T15:36:13.284333Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-16:\n",
      "Process Process-13:\n",
      "Process Process-18:\n",
      "Process Process-14:\n",
      "Process Process-17:\n",
      "Process Process-15:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/adryw/miniconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/adryw/miniconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/adryw/miniconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/adryw/miniconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/adryw/miniconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/adryw/miniconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/adryw/miniconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/adryw/miniconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/adryw/miniconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-15-f2d8177e37a8>\", line 12, in sim\n",
      "    winner = play_eval(reverted, pipe, process_id)\n",
      "  File \"<ipython-input-15-f2d8177e37a8>\", line 12, in sim\n",
      "    winner = play_eval(reverted, pipe, process_id)\n",
      "  File \"<ipython-input-15-f2d8177e37a8>\", line 12, in sim\n",
      "    winner = play_eval(reverted, pipe, process_id)\n",
      "  File \"<ipython-input-8-8b8c96bb6457>\", line 23, in play_eval\n",
      "    policy = do_search(MCTS_eval_steps, s, mapp, game, tree_player0, pipe=pipe, process_id=process_id, ask_predict=ask_predict, alphabot=reverted, allow_move=allow_move)\n",
      "  File \"/home/adryw/miniconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"src/mcts.py\", line 165, in do_search\n",
      "    tree.search(s, mapp, game, pipe, ask_predict, process_id, alphabot=alphabot, allow_move=allow_move)\n",
      "  File \"<ipython-input-15-f2d8177e37a8>\", line 12, in sim\n",
      "    winner = play_eval(reverted, pipe, process_id)\n",
      "  File \"<ipython-input-8-8b8c96bb6457>\", line 23, in play_eval\n",
      "    policy = do_search(MCTS_eval_steps, s, mapp, game, tree_player0, pipe=pipe, process_id=process_id, ask_predict=ask_predict, alphabot=reverted, allow_move=allow_move)\n",
      "  File \"src/mcts.py\", line 89, in search\n",
      "    v = self.search(sp, new_map, game, pipe, ask_predict, process_id, allow_move, alphabot, head_pos)\n",
      "  File \"/home/adryw/miniconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"<ipython-input-15-f2d8177e37a8>\", line 12, in sim\n",
      "    winner = play_eval(reverted, pipe, process_id)\n",
      "  File \"/home/adryw/miniconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"src/mcts.py\", line 165, in do_search\n",
      "    tree.search(s, mapp, game, pipe, ask_predict, process_id, alphabot=alphabot, allow_move=allow_move)\n",
      "  File \"src/mcts.py\", line 89, in search\n",
      "    v = self.search(sp, new_map, game, pipe, ask_predict, process_id, allow_move, alphabot, head_pos)\n",
      "  File \"<ipython-input-8-8b8c96bb6457>\", line 23, in play_eval\n",
      "    policy = do_search(MCTS_eval_steps, s, mapp, game, tree_player0, pipe=pipe, process_id=process_id, ask_predict=ask_predict, alphabot=reverted, allow_move=allow_move)\n",
      "  File \"<ipython-input-8-8b8c96bb6457>\", line 25, in play_eval\n",
      "    policy = do_search(MCTS_eval_steps2, s, mapp, game, tree_player1, pipe=pipe, process_id=process_id, ask_predict=ask_predict, alphabot=reverted, allow_move=allow_move)\n",
      "  File \"<ipython-input-15-f2d8177e37a8>\", line 12, in sim\n",
      "    winner = play_eval(reverted, pipe, process_id)\n",
      "  File \"src/mcts.py\", line 89, in search\n",
      "    v = self.search(sp, new_map, game, pipe, ask_predict, process_id, allow_move, alphabot, head_pos)\n",
      "  File \"src/mcts.py\", line 89, in search\n",
      "    v = self.search(sp, new_map, game, pipe, ask_predict, process_id, allow_move, alphabot, head_pos)\n",
      "  File \"<ipython-input-8-8b8c96bb6457>\", line 25, in play_eval\n",
      "    policy = do_search(MCTS_eval_steps2, s, mapp, game, tree_player1, pipe=pipe, process_id=process_id, ask_predict=ask_predict, alphabot=reverted, allow_move=allow_move)\n",
      "  [Previous line repeated 7 more times]\n",
      "  File \"src/mcts.py\", line 165, in do_search\n",
      "    tree.search(s, mapp, game, pipe, ask_predict, process_id, alphabot=alphabot, allow_move=allow_move)\n",
      "  File \"src/mcts.py\", line 89, in search\n",
      "    v = self.search(sp, new_map, game, pipe, ask_predict, process_id, allow_move, alphabot, head_pos)\n",
      "  File \"src/mcts.py\", line 32, in search\n",
      "    raw_prediction = pipe.recv()\n",
      "  File \"src/mcts.py\", line 89, in search\n",
      "    v = self.search(sp, new_map, game, pipe, ask_predict, process_id, allow_move, alphabot, head_pos)\n",
      "  File \"/home/adryw/miniconda3/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  [Previous line repeated 2 more times]\n",
      "  File \"/home/adryw/miniconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"src/mcts.py\", line 32, in search\n",
      "    raw_prediction = pipe.recv()\n",
      "  File \"/home/adryw/miniconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"src/mcts.py\", line 89, in search\n",
      "    v = self.search(sp, new_map, game, pipe, ask_predict, process_id, allow_move, alphabot, head_pos)\n",
      "  File \"/home/adryw/miniconda3/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/adryw/miniconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"src/mcts.py\", line 89, in search\n",
      "    v = self.search(sp, new_map, game, pipe, ask_predict, process_id, allow_move, alphabot, head_pos)\n",
      "  File \"src/mcts.py\", line 165, in do_search\n",
      "    tree.search(s, mapp, game, pipe, ask_predict, process_id, alphabot=alphabot, allow_move=allow_move)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/adryw/miniconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"src/mcts.py\", line 89, in search\n",
      "    v = self.search(sp, new_map, game, pipe, ask_predict, process_id, allow_move, alphabot, head_pos)\n",
      "KeyboardInterrupt\n",
      "  File \"src/mcts.py\", line 89, in search\n",
      "    v = self.search(sp, new_map, game, pipe, ask_predict, process_id, allow_move, alphabot, head_pos)\n",
      "  File \"/home/adryw/miniconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"src/mcts.py\", line 89, in search\n",
      "    v = self.search(sp, new_map, game, pipe, ask_predict, process_id, allow_move, alphabot, head_pos)\n",
      "  File \"src/mcts.py\", line 165, in do_search\n",
      "    tree.search(s, mapp, game, pipe, ask_predict, process_id, alphabot=alphabot, allow_move=allow_move)\n",
      "  File \"src/mcts.py\", line 32, in search\n",
      "    raw_prediction = pipe.recv()\n",
      "  File \"/home/adryw/miniconda3/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"src/mcts.py\", line 89, in search\n",
      "    v = self.search(sp, new_map, game, pipe, ask_predict, process_id, allow_move, alphabot, head_pos)\n",
      "  File \"src/mcts.py\", line 89, in search\n",
      "    v = self.search(sp, new_map, game, pipe, ask_predict, process_id, allow_move, alphabot, head_pos)\n",
      "  File \"/home/adryw/miniconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"<ipython-input-8-8b8c96bb6457>\", line 23, in play_eval\n",
      "    policy = do_search(MCTS_eval_steps, s, mapp, game, tree_player0, pipe=pipe, process_id=process_id, ask_predict=ask_predict, alphabot=reverted, allow_move=allow_move)\n",
      "  File \"src/mcts.py\", line 165, in do_search\n",
      "    tree.search(s, mapp, game, pipe, ask_predict, process_id, alphabot=alphabot, allow_move=allow_move)\n",
      "  [Previous line repeated 4 more times]\n",
      "  File \"src/mcts.py\", line 89, in search\n",
      "    v = self.search(sp, new_map, game, pipe, ask_predict, process_id, allow_move, alphabot, head_pos)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/adryw/miniconda3/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"src/mcts.py\", line 32, in search\n",
      "    raw_prediction = pipe.recv()\n",
      "KeyboardInterrupt\n",
      "  File \"src/mcts.py\", line 89, in search\n",
      "    v = self.search(sp, new_map, game, pipe, ask_predict, process_id, allow_move, alphabot, head_pos)\n",
      "  File \"src/mcts.py\", line 89, in search\n",
      "    v = self.search(sp, new_map, game, pipe, ask_predict, process_id, allow_move, alphabot, head_pos)\n",
      "  [Previous line repeated 2 more times]\n",
      "  File \"/home/adryw/miniconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"src/mcts.py\", line 32, in search\n",
      "    raw_prediction = pipe.recv()\n",
      "  File \"/home/adryw/miniconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/adryw/miniconda3/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/adryw/miniconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/adryw/miniconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"src/mcts.py\", line 32, in search\n",
      "    raw_prediction = pipe.recv()\n",
      "  File \"/home/adryw/miniconda3/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/adryw/miniconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/adryw/miniconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-93d769017e0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mcycles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcycles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-b151e5fc8e5e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(cycles)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcycles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training cycle: %s'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mtraining_cycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-d041ba4650f6>\u001b[0m in \u001b[0;36mtraining_cycle\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Starting self-play evaluation'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mparallel_sim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Start Parallel Games\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0mmanage_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwinner_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m                 \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwinner_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-7f7cec78bfb0>\u001b[0m in \u001b[0;36mmanage_predictions\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mstates2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0mpredictions2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malphabot_best\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1167\u001b[0m                                             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1169\u001b[0;31m                                             steps=steps)\n\u001b[0m\u001b[1;32m   1170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m    292\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# History of games for training\n",
    "#complete_history = []\n",
    "\n",
    "# Game Params\n",
    "n_players = 2\n",
    "n_games = 1 #8_000 #10_000 # Simulate N games before each training\n",
    "k = 5 # Games to be stored n_games * K\n",
    "\n",
    "# Eval options\n",
    "allow_move = False\n",
    "use_eval_choice = False\n",
    "\n",
    "# Simulation Params\n",
    "num_threads = 6\n",
    "\n",
    "MCTS_steps = 70\n",
    "MCTS_eval_steps = 40\n",
    "MCTS_eval_steps2 = MCTS_eval_steps\n",
    "MCTS_alpha = 1.\n",
    "MCTS_eval_alpha = 1.\n",
    "\n",
    "# Training Params\n",
    "t_steps = 2000 # Steps of training\n",
    "eval_steps = 1 #500 # How many steps before evaluation\n",
    "eval_games = 200 # How many games to play to evaluate who's best model\n",
    "win_percent = 0.55 # Ratio of game won to become best model\n",
    "BATCH_SIZE = 512\n",
    "total_improv = 0\n",
    "\n",
    "cycles = 1000\n",
    "\n",
    "train(cycles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T16:09:56.466989Z",
     "start_time": "2019-02-05T16:09:56.463191Z"
    },
    "autopy": 0
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]),\n",
       " array([0.        , 0.14814815, 0.33333333, 0.51851852]))"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_history[506].state[..., 2], complete_history[503].policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-03T12:53:38.883498Z",
     "start_time": "2019-02-03T12:53:38.877195Z"
    },
    "autopy": 0,
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([s.state for s in complete_history[506:1000:4]])[:, :, ::-1][0, ..., 2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
