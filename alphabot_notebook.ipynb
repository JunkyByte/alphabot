{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T18:31:20.879214Z",
     "start_time": "2019-02-06T18:31:19.864815Z"
    },
    "autopy": 2
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adryw/miniconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/adryw/miniconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pickle\n",
    "import keras\n",
    "from keras.models import Model, load_model, clone_model\n",
    "from keras.utils import multi_gpu_model\n",
    "from keras.layers import *\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.regularizers import l2\n",
    "from keras.losses import binary_crossentropy\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import random\n",
    "sys.path.append('src')  # Fix for jupyter\n",
    "import src.emulator as emulator\n",
    "import src.emulator_utils as emulator_utils\n",
    "import src.emulator_vis as emulator_vis\n",
    "%matplotlib inline\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "import multiprocessing\n",
    "from multiprocessing import Event, Queue, Pipe\n",
    "from multiprocessing import Process as Thread\n",
    "import os\n",
    "import logging\n",
    "from mcts import *\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autopy": 0
   },
   "source": [
    "# Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T18:31:20.883490Z",
     "start_time": "2019-02-06T18:31:20.880761Z"
    },
    "autopy": 0
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(filename='logging.log', level=logging.INFO, format='%(asctime)s %(message)s', filemode='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autopy": 0
   },
   "source": [
    "# Model Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T18:31:21.082121Z",
     "start_time": "2019-02-06T18:31:21.077970Z"
    },
    "autopy": 0
   },
   "outputs": [],
   "source": [
    "#INPUT_SIZE = (16, 16, 5) # Map size fixed to 16x16 (2 to 3 players)\n",
    "INPUT_SIZE = (9, 9, 5) # Map size fixed to 16x16 (2 to 3 players)\n",
    "N_ACTIONS = 4\n",
    "gpus = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autopy": 0
   },
   "source": [
    "# Define the Layers Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T18:31:21.927140Z",
     "start_time": "2019-02-06T18:31:21.916149Z"
    },
    "autopy": 0
   },
   "outputs": [],
   "source": [
    "filters = 128\n",
    "\n",
    "# Convolutional Block\n",
    "def conv_block(in_layer, name, filters=filters, kernel_size=(3,3), bn=True, relu=True):\n",
    "    l = Conv2D(filters, kernel_size, use_bias = False, \n",
    "               padding='same', name = name, kernel_regularizer=l2(1e-4))(in_layer)\n",
    "    if bn:\n",
    "        l = BatchNormalization(axis=3, name = name + '_bn')(l)\n",
    "    if relu:\n",
    "        #l = Activation('relu', name = name + '_relu')(l)\n",
    "        l = LeakyReLU(name = name + '_lkrelu')(l)\n",
    "\n",
    "    return l\n",
    "\n",
    "# Residual Block\n",
    "def residual_conv(in_layer, idx, filters=filters, kernel_size=(3,3), bn=True, relu=True):\n",
    "    name = 'res_' + str(idx)\n",
    "    # Full conv block of pre-defined shape\n",
    "    l = conv_block(in_layer, name + '_conv1', filters, kernel_size=(3,3), bn=True, relu=True)\n",
    "    # Second block with skip connection\n",
    "    l = Conv2D(filters, kernel_size, use_bias = False, padding='same', \n",
    "               name = name + '_conv2', kernel_regularizer=l2(1e-4))(l)\n",
    "    if bn:\n",
    "        l = BatchNormalization(axis=3, name = name + '_conv2_bn')(l)\n",
    "    \n",
    "    l = Concatenate()([in_layer, l]) # Skip conn.\n",
    "    #l = Add()([in_layer, l]) # Skip conn.\n",
    "    \n",
    "    if relu:\n",
    "        #l = Activation('relu', name = name + '_relu')(l)\n",
    "        l = LeakyReLU(name = name + '_lkrelu')(l)\n",
    "        \n",
    "    return l\n",
    "\n",
    "def value_head(in_layer):\n",
    "    l = conv_block(in_layer, 'value_head', filters=1, kernel_size=(1,1))\n",
    "    #l = conv_block(in_layer, 'value_head', filters=32, kernel_size=(1,1))\n",
    "    l = Flatten(name = 'value_flatten')(l)\n",
    "    \n",
    "    l = Dense(128, kernel_regularizer=l2(1e-4), name = 'value_dense')(l)\n",
    "    #l = Activation('relu', name = 'value_relu')(l)\n",
    "    l = LeakyReLU(name = 'value_lkrelu')(l)\n",
    "    \n",
    "    l = BatchNormalization(axis=1, name = 'value_bn')(l)\n",
    "\n",
    "    l = Dense(1, use_bias = False, name = 'value', kernel_regularizer=l2(1e-4),\n",
    "              activation='tanh')(l) # Value output\n",
    "    return l\n",
    "\n",
    "def policy_head(in_layer):\n",
    "    l = conv_block(in_layer, 'policy_head', filters=2, kernel_size=(1,1))\n",
    "    #l = conv_block(in_layer, 'policy_head', filters=64, kernel_size=(1,1))\n",
    "    l = Flatten(name = 'policy_flatten')(l)\n",
    "    \n",
    "    l = Dense(N_ACTIONS, name = 'policy', use_bias = False, kernel_regularizer=l2(1e-4),\n",
    "              activation='softmax')(l) # Policy output\n",
    "    return l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autopy": 0
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T18:31:22.873395Z",
     "start_time": "2019-02-06T18:31:22.869583Z"
    },
    "autopy": 0
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    def declare_model():\n",
    "        n_residual = 4\n",
    "\n",
    "        input_layer = Input(INPUT_SIZE)\n",
    "        l = conv_block(input_layer, 'conv')\n",
    "        for i in range(n_residual):\n",
    "            l = residual_conv(l, idx=i + 1)\n",
    "\n",
    "        policy = policy_head(l)\n",
    "        \n",
    "        value = value_head(l)\n",
    "\n",
    "        alphabot = Model(input_layer, [policy, value])\n",
    "        return alphabot\n",
    "    \n",
    "    if gpus > 1:\n",
    "        with tf.device('/cpu:0'):\n",
    "            alphabot = declare_model()\n",
    "        alphabot_multi = multi_gpu_model(alphabot, gpus=gpus)\n",
    "        return alphabot_multi, alphabot\n",
    "    \n",
    "    alphabot = declare_model()\n",
    "    return alphabot, alphabot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T18:31:23.791038Z",
     "start_time": "2019-02-06T18:31:23.775791Z"
    },
    "autopy": 0
   },
   "outputs": [],
   "source": [
    "def policy_rot90(policy, k = 1):\n",
    "    k = k % 4\n",
    "    policy = np.array(policy)\n",
    "    for i in range(k):\n",
    "        policy = policy[..., [1, 2, 3, 0]]\n",
    "    \n",
    "    return policy\n",
    "\n",
    "def policy_flip(policy, vert=False):\n",
    "    policy = np.array(policy)\n",
    "    if vert:\n",
    "        return policy[..., [0, 3, 2, 1]]\n",
    "    \n",
    "    return policy[..., [2, 1, 0, 3]]\n",
    "\n",
    "def state_flip(state, vert=False):\n",
    "    state = np.array(state)\n",
    "    \n",
    "    if vert:\n",
    "        return state[:, ::-1]\n",
    "    return state[:, :, ::-1]\n",
    "\n",
    "def apply_simmetries(data):\n",
    "    # 90;180:270 degrees rotations\n",
    "    # 0 right, 1 down, 2 left, 3 up\n",
    "    # Flips\n",
    "    \n",
    "    train_steps = copy.copy(data)\n",
    "    \n",
    "    t_s = []\n",
    "    t_p = []\n",
    "    value = []\n",
    "    for step in train_steps:\n",
    "        t_s.append(step.state)\n",
    "        t_p.append(step.policy)\n",
    "        value.append(step.value)\n",
    "    \n",
    "    i = np.random.randint(1, 5)\n",
    "    j = np.random.randint(0, 3)\n",
    "    \n",
    "    state = np.rot90(t_s, k=i, axes=(1, 2))\n",
    "    policy = policy_rot90(t_p, k=i)\n",
    "    \n",
    "    if j == 0: # Horizontal flip\n",
    "        state = state_flip(state, vert=False)\n",
    "        policy = policy_flip(policy, vert=False)\n",
    "    elif j == 1: # Vertical flip\n",
    "        state = state_flip(state, vert=True)\n",
    "        policy = policy_flip(policy, vert=True)\n",
    "\n",
    "    steps = [TrainStep(s, v, p) for s, p, v in zip(state, policy, value)]\n",
    "\n",
    "    return steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T18:31:24.519579Z",
     "start_time": "2019-02-06T18:31:24.506642Z"
    },
    "autopy": 0,
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def manage_predictions():\n",
    "    t = 0\n",
    "    \n",
    "    while not winner_buffer.full():\n",
    "        indices1, states1 = [], []\n",
    "        indices2, states2 = [], []\n",
    "        \n",
    "        if processable_buffer.qsize() < min(num_threads, 2): # Wait until a bunch of requests are queued\n",
    "            continue\n",
    "\n",
    "        net0, net1 = [], []\n",
    "        for i in range(processable_buffer.qsize()):\n",
    "            index, state, net = processable_buffer.get()\n",
    "            if net == False:\n",
    "                if state[..., -1].all() == 0:\n",
    "                    net = 'alphabot'\n",
    "                else:\n",
    "                    net = 'alphabot_best'\n",
    "            else:\n",
    "                if state[..., -1].all() == 0:\n",
    "                    net = 'alphabot_best'\n",
    "                else:\n",
    "                    net = 'alphabot'\n",
    "                \n",
    "            if net == 'alphabot':\n",
    "                indices1.append(index)\n",
    "                states1.append(state)\n",
    "            elif net == 'alphabot_best':\n",
    "                indices2.append(index)\n",
    "                states2.append(state)\n",
    "        \n",
    "        predictions1, predictions2 = [], []\n",
    "        if len(states1) > 0:\n",
    "            states1 = np.array(states1, dtype=np.float32)\n",
    "            predictions1 = alphabot.predict(states1)\n",
    "        if len(states2) > 0:\n",
    "            states2 = np.array(states2, dtype=np.float32)\n",
    "            predictions2 = alphabot_best.predict(states2)\n",
    "\n",
    "        if len(predictions1) > 0:\n",
    "            for i, pred in enumerate(tuple(zip(predictions1[0], predictions1[1]))):\n",
    "                pipes[indices1[i]].send(dict(zip(alphabot.output_names, pred)))\n",
    "        \n",
    "        if len(predictions2) > 0:\n",
    "            for i, pred in enumerate(tuple(zip(predictions2[0], predictions2[1]))):\n",
    "                pipes[indices2[i]].send(dict(zip(alphabot.output_names, pred)))\n",
    "        \n",
    "        if time.time() - t > 30: # Every 30 secs\n",
    "            t = time.time()\n",
    "            logging.info('Finished evaluation %d games' % winner_buffer.qsize())\n",
    "        \n",
    "def simulate_games():\n",
    "    logging.debug('Starting Threads for parallel Games')\n",
    "    \n",
    "    parallel_sim(evaluation=False) # Parallel Games\n",
    "    \n",
    "    while not history_buffer.full():\n",
    "        indices, states = [], []\n",
    "        if processable_buffer.qsize() < min(num_threads, 2): # Wait until a bunch of requests are queued\n",
    "            continue\n",
    "\n",
    "        for i in range(processable_buffer.qsize()):\n",
    "            index, state, _ = processable_buffer.get()\n",
    "            indices.append(index)\n",
    "            states.append(state)\n",
    "            \n",
    "        states = np.array(states, dtype=np.float32)\n",
    "        predictions = alphabot.predict(states)\n",
    "        for i, pred in enumerate(tuple(zip(predictions[0], predictions[1]))):\n",
    "            pipes[indices[i]].send(dict(zip(alphabot.output_names, pred)))\n",
    "\n",
    "    logging.info('Finished Simulating %s games', n_games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T18:31:25.051386Z",
     "start_time": "2019-02-06T18:31:25.027430Z"
    },
    "autopy": 0,
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def play_eval(reverted=False, pipe=None, process_id=None):\n",
    "    global alphabot_best\n",
    "    global alphabot\n",
    "    \n",
    "    game = emulator.Game(2)\n",
    "    mapp = game.reset()\n",
    "  \n",
    "    tree_player0 = MCTS()\n",
    "    tree_player0.alpha = MCTS_eval_alpha\n",
    "  \n",
    "    tree_player1 = MCTS()\n",
    "    tree_player1.alpha = MCTS_eval_alpha\n",
    "\n",
    "    old_mapp = None\n",
    "    head = None\n",
    "    turn = 0\n",
    "    s = map_to_state(mapp, old_mapp, None, 0)\n",
    "    old_mapp = copy.deepcopy(mapp)\n",
    "  \n",
    "    states = []\n",
    "    policies = []\n",
    "    \n",
    "    while True:\n",
    "        states.append(np.array(s))\n",
    "        if turn == 0:\n",
    "            policy = do_search(MCTS_eval_steps, s, mapp, game, tree_player0, pipe=pipe, process_id=process_id, ask_predict=ask_predict, alphabot=reverted, allow_move=allow_move)\n",
    "        else:\n",
    "            policy = do_search(MCTS_eval_steps2, s, mapp, game, tree_player1, pipe=pipe, process_id=process_id, ask_predict=ask_predict, alphabot=reverted, allow_move=allow_move)\n",
    "\n",
    "        if not use_eval_choice:\n",
    "            choosen = np.argmax(policy)\n",
    "        else :\n",
    "            choosen = np.random.choice(4, p=policy)\n",
    "\n",
    "        policies.append(np.array(policy))\n",
    "        mapp, tmp_head = game.step(mapp, s, choosen, turn, mcts=True)\n",
    "\n",
    "        turn = 1 - turn\n",
    "        if turn == 0:  # We update the state\n",
    "            s = map_to_state(mapp, old_mapp, s, 0, head)  # TODO: Map to state\n",
    "        else:\n",
    "            head = tmp_head\n",
    "            s[..., -1] = 1\n",
    "\n",
    "        if turn == 0:\n",
    "            old_mapp = np.array(mapp)\n",
    "        \n",
    "        if game.game_ended():\n",
    "            logging.debug('GAME ENDED, %s won, %s <- reverted' % (turn, reverted))\n",
    "            if not reverted:\n",
    "                return turn\n",
    "            else:\n",
    "                return  1 - turn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T18:31:25.960818Z",
     "start_time": "2019-02-06T18:31:25.956094Z"
    },
    "autopy": 0
   },
   "outputs": [],
   "source": [
    "def train_model():        \n",
    "        picked_data = random.sample(complete_history, k=min(BATCH_SIZE, len(complete_history))) \n",
    "        picked_data = apply_simmetries(picked_data)\n",
    "        \n",
    "        state = []\n",
    "        policy = []\n",
    "        value = []\n",
    "        for step in picked_data:\n",
    "            policy.append(step.policy)\n",
    "            state.append(step.state)\n",
    "            value.append(step.value)\n",
    "            \n",
    "        y = [np.zeros((len(state), 4)), np.zeros((len(state), 1))]\n",
    "        y[0] = policy\n",
    "        y[1] = value\n",
    "        \n",
    "        losses = alphabot.train_on_batch(np.array(state, dtype=np.float32), y)\n",
    "        return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T18:31:27.129804Z",
     "start_time": "2019-02-06T18:31:27.105970Z"
    },
    "autopy": 0,
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def training_cycle():\n",
    "    global alphabot\n",
    "    global alphabot_best\n",
    "    global total_improv\n",
    "    \n",
    "    logging.info('Starting Training Cycle')\n",
    "    simulate_games()\n",
    "    \n",
    "    # history_buffer contains the games, we store them inside complete history    \n",
    "    for g in range(history_buffer.qsize()):\n",
    "        complete_history.append(history_buffer.get())\n",
    "    stop_simulation() # We can now stop the simulation (will free the memory)\n",
    "    \n",
    "    logging.info('Starting Model Training')\n",
    "    losses = [0, 0, 0] # For debug purpose\n",
    "    sum_loss = 0\n",
    "    cc = 1\n",
    "    for i in range(t_steps + 1):\n",
    "        if i % 25 == 0:\n",
    "            logging.info('Training Interaction: %s losses: %s %s', i, \n",
    "                         round(sum_loss / cc, 2), np.round(losses, 2))\n",
    "        \n",
    "        losses = train_model()\n",
    "        sum_loss += losses[0]\n",
    "        logging.debug('Losses: %s', losses)\n",
    "        \n",
    "        cc += 1\n",
    "        if i % eval_steps == 0 and i > 0:\n",
    "            cc = 1 # Reset loss counter\n",
    "            sum_loss = 0\n",
    "            wins = {'candidate' : 0, 'best' : 0}\n",
    "            n_c = {0 : 'candidate', 1 : 'best'}\n",
    "            \n",
    "            logging.info('Starting self-play evaluation')    \n",
    "            parallel_sim(evaluation=True) # Start Parallel Games\n",
    "            manage_predictions()\n",
    "            for i in range(winner_buffer.qsize()):\n",
    "                w = winner_buffer.get()\n",
    "                wins[n_c[w]] += 1 # add a win to the winner\n",
    "            stop_simulation()\n",
    "            \n",
    "            win_ratio = round(wins['candidate'] / eval_games, 2)\n",
    "            if win_ratio >= win_percent:\n",
    "                logging.info('Great! Our candidate won %s percent of games', round(win_ratio * 100))\n",
    "                total_improv += 1\n",
    "                logging.info('Our bot got better %s times', total_improv)\n",
    "                alphabot.save('alphabot_best.pickle')\n",
    "                replace_best()    \n",
    "            else:\n",
    "                logging.info('Damn! Our candidate only won %s percent of games', round(win_ratio * 100, 2))         \n",
    "                logging.info('Cloning to best')\n",
    "                reload_best()\n",
    "            \n",
    "    if len(complete_history) >= k * n_games: #* 2:\n",
    "        logging.info('Removing oldest games')\n",
    "        del complete_history[:n_games] # Delete n oldest games from history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T19:46:08.962015Z",
     "start_time": "2019-02-06T19:46:08.947940Z"
    },
    "autopy": 0
   },
   "outputs": [],
   "source": [
    "def load_best(best_model):\n",
    "    global alphabot\n",
    "    global alphabot_best\n",
    "    alphabot_best = load_model(best_model, \n",
    "                               custom_objects={'softmax_cross_entropy_with_logits' : softmax_cross_entropy_with_logits,\n",
    "                                          'categorical_weighted' : categorical_weighted})\n",
    "    alphabot = load_model(best_model, \n",
    "                               custom_objects={'softmax_cross_entropy_with_logits' : softmax_cross_entropy_with_logits,\n",
    "                                          'categorical_weighted' : categorical_weighted})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T18:31:28.404444Z",
     "start_time": "2019-02-06T18:31:28.399457Z"
    },
    "autopy": 0
   },
   "outputs": [],
   "source": [
    "def reload_best():\n",
    "    global alphabot\n",
    "    global alphabot_best\n",
    "    \n",
    "    alphabot.set_weights(alphabot_best.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T18:31:29.062549Z",
     "start_time": "2019-02-06T18:31:29.060011Z"
    },
    "autopy": 0
   },
   "outputs": [],
   "source": [
    "def replace_best():\n",
    "    global alphabot\n",
    "    global alphabot_best\n",
    "    \n",
    "    alphabot_best.set_weights(alphabot.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T18:31:29.697400Z",
     "start_time": "2019-02-06T18:31:29.694572Z"
    },
    "autopy": 0
   },
   "outputs": [],
   "source": [
    "def train(cycles):\n",
    "    global alphabot_best\n",
    "    global alphabot\n",
    "    \n",
    "    #replace_best()\n",
    "    \n",
    "    complete_history = []\n",
    "    for i in range(cycles):\n",
    "        logging.info('Training cycle: %s', i)\n",
    "        training_cycle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T18:31:30.411728Z",
     "start_time": "2019-02-06T18:31:30.394699Z"
    },
    "autopy": 0,
    "code_folding": [
     43
    ]
   },
   "outputs": [],
   "source": [
    "def ask_predict(idi, x, net=None):\n",
    "    # Adds to queue id and data from process\n",
    "    processable_buffer.put((idi, x, net))\n",
    "\n",
    "def sim(process_id, pipe, evaluation=False):\n",
    "    np.random.seed()\n",
    "    random.seed()\n",
    "    \n",
    "    if evaluation:\n",
    "        while True:\n",
    "            reverted = np.random.random() >= 0.5\n",
    "            winner = play_eval(reverted, pipe, process_id)\n",
    "            \n",
    "            try:\n",
    "                winner_buffer.put_nowait(winner)\n",
    "            except:\n",
    "                break\n",
    "    \n",
    "    else:\n",
    "        while True:\n",
    "            train_steps = simulate_game(MCTS_steps, MCTS_alpha, pipe, ask_predict, process_id)    \n",
    "        \n",
    "            try:\n",
    "                for step in train_steps:\n",
    "                    history_buffer.put_nowait(step)\n",
    "            except:\n",
    "                break\n",
    "                    \n",
    "def stop_simulation():\n",
    "    global workers\n",
    "    global history_buffer\n",
    "    global processable_buffer\n",
    "    global winner_buffer\n",
    "    global pipes\n",
    "    global child_pipes\n",
    "    \n",
    "    if 'workers' in globals() and len(workers) != 0:\n",
    "        for worker in workers:\n",
    "            worker.terminate()\n",
    "    workers = []\n",
    "    \n",
    "    for pipe in pipes:\n",
    "        pipe.close()\n",
    "\n",
    "    for pipe in child_pipes:\n",
    "        pipe.close()\n",
    "    \n",
    "    #for _ in range(history_buffer.qsize()):\n",
    "    #    try:\n",
    "    #        history_buffer.get_nowait()\n",
    "    #    except:\n",
    "    #        break\n",
    "            \n",
    "    #for _ in range(processable_buffer.qsize()):\n",
    "    #    try:\n",
    "    #        processable_buffer.get_nowait()\n",
    "    #    except:\n",
    "    #        break\n",
    "        \n",
    "    history_buffer.close()\n",
    "    processable_buffer.close()\n",
    "    winner_buffer.close()\n",
    "    \n",
    "    # Then we empty the queues\n",
    "    del history_buffer\n",
    "    del processable_buffer\n",
    "    del pipes\n",
    "    del child_pipes\n",
    "    del winner_buffer\n",
    "\n",
    "def parallel_sim(evaluation=False):\n",
    "    global workers\n",
    "    global history_buffer\n",
    "    global processable_buffer\n",
    "    global winner_buffer\n",
    "    global pipes\n",
    "    global child_pipes\n",
    "    \n",
    "    if 'workers' in globals() and len(workers) != 0:\n",
    "        stop_simulation()\n",
    "    \n",
    "    history_buffer = Queue(n_games) # This numbers can be tweaked\n",
    "    winner_buffer = Queue(eval_games)\n",
    "    processable_buffer = Queue(num_threads)\n",
    "    pipes = []\n",
    "    child_pipes = []\n",
    "    \n",
    "    workers = []\n",
    "    for i in range(num_threads):\n",
    "        parent_pipe, child_pipe = Pipe() # Pipe to communicate with childs\n",
    "        pipes.append(parent_pipe)\n",
    "        child_pipes.append(child_pipe)\n",
    "        \n",
    "        worker = Thread(target=sim, args=[i, child_pipe, evaluation])\n",
    "        worker.daemon = False\n",
    "        worker.start()\n",
    "        workers.append(worker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T18:31:31.269243Z",
     "start_time": "2019-02-06T18:31:31.263008Z"
    },
    "autopy": 0
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def softmax_cross_entropy_with_logits(y_true, y_pred):\n",
    "\n",
    "    p = y_pred\n",
    "    pi = y_true\n",
    "\n",
    "    zero = tf.zeros(shape = tf.shape(pi), dtype=tf.float32)\n",
    "    where = tf.equal(pi, zero)\n",
    "\n",
    "    negatives = tf.fill(tf.shape(pi), -100.0) \n",
    "    p = tf.where(where, negatives, p)\n",
    "\n",
    "    loss = tf.maximum(0., tf.nn.softmax_cross_entropy_with_logits(labels = pi, logits = p) - 1)\n",
    "\n",
    "    return loss\n",
    "\n",
    "def categorical_weighted(y_true, y_pred):\n",
    "    return tf.maximum(0., keras.losses.categorical_crossentropy(y_true, y_pred) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T18:31:33.610917Z",
     "start_time": "2019-02-06T18:31:32.388266Z"
    },
    "autopy": 0,
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________________________________________\n",
      "Layer (type)                        Output Shape             Param #       Connected to                         \n",
      "================================================================================================================\n",
      "input_1 (InputLayer)                (None, 9, 9, 5)          0                                                  \n",
      "________________________________________________________________________________________________________________\n",
      "conv (Conv2D)                       (None, 9, 9, 128)        5760          input_1[0][0]                        \n",
      "________________________________________________________________________________________________________________\n",
      "conv_bn (BatchNormalization)        (None, 9, 9, 128)        512           conv[0][0]                           \n",
      "________________________________________________________________________________________________________________\n",
      "conv_lkrelu (LeakyReLU)             (None, 9, 9, 128)        0             conv_bn[0][0]                        \n",
      "________________________________________________________________________________________________________________\n",
      "res_1_conv1 (Conv2D)                (None, 9, 9, 128)        147456        conv_lkrelu[0][0]                    \n",
      "________________________________________________________________________________________________________________\n",
      "res_1_conv1_bn (BatchNormalization) (None, 9, 9, 128)        512           res_1_conv1[0][0]                    \n",
      "________________________________________________________________________________________________________________\n",
      "res_1_conv1_lkrelu (LeakyReLU)      (None, 9, 9, 128)        0             res_1_conv1_bn[0][0]                 \n",
      "________________________________________________________________________________________________________________\n",
      "res_1_conv2 (Conv2D)                (None, 9, 9, 128)        147456        res_1_conv1_lkrelu[0][0]             \n",
      "________________________________________________________________________________________________________________\n",
      "res_1_conv2_bn (BatchNormalization) (None, 9, 9, 128)        512           res_1_conv2[0][0]                    \n",
      "________________________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)         (None, 9, 9, 256)        0             conv_lkrelu[0][0]                    \n",
      "                                                                           res_1_conv2_bn[0][0]                 \n",
      "________________________________________________________________________________________________________________\n",
      "res_1_lkrelu (LeakyReLU)            (None, 9, 9, 256)        0             concatenate_1[0][0]                  \n",
      "________________________________________________________________________________________________________________\n",
      "res_2_conv1 (Conv2D)                (None, 9, 9, 128)        294912        res_1_lkrelu[0][0]                   \n",
      "________________________________________________________________________________________________________________\n",
      "res_2_conv1_bn (BatchNormalization) (None, 9, 9, 128)        512           res_2_conv1[0][0]                    \n",
      "________________________________________________________________________________________________________________\n",
      "res_2_conv1_lkrelu (LeakyReLU)      (None, 9, 9, 128)        0             res_2_conv1_bn[0][0]                 \n",
      "________________________________________________________________________________________________________________\n",
      "res_2_conv2 (Conv2D)                (None, 9, 9, 128)        147456        res_2_conv1_lkrelu[0][0]             \n",
      "________________________________________________________________________________________________________________\n",
      "res_2_conv2_bn (BatchNormalization) (None, 9, 9, 128)        512           res_2_conv2[0][0]                    \n",
      "________________________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)         (None, 9, 9, 384)        0             res_1_lkrelu[0][0]                   \n",
      "                                                                           res_2_conv2_bn[0][0]                 \n",
      "________________________________________________________________________________________________________________\n",
      "res_2_lkrelu (LeakyReLU)            (None, 9, 9, 384)        0             concatenate_2[0][0]                  \n",
      "________________________________________________________________________________________________________________\n",
      "res_3_conv1 (Conv2D)                (None, 9, 9, 128)        442368        res_2_lkrelu[0][0]                   \n",
      "________________________________________________________________________________________________________________\n",
      "res_3_conv1_bn (BatchNormalization) (None, 9, 9, 128)        512           res_3_conv1[0][0]                    \n",
      "________________________________________________________________________________________________________________\n",
      "res_3_conv1_lkrelu (LeakyReLU)      (None, 9, 9, 128)        0             res_3_conv1_bn[0][0]                 \n",
      "________________________________________________________________________________________________________________\n",
      "res_3_conv2 (Conv2D)                (None, 9, 9, 128)        147456        res_3_conv1_lkrelu[0][0]             \n",
      "________________________________________________________________________________________________________________\n",
      "res_3_conv2_bn (BatchNormalization) (None, 9, 9, 128)        512           res_3_conv2[0][0]                    \n",
      "________________________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)         (None, 9, 9, 512)        0             res_2_lkrelu[0][0]                   \n",
      "                                                                           res_3_conv2_bn[0][0]                 \n",
      "________________________________________________________________________________________________________________\n",
      "res_3_lkrelu (LeakyReLU)            (None, 9, 9, 512)        0             concatenate_3[0][0]                  \n",
      "________________________________________________________________________________________________________________\n",
      "res_4_conv1 (Conv2D)                (None, 9, 9, 128)        589824        res_3_lkrelu[0][0]                   \n",
      "________________________________________________________________________________________________________________\n",
      "res_4_conv1_bn (BatchNormalization) (None, 9, 9, 128)        512           res_4_conv1[0][0]                    \n",
      "________________________________________________________________________________________________________________\n",
      "res_4_conv1_lkrelu (LeakyReLU)      (None, 9, 9, 128)        0             res_4_conv1_bn[0][0]                 \n",
      "________________________________________________________________________________________________________________\n",
      "res_4_conv2 (Conv2D)                (None, 9, 9, 128)        147456        res_4_conv1_lkrelu[0][0]             \n",
      "________________________________________________________________________________________________________________\n",
      "res_4_conv2_bn (BatchNormalization) (None, 9, 9, 128)        512           res_4_conv2[0][0]                    \n",
      "________________________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)         (None, 9, 9, 640)        0             res_3_lkrelu[0][0]                   \n",
      "                                                                           res_4_conv2_bn[0][0]                 \n",
      "________________________________________________________________________________________________________________\n",
      "res_4_lkrelu (LeakyReLU)            (None, 9, 9, 640)        0             concatenate_4[0][0]                  \n",
      "________________________________________________________________________________________________________________\n",
      "value_head (Conv2D)                 (None, 9, 9, 1)          640           res_4_lkrelu[0][0]                   \n",
      "________________________________________________________________________________________________________________\n",
      "value_head_bn (BatchNormalization)  (None, 9, 9, 1)          4             value_head[0][0]                     \n",
      "________________________________________________________________________________________________________________\n",
      "value_head_lkrelu (LeakyReLU)       (None, 9, 9, 1)          0             value_head_bn[0][0]                  \n",
      "________________________________________________________________________________________________________________\n",
      "policy_head (Conv2D)                (None, 9, 9, 2)          1280          res_4_lkrelu[0][0]                   \n",
      "________________________________________________________________________________________________________________\n",
      "value_flatten (Flatten)             (None, 81)               0             value_head_lkrelu[0][0]              \n",
      "________________________________________________________________________________________________________________\n",
      "policy_head_bn (BatchNormalization) (None, 9, 9, 2)          8             policy_head[0][0]                    \n",
      "________________________________________________________________________________________________________________\n",
      "value_dense (Dense)                 (None, 128)              10496         value_flatten[0][0]                  \n",
      "________________________________________________________________________________________________________________\n",
      "policy_head_lkrelu (LeakyReLU)      (None, 9, 9, 2)          0             policy_head_bn[0][0]                 \n",
      "________________________________________________________________________________________________________________\n",
      "value_lkrelu (LeakyReLU)            (None, 128)              0             value_dense[0][0]                    \n",
      "________________________________________________________________________________________________________________\n",
      "policy_flatten (Flatten)            (None, 162)              0             policy_head_lkrelu[0][0]             \n",
      "________________________________________________________________________________________________________________\n",
      "value_bn (BatchNormalization)       (None, 128)              512           value_lkrelu[0][0]                   \n",
      "________________________________________________________________________________________________________________\n",
      "policy (Dense)                      (None, 4)                648           policy_flatten[0][0]                 \n",
      "________________________________________________________________________________________________________________\n",
      "value (Dense)                       (None, 1)                128           value_bn[0][0]                       \n",
      "================================================================================================================\n",
      "Total params: 2,088,468\n",
      "Trainable params: 2,085,902\n",
      "Non-trainable params: 2,566\n",
      "________________________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "alphabot, _ = create_model()\n",
    "alphabot.compile(optimizer=Adam(1e-3),#SGD(1e-3, momentum=0.9),\n",
    "                          loss={'value' : 'mse', 'policy': categorical_weighted},\n",
    "                          loss_weights={'value' : 0.5, 'policy' : 0.5})\n",
    "alphabot.summary(line_length=112)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T18:31:50.227724Z",
     "start_time": "2019-02-06T18:31:46.480265Z"
    },
    "autopy": 0
   },
   "outputs": [],
   "source": [
    "#alphabot.save('alphabot_best.pickle')\n",
    "alphabot_best = load_model('alphabot_best.pickle', \n",
    "                           custom_objects={'categorical_weighted' : categorical_weighted})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T19:46:48.003607Z",
     "start_time": "2019-02-06T19:46:34.203931Z"
    },
    "autopy": 0,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "load_best('alphabot_best.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T18:31:53.603985Z",
     "start_time": "2019-02-06T18:31:53.600510Z"
    },
    "autopy": 0,
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# History of games for training\n",
    "#complete_history = []\n",
    "\n",
    "# Game Params\n",
    "n_players = 2\n",
    "n_games = 1 #5_000 #10_000 # Simulate N games before each training\n",
    "k = 10 # Games to be stored n_games * K\n",
    "\n",
    "# Eval options\n",
    "allow_move = False\n",
    "use_eval_choice = False\n",
    "\n",
    "# Simulation Params\n",
    "num_threads = 6\n",
    "\n",
    "MCTS_steps = 35\n",
    "MCTS_eval_steps = 25\n",
    "MCTS_eval_steps2 = MCTS_eval_steps\n",
    "MCTS_alpha = 1.\n",
    "MCTS_eval_alpha = 1.\n",
    "\n",
    "# Training Params\n",
    "t_steps = 900 #2000 # Steps of training\n",
    "eval_steps = 1 #300 #500 # How many steps before evaluation\n",
    "eval_games = 300 #150 # How many games to play to evaluate how's best model\n",
    "win_percent = 0.55 # Ratio of game won to become best model\n",
    "BATCH_SIZE = 256\n",
    "total_improv = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T16:58:42.472857Z",
     "start_time": "2019-02-06T16:52:26.120892Z"
    },
    "autopy": 0,
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-2306:\n",
      "Process Process-2310:\n",
      "Process Process-2309:\n",
      "Process Process-2308:\n",
      "Process Process-2305:\n",
      "Process Process-2307:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/adryw/miniconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/adryw/miniconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/adryw/miniconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/adryw/miniconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"<ipython-input-16-f2d8177e37a8>\", line 12, in sim\n",
      "    winner = play_eval(reverted, pipe, process_id)\n",
      "  File \"/home/adryw/miniconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/adryw/miniconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/adryw/miniconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-10-4884c541ba3c>\", line 26, in play_eval\n",
      "    policy = do_search(MCTS_eval_steps, s, mapp, game, tree_player0, pipe=pipe, process_id=process_id, ask_predict=ask_predict, alphabot=reverted, allow_move=allow_move)\n",
      "  File \"<ipython-input-16-f2d8177e37a8>\", line 12, in sim\n",
      "    winner = play_eval(reverted, pipe, process_id)\n",
      "  File \"src/mcts.py\", line 160, in do_search\n",
      "    tree.search(s, mapp, game, pipe, ask_predict, process_id, alphabot=alphabot, allow_move=allow_move)\n",
      "  File \"src/mcts.py\", line 84, in search\n",
      "    v = self.search(sp, new_map, game, pipe, ask_predict, process_id, allow_move, alphabot, head_pos)\n",
      "  File \"<ipython-input-10-4884c541ba3c>\", line 26, in play_eval\n",
      "    policy = do_search(MCTS_eval_steps, s, mapp, game, tree_player0, pipe=pipe, process_id=process_id, ask_predict=ask_predict, alphabot=reverted, allow_move=allow_move)\n",
      "  File \"/home/adryw/miniconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"src/mcts.py\", line 84, in search\n",
      "    v = self.search(sp, new_map, game, pipe, ask_predict, process_id, allow_move, alphabot, head_pos)\n",
      "  File \"src/mcts.py\", line 160, in do_search\n",
      "    tree.search(s, mapp, game, pipe, ask_predict, process_id, alphabot=alphabot, allow_move=allow_move)\n",
      "  File \"/home/adryw/miniconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-16-f2d8177e37a8>\", line 12, in sim\n",
      "    winner = play_eval(reverted, pipe, process_id)\n",
      "Traceback (most recent call last):\n",
      "  File \"src/mcts.py\", line 84, in search\n",
      "    v = self.search(sp, new_map, game, pipe, ask_predict, process_id, allow_move, alphabot, head_pos)\n",
      "  File \"src/mcts.py\", line 84, in search\n",
      "    v = self.search(sp, new_map, game, pipe, ask_predict, process_id, allow_move, alphabot, head_pos)\n",
      "  File \"/home/adryw/miniconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"src/mcts.py\", line 84, in search\n",
      "    v = self.search(sp, new_map, game, pipe, ask_predict, process_id, allow_move, alphabot, head_pos)\n",
      "  File \"/home/adryw/miniconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"src/mcts.py\", line 84, in search\n",
      "    v = self.search(sp, new_map, game, pipe, ask_predict, process_id, allow_move, alphabot, head_pos)\n",
      "  File \"<ipython-input-16-f2d8177e37a8>\", line 12, in sim\n",
      "    winner = play_eval(reverted, pipe, process_id)\n",
      "  File \"src/mcts.py\", line 32, in search\n",
      "    raw_prediction = pipe.recv()\n",
      "  File \"<ipython-input-10-4884c541ba3c>\", line 26, in play_eval\n",
      "    policy = do_search(MCTS_eval_steps, s, mapp, game, tree_player0, pipe=pipe, process_id=process_id, ask_predict=ask_predict, alphabot=reverted, allow_move=allow_move)\n",
      "  File \"/home/adryw/miniconda3/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/adryw/miniconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/adryw/miniconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/adryw/miniconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"<ipython-input-16-f2d8177e37a8>\", line 12, in sim\n",
      "    winner = play_eval(reverted, pipe, process_id)\n",
      "KeyboardInterrupt\n",
      "  File \"<ipython-input-10-4884c541ba3c>\", line 26, in play_eval\n",
      "    policy = do_search(MCTS_eval_steps, s, mapp, game, tree_player0, pipe=pipe, process_id=process_id, ask_predict=ask_predict, alphabot=reverted, allow_move=allow_move)\n",
      "  File \"src/mcts.py\", line 160, in do_search\n",
      "    tree.search(s, mapp, game, pipe, ask_predict, process_id, alphabot=alphabot, allow_move=allow_move)\n",
      "  File \"src/mcts.py\", line 84, in search\n",
      "    v = self.search(sp, new_map, game, pipe, ask_predict, process_id, allow_move, alphabot, head_pos)\n",
      "  File \"src/mcts.py\", line 84, in search\n",
      "    v = self.search(sp, new_map, game, pipe, ask_predict, process_id, allow_move, alphabot, head_pos)\n",
      "  File \"<ipython-input-10-4884c541ba3c>\", line 28, in play_eval\n",
      "    policy = do_search(MCTS_eval_steps2, s, mapp, game, tree_player1, pipe=pipe, process_id=process_id, ask_predict=ask_predict, alphabot=reverted, allow_move=allow_move)\n",
      "  [Previous line repeated 2 more times]\n",
      "  File \"<ipython-input-16-f2d8177e37a8>\", line 12, in sim\n",
      "    winner = play_eval(reverted, pipe, process_id)\n",
      "  File \"src/mcts.py\", line 160, in do_search\n",
      "    tree.search(s, mapp, game, pipe, ask_predict, process_id, alphabot=alphabot, allow_move=allow_move)\n",
      "  File \"src/mcts.py\", line 84, in search\n",
      "    v = self.search(sp, new_map, game, pipe, ask_predict, process_id, allow_move, alphabot, head_pos)\n",
      "  File \"src/mcts.py\", line 32, in search\n",
      "    raw_prediction = pipe.recv()\n",
      "  File \"src/mcts.py\", line 160, in do_search\n",
      "    tree.search(s, mapp, game, pipe, ask_predict, process_id, alphabot=alphabot, allow_move=allow_move)\n",
      "  File \"/home/adryw/miniconda3/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"src/mcts.py\", line 84, in search\n",
      "    v = self.search(sp, new_map, game, pipe, ask_predict, process_id, allow_move, alphabot, head_pos)\n",
      "  File \"src/mcts.py\", line 84, in search\n",
      "    v = self.search(sp, new_map, game, pipe, ask_predict, process_id, allow_move, alphabot, head_pos)\n",
      "  File \"src/mcts.py\", line 84, in search\n",
      "    v = self.search(sp, new_map, game, pipe, ask_predict, process_id, allow_move, alphabot, head_pos)\n",
      "  [Previous line repeated 2 more times]\n",
      "  File \"/home/adryw/miniconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"src/mcts.py\", line 32, in search\n",
      "    raw_prediction = pipe.recv()\n",
      "  File \"<ipython-input-10-4884c541ba3c>\", line 26, in play_eval\n",
      "    policy = do_search(MCTS_eval_steps, s, mapp, game, tree_player0, pipe=pipe, process_id=process_id, ask_predict=ask_predict, alphabot=reverted, allow_move=allow_move)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-d07c56b67da1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcycles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcycles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-25-b151e5fc8e5e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(cycles)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcycles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training cycle: %s'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mtraining_cycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-14ad6903bcee>\u001b[0m in \u001b[0;36mtraining_cycle\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Starting self-play evaluation'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mparallel_sim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Start Parallel Games\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0mmanage_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwinner_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                 \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwinner_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-c528f5bae18f>\u001b[0m in \u001b[0;36mmanage_predictions\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mstates2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0mpredictions2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malphabot_best\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1167\u001b[0m                                             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1169\u001b[0;31m                                             steps=steps)\n\u001b[0m\u001b[1;32m   1170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m    292\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"src/mcts.py\", line 160, in do_search\n",
      "    tree.search(s, mapp, game, pipe, ask_predict, process_id, alphabot=alphabot, allow_move=allow_move)\n",
      "  File \"src/mcts.py\", line 84, in search\n",
      "    v = self.search(sp, new_map, game, pipe, ask_predict, process_id, allow_move, alphabot, head_pos)\n",
      "  [Previous line repeated 3 more times]\n",
      "  File \"/home/adryw/miniconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"src/mcts.py\", line 84, in search\n",
      "    v = self.search(sp, new_map, game, pipe, ask_predict, process_id, allow_move, alphabot, head_pos)\n",
      "  File \"src/mcts.py\", line 32, in search\n",
      "    raw_prediction = pipe.recv()\n",
      "  File \"src/mcts.py\", line 84, in search\n",
      "    v = self.search(sp, new_map, game, pipe, ask_predict, process_id, allow_move, alphabot, head_pos)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/adryw/miniconda3/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/adryw/miniconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/adryw/miniconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/adryw/miniconda3/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/adryw/miniconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/adryw/miniconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"src/mcts.py\", line 84, in search\n",
      "    v = self.search(sp, new_map, game, pipe, ask_predict, process_id, allow_move, alphabot, head_pos)\n",
      "KeyboardInterrupt\n",
      "  [Previous line repeated 3 more times]\n",
      "  File \"src/mcts.py\", line 32, in search\n",
      "    raw_prediction = pipe.recv()\n",
      "  File \"/home/adryw/miniconda3/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/adryw/miniconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/adryw/miniconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"src/mcts.py\", line 84, in search\n",
      "    v = self.search(sp, new_map, game, pipe, ask_predict, process_id, allow_move, alphabot, head_pos)\n",
      "  File \"src/mcts.py\", line 84, in search\n",
      "    v = self.search(sp, new_map, game, pipe, ask_predict, process_id, allow_move, alphabot, head_pos)\n",
      "  [Previous line repeated 4 more times]\n",
      "  File \"src/mcts.py\", line 32, in search\n",
      "    raw_prediction = pipe.recv()\n",
      "  File \"/home/adryw/miniconda3/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/adryw/miniconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/adryw/miniconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "#complete_history = []\n",
    "cycles = 1000\n",
    "\n",
    "train(cycles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T11:15:12.427486Z",
     "start_time": "2019-02-04T11:15:11.964793Z"
    },
    "autopy": 0
   },
   "outputs": [],
   "source": [
    "K.set_value(alphabot.optimizer.lr, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T15:43:56.907139Z",
     "start_time": "2019-02-05T15:43:39.541703Z"
    },
    "autopy": 0,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.1583364, 1.446481, 0.6207268]\n",
      "[1.331359, 1.4504187, 0.9629259]\n",
      "[1.209579, 1.473572, 0.6963061]\n",
      "[1.164076, 1.4366484, 0.6423168]\n",
      "[1.1588454, 1.4081893, 0.6604059]\n",
      "[1.2281443, 1.4697251, 0.7375589]\n",
      "[1.0960766, 1.4094826, 0.5337554]\n",
      "[1.3415568, 1.4282053, 1.0060816]\n",
      "[1.3080968, 1.4753394, 0.89211404]\n",
      "[1.1649989, 1.448045, 0.63329995]\n",
      "[1.326799, 1.4644306, 0.94060147]\n",
      "[1.4240673, 1.3936629, 1.2059927]\n",
      "[1.1683818, 1.4462812, 0.6420899]\n",
      "[1.365388, 1.4447434, 1.0377253]\n",
      "[1.396484, 1.4784896, 1.0662558]\n",
      "[1.2087141, 1.4179596, 0.7513251]\n",
      "[1.1451406, 1.4722918, 0.56992173]\n",
      "[1.1463888, 1.4786279, 0.5661542]\n",
      "[1.082129, 1.4391775, 0.47715548]\n",
      "[1.2509357, 1.4245348, 0.8294823]\n",
      "[1.2369635, 1.4686078, 0.75753635]\n",
      "[1.1617712, 1.4352183, 0.6406163]\n",
      "[1.2207134, 1.504924, 0.68887216]\n",
      "[1.2449014, 1.4160061, 0.82624316]\n",
      "[1.2152234, 1.4736707, 0.7093023]\n",
      "[1.2662878, 1.4693744, 0.8158107]\n",
      "[1.2466354, 1.4522547, 0.79370886]\n",
      "[1.1386575, 1.4999915, 0.53010005]\n",
      "[1.2118541, 1.4471065, 0.7294631]\n",
      "[1.1510406, 1.4445523, 0.61047447]\n",
      "[1.2642107, 1.4475902, 0.83386254]\n",
      "[1.1419444, 1.5031493, 0.5338578]\n",
      "[1.1417203, 1.4607831, 0.57586485]\n",
      "[1.1801577, 1.4572195, 0.6563927]\n",
      "[1.2426178, 1.4115906, 0.82703006]\n",
      "[1.122229, 1.4370755, 0.560853]\n",
      "[1.1340868, 1.4413744, 0.58035374]\n",
      "[1.0868995, 1.4835027, 0.44393617]\n",
      "[1.050715, 1.482208, 0.37294865]\n",
      "[1.3346663, 1.4920874, 0.93105966]\n",
      "[1.3226911, 1.5057349, 0.89354974]\n",
      "[1.2787254, 1.5020447, 0.80939615]\n",
      "[1.106729, 1.3800528, 0.5874852]\n",
      "[1.0544583, 1.4338698, 0.4292121]\n",
      "[1.0939139, 1.4314289, 0.51064575]\n",
      "[1.4506036, 1.4433455, 1.2121873]\n",
      "[1.3932073, 1.5510583, 0.98975885]\n",
      "[1.1358416, 1.4489309, 0.5772276]\n",
      "[1.3952087, 1.4863523, 1.0586085]\n",
      "[1.1788862, 1.4594171, 0.6529649]\n",
      "[1.2785097, 1.5689552, 0.7427352]\n",
      "[1.4031577, 1.4917771, 1.0692677]\n",
      "[1.2091746, 1.4346284, 0.7385061]\n",
      "[1.2400278, 1.3744806, 0.8604144]\n",
      "[1.2461128, 1.4850492, 0.7620697]\n",
      "[1.3363969, 1.5320295, 0.8957112]\n",
      "[1.284849, 1.5110104, 0.81368697]\n",
      "[1.1721832, 1.4642863, 0.6351329]\n",
      "[1.3018146, 1.4439756, 0.9147588]\n",
      "[1.207384, 1.5020978, 0.6678259]\n",
      "[1.1952858, 1.4337304, 0.7120465]\n",
      "[1.2325546, 1.5536921, 0.6666706]\n",
      "[1.3208472, 1.4879035, 0.909094]\n",
      "[1.2383791, 1.527811, 0.70430434]\n",
      "[1.1640979, 1.4120157, 0.67159367]\n",
      "[1.2494493, 1.4755145, 0.7788564]\n",
      "[1.2230085, 1.4414988, 0.7600527]\n",
      "[1.260419, 1.4789686, 0.7974677]\n",
      "[1.138875, 1.5091769, 0.5242363]\n",
      "[1.1409999, 1.4694433, 0.56828684]\n",
      "[1.2683383, 1.4870801, 0.80539584]\n",
      "[1.2049845, 1.4856348, 0.6802064]\n",
      "[1.1174614, 1.4641901, 0.52668023]\n",
      "[1.2780871, 1.4800899, 0.83211005]\n",
      "[1.0977912, 1.4578512, 0.49383718]\n",
      "[1.1023186, 1.3979319, 0.5628927]\n",
      "[1.2930589, 1.5156248, 0.8267633]\n",
      "[1.1537607, 1.5920281, 0.47184733]\n",
      "[1.2165481, 1.4614357, 0.7280998]\n",
      "[1.2173288, 1.4513938, 0.7397919]\n",
      "[1.278428, 1.4965606, 0.8169134]\n",
      "[1.2747927, 1.5667555, 0.739537]\n",
      "[1.1436523, 1.4561541, 0.5879484]\n",
      "[1.2299031, 1.4149997, 0.80169475]\n",
      "[1.3530352, 1.5570915, 0.9059564]\n",
      "[1.2318659, 1.5238781, 0.69691986]\n",
      "[1.1398712, 1.4402508, 0.59664476]\n",
      "[1.1828527, 1.4395308, 0.68341184]\n",
      "[1.1163788, 1.4481932, 0.54188406]\n",
      "[1.2575237, 1.5078778, 0.7645715]\n",
      "[1.1949319, 1.4787674, 0.66857976]\n",
      "[1.2800112, 1.4156684, 0.9019164]\n",
      "[1.1345496, 1.5062646, 0.52047014]\n",
      "[1.1918485, 1.5172585, 0.62414455]\n",
      "[1.1539737, 1.4132459, 0.65247995]\n",
      "[1.0958605, 1.4410326, 0.50854015]\n",
      "[1.2143619, 1.5334563, 0.6531913]\n",
      "[1.2159729, 1.5079587, 0.6819864]\n",
      "[1.1988249, 1.403707, 0.7520149]\n",
      "[1.097256, 1.437446, 0.515208]\n",
      "[1.1640806, 1.4267983, 0.65957195]\n",
      "[1.0978289, 1.4573812, 0.49654862]\n",
      "[1.2189659, 1.469722, 0.72654444]\n",
      "[1.1414065, 1.4818125, 0.5593996]\n",
      "[1.3596884, 1.4720154, 1.0058258]\n",
      "[1.1338173, 1.4375288, 0.5886324]\n",
      "[1.3542765, 1.4675081, 0.99963206]\n",
      "[1.2117263, 1.4320563, 0.7500399]\n",
      "[1.186659, 1.4326243, 0.69939387]\n",
      "[1.1739264, 1.4291879, 0.6774212]\n",
      "[1.074077, 1.4216423, 0.4853279]\n",
      "[1.2354136, 1.4676898, 0.7620121]\n",
      "[1.085011, 1.4429849, 0.48597088]\n",
      "[1.3658413, 1.397408, 1.0932674]\n",
      "[1.1175617, 1.4075952, 0.5865755]\n",
      "[1.2325134, 1.4494424, 0.77468574]\n",
      "[1.1467392, 1.470288, 0.58234346]\n",
      "[1.1186883, 1.4666545, 0.5299268]\n",
      "[1.1395922, 1.4502847, 0.58815897]\n",
      "[1.1626823, 1.4302646, 0.6544165]\n",
      "[1.1578785, 1.4504931, 0.62463546]\n",
      "[1.236197, 1.4406028, 0.79121566]\n",
      "[1.1706787, 1.4421301, 0.65870154]\n",
      "[1.1307541, 1.4255501, 0.5954809]\n",
      "[1.1268007, 1.4526018, 0.56057036]\n",
      "[1.3210303, 1.5211464, 0.8805321]\n",
      "[1.0639846, 1.4674678, 0.42016643]\n",
      "[1.1547982, 1.5032959, 0.56601214]\n",
      "[1.0683886, 1.4478326, 0.4487036]\n",
      "[1.080985, 1.447178, 0.47459698]\n",
      "[1.2027032, 1.4721966, 0.6930609]\n",
      "[1.128842, 1.4557292, 0.56184995]\n",
      "[1.0072571, 1.3924634, 0.3819878]\n",
      "[1.0501902, 1.4328644, 0.42749453]\n",
      "[1.2166519, 1.4498578, 0.7434659]\n",
      "[1.0319787, 1.4268528, 0.39716575]\n",
      "[1.1119529, 1.4102566, 0.5737491]\n",
      "[1.0731024, 1.4535613, 0.45278412]\n",
      "[1.0843432, 1.4442883, 0.4845801]\n",
      "[1.0581658, 1.4499705, 0.42658436]\n",
      "[1.1797799, 1.4786005, 0.64122164]\n",
      "[1.0226262, 1.4462658, 0.35928625]\n",
      "[1.0172393, 1.4029738, 0.39184335]\n",
      "[1.0246791, 1.4215195, 0.3882177]\n",
      "[1.3434846, 1.4387655, 1.0086238]\n",
      "[1.0635614, 1.4087328, 0.47885045]\n",
      "[1.0201674, 1.4102039, 0.39063346]\n",
      "[1.0574925, 1.4437032, 0.43182153]\n",
      "[1.2037249, 1.4491369, 0.71888983]\n",
      "[1.132878, 1.4431529, 0.58320975]\n",
      "[1.0170736, 1.469468, 0.32531026]\n",
      "[1.2690226, 1.4625224, 0.8361793]\n",
      "[1.1964077, 1.4320209, 0.72147524]\n",
      "[1.0123451, 1.4074492, 0.37794667]\n",
      "[1.0884547, 1.4826312, 0.45500633]\n",
      "[0.9927648, 1.4138836, 0.3323948]\n",
      "[1.0749912, 1.3963646, 0.5143811]\n",
      "[1.1108023, 1.4343987, 0.54797745]\n",
      "[1.187246, 1.4685625, 0.6667095]\n",
      "[1.0198791, 1.466636, 0.33391]\n",
      "[1.2282726, 1.4224054, 0.79493785]\n",
      "[1.0880717, 1.481199, 0.45575505]\n",
      "[1.0170428, 1.3948821, 0.40003145]\n",
      "[1.3451731, 1.4309268, 1.020268]\n",
      "[1.0922539, 1.4130303, 0.5323452]\n",
      "[1.1074374, 1.4623373, 0.5134228]\n",
      "[1.1004062, 1.4532292, 0.5084847]\n",
      "[1.1356503, 1.4636078, 0.5686092]\n",
      "[1.0411574, 1.4304549, 0.4127872]\n",
      "[1.0736215, 1.4181528, 0.4900259]\n",
      "[1.0748061, 1.4168252, 0.49372694]\n",
      "[1.0697875, 1.4435382, 0.45697933]\n",
      "[1.1636195, 1.4430573, 0.6451229]\n",
      "[0.9420266, 1.402231, 0.24275884]\n",
      "[0.98441917, 1.4457059, 0.2840616]\n",
      "[1.1302215, 1.4459246, 0.57544065]\n",
      "[1.1358751, 1.4290962, 0.6035711]\n",
      "[1.0719494, 1.4565783, 0.44823384]\n",
      "[0.943747, 1.395941, 0.25246364]\n",
      "[1.0988683, 1.4736233, 0.4850224]\n",
      "[1.0667449, 1.3849256, 0.50947326]\n",
      "[1.1690146, 1.4638543, 0.63508403]\n",
      "[1.0717432, 1.4355431, 0.46885094]\n",
      "[1.0395694, 1.4013624, 0.43867844]\n",
      "[1.2903037, 1.460681, 0.88082135]\n",
      "[1.191705, 1.4935778, 0.65071785]\n",
      "[1.0435044, 1.3872364, 0.4606424]\n",
      "[0.99718976, 1.375671, 0.37955412]\n",
      "[0.97533923, 1.4927495, 0.21873915]\n",
      "[1.0531842, 1.4526362, 0.41450113]\n",
      "[1.0518006, 1.4149549, 0.44937593]\n",
      "[1.1721177, 1.4268516, 0.67807657]\n",
      "[1.0450433, 1.4646492, 0.38609505]\n",
      "[1.2216241, 1.5062907, 0.69758224]\n",
      "[1.196942, 1.4116753, 0.74280494]\n",
      "[1.1848515, 1.4534035, 0.67686605]\n",
      "[1.117268, 1.3955202, 0.59955263]\n",
      "[1.0490055, 1.4325953, 0.42592067]\n",
      "[1.0370945, 1.4280438, 0.4066209]\n",
      "[1.0769877, 1.4356189, 0.4788055]\n",
      "[1.0915692, 1.4673836, 0.47617796]\n",
      "[1.0825951, 1.4249645, 0.50062764]\n",
      "[1.091412, 1.4591439, 0.48406485]\n",
      "[1.0565517, 1.3902723, 0.48320138]\n",
      "[1.044693, 1.4054552, 0.4442881]\n",
      "[1.0135108, 1.4960456, 0.29131973]\n",
      "[1.055594, 1.4661499, 0.40536925]\n",
      "[1.129906, 1.4791601, 0.54097354]\n",
      "[0.9514133, 1.444094, 0.21904321]\n",
      "[0.9865861, 1.4875079, 0.24596487]\n",
      "[1.0635191, 1.4300735, 0.45725858]\n",
      "[0.95280623, 1.4542751, 0.21162722]\n",
      "[0.99556273, 1.4226286, 0.3287853]\n",
      "[1.1555979, 1.5307114, 0.54076946]\n",
      "[1.1008449, 1.5323204, 0.42964932]\n",
      "[0.9285807, 1.4167578, 0.20067543]\n",
      "[1.004106, 1.4807445, 0.2877297]\n",
      "[1.0470781, 1.4393625, 0.4150479]\n",
      "[0.97295034, 1.3822681, 0.32388106]\n",
      "[1.1476492, 1.5051575, 0.5503792]\n",
      "[0.932897, 1.4224893, 0.20353329]\n",
      "[1.0388784, 1.402914, 0.4350594]\n",
      "[1.1317571, 1.5175568, 0.50616395]\n",
      "[1.158999, 1.5171432, 0.56105196]\n",
      "[1.1763784, 1.4637313, 0.64920884]\n",
      "[0.9918666, 1.4150757, 0.32882243]\n",
      "[1.0938084, 1.4703236, 0.47743678]\n",
      "[1.0262834, 1.4832782, 0.32940894]\n",
      "[0.9542393, 1.4210961, 0.24747841]\n",
      "[0.9618981, 1.4252036, 0.25866583]\n",
      "[1.0102115, 1.5532988, 0.22717848]\n",
      "[1.0610803, 1.4447639, 0.437438]\n",
      "[0.8983932, 1.4247671, 0.13205013]\n",
      "[1.1997917, 1.5298753, 0.6297319]\n",
      "[1.0744246, 1.5495545, 0.3593145]\n",
      "[1.021516, 1.44848, 0.35456628]\n",
      "[1.1530484, 1.595576, 0.4705292]\n",
      "[0.9427789, 1.4778757, 0.1676817]\n",
      "[0.9811632, 1.4948763, 0.2274401]\n",
      "[0.9708744, 1.4682679, 0.23346189]\n",
      "[1.0392282, 1.4762409, 0.36218935]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.1077349, 1.426611, 0.5488308]\n",
      "[1.128782, 1.4809525, 0.53658205]\n",
      "[1.0053349, 1.4577618, 0.3128789]\n",
      "[1.1363585, 1.4828447, 0.54984343]\n",
      "[1.0767553, 1.4569311, 0.45654386]\n",
      "[1.1495633, 1.4893489, 0.5697256]\n",
      "[1.0929075, 1.4614887, 0.48424965]\n",
      "[1.0910349, 1.5019503, 0.44001088]\n",
      "[1.0323409, 1.4724289, 0.35210967]\n",
      "[1.0044079, 1.4322128, 0.33642077]\n",
      "[0.98479426, 1.4211771, 0.30818796]\n",
      "[0.88544625, 1.4318893, 0.09873828]\n",
      "[1.0326995, 1.499598, 0.32549775]\n",
      "[1.0039341, 1.4403822, 0.3271491]\n",
      "[0.9628965, 1.4283788, 0.25705153]\n",
      "[1.1579598, 1.4651093, 0.61042774]\n",
      "[0.90291744, 1.4109294, 0.15450667]\n",
      "[0.9473989, 1.472036, 0.18235049]\n",
      "[0.9774379, 1.4263264, 0.28813177]\n",
      "[0.9569534, 1.4122491, 0.26124322]\n",
      "[1.0729852, 1.4608078, 0.44475755]\n",
      "[0.93858117, 1.4660792, 0.17069337]\n",
      "[1.0351478, 1.4290572, 0.40086967]\n",
      "[1.0629655, 1.4681504, 0.41743517]\n",
      "[1.0566732, 1.4706595, 0.4023657]\n",
      "[0.98024964, 1.4077466, 0.3124576]\n",
      "[1.0525099, 1.4757541, 0.38899714]\n",
      "[0.9478945, 1.4150343, 0.240513]\n",
      "[0.96371955, 1.4672663, 0.2199586]\n",
      "[0.99119025, 1.4572268, 0.2849676]\n",
      "[0.9755317, 1.4317353, 0.27917397]\n",
      "[1.0169202, 1.4100957, 0.38362482]\n",
      "[0.954625, 1.4081678, 0.26099703]\n",
      "[0.9225966, 1.4423022, 0.16284049]\n",
      "[0.9646912, 1.5077983, 0.18157116]\n",
      "[0.99550223, 1.4899472, 0.26108423]\n",
      "[0.94053173, 1.4261723, 0.21495838]\n",
      "[1.010893, 1.3632482, 0.4186461]\n",
      "[0.8934619, 1.4196739, 0.1273987]\n",
      "[1.0608946, 1.5133979, 0.36858088]\n",
      "[1.080508, 1.5521698, 0.36907646]\n",
      "[1.0929726, 1.4674275, 0.47878823]\n",
      "[1.1354975, 1.5049345, 0.5263692]\n",
      "[0.99642247, 1.4387902, 0.31440157]\n",
      "[0.9471726, 1.4318969, 0.22283304]\n",
      "[1.0596925, 1.4763558, 0.40345442]\n",
      "[0.90722257, 1.4041712, 0.17073923]\n",
      "[1.0278785, 1.4741086, 0.34215635]\n",
      "[1.0409001, 1.4661642, 0.37618467]\n",
      "[0.98390657, 1.4431624, 0.28524333]\n",
      "[0.95892906, 1.5196432, 0.15885027]\n",
      "[1.0320511, 1.4678295, 0.35695362]\n",
      "[0.97547615, 1.5117608, 0.19991942]\n",
      "[0.8682148, 1.4159031, 0.08130254]\n",
      "[0.9145858, 1.4300766, 0.15992115]\n",
      "[0.9244847, 1.4480505, 0.16179666]\n",
      "[0.981097, 1.4455936, 0.2775313]\n",
      "[0.8811203, 1.4132831, 0.10994291]\n",
      "[0.9648076, 1.4473383, 0.24331963]\n",
      "[0.9164715, 1.4320688, 0.1619778]\n",
      "[0.8507642, 1.4125884, 0.05010671]\n",
      "[1.0263352, 1.50524, 0.30866402]\n",
      "[0.9753615, 1.456106, 0.25591886]\n",
      "[0.8688702, 1.3809614, 0.11814815]\n",
      "[0.9783397, 1.4378247, 0.2802916]\n",
      "[0.89084065, 1.3918865, 0.1512994]\n",
      "[1.0029671, 1.4811168, 0.2863893]\n",
      "[0.94596213, 1.4559848, 0.197573]\n",
      "[0.89399165, 1.423662, 0.12601554]\n",
      "[1.0573726, 1.5122559, 0.36424333]\n",
      "[0.8914731, 1.406273, 0.13848683]\n",
      "[1.0409737, 1.4568663, 0.38695475]\n",
      "[0.8905148, 1.3727853, 0.17017901]\n",
      "[0.88558453, 1.4378284, 0.09533546]\n",
      "[0.87642604, 1.4386333, 0.07627557]\n",
      "[1.117874, 1.4777157, 0.5201516]\n",
      "[0.97199523, 1.4306595, 0.27551073]\n",
      "[1.0237546, 1.4373205, 0.3724292]\n",
      "[0.9667713, 1.4138334, 0.28200874]\n",
      "[0.90342087, 1.4415777, 0.1276182]\n",
      "[0.9160266, 1.4174058, 0.17705464]\n",
      "[0.91409904, 1.394477, 0.19618168]\n",
      "[1.0219398, 1.3683814, 0.4380101]\n",
      "[0.8943336, 1.418993, 0.1322326]\n",
      "[0.89673007, 1.4483887, 0.107673466]\n",
      "[0.9273203, 1.4233375, 0.19394852]\n",
      "[0.99794304, 1.4386008, 0.319976]\n",
      "[0.9141005, 1.4174223, 0.17351352]\n",
      "[1.1041065, 1.4280344, 0.54295695]\n",
      "[0.8579302, 1.4027417, 0.07594113]\n",
      "[1.0023091, 1.4777361, 0.2897457]\n",
      "[0.9589499, 1.3874013, 0.2934003]\n",
      "[0.9350473, 1.4368168, 0.1962203]\n",
      "[0.8722642, 1.4084266, 0.09908749]\n",
      "[0.8880613, 1.4562895, 0.0828667]\n",
      "[0.8856262, 1.3750224, 0.15931517]\n",
      "[0.9044305, 1.4269555, 0.14504537]\n",
      "[0.9353252, 1.4419158, 0.19193229]\n",
      "[0.8555554, 1.3942924, 0.08007479]\n",
      "[0.97631687, 1.4487829, 0.2671681]\n",
      "[0.91293454, 1.4637289, 0.12552077]\n",
      "[0.88898253, 1.4242942, 0.11711672]\n",
      "[0.8957591, 1.3903747, 0.16465487]\n",
      "[0.9303864, 1.4035714, 0.2207768]\n",
      "[0.96312696, 1.4534006, 0.23649123]\n",
      "[0.8523488, 1.3965917, 0.07180092]\n",
      "[0.92599416, 1.416369, 0.19936442]\n",
      "[0.9197659, 1.4414725, 0.16184756]\n",
      "[0.8998341, 1.4104004, 0.15309379]\n",
      "[0.93491423, 1.4206415, 0.2130504]\n",
      "[0.9340999, 1.4206285, 0.21147189]\n",
      "[0.95207566, 1.4314768, 0.23661458]\n",
      "[0.90274125, 1.4391676, 0.13029453]\n",
      "[0.9498866, 1.4435222, 0.22027075]\n",
      "[1.0097914, 1.4075477, 0.37609625]\n",
      "[0.9187816, 1.4516544, 0.15000522]\n",
      "[1.0117227, 1.3976824, 0.3898915]\n",
      "[1.0138777, 1.4539993, 0.3379131]\n",
      "[1.0194926, 1.4254206, 0.377748]\n",
      "[0.9155707, 1.4039992, 0.1913484]\n",
      "[1.0325649, 1.4185451, 0.4108131]\n",
      "[0.9986633, 1.4223526, 0.33922094]\n",
      "[0.94604474, 1.5092555, 0.14709637]\n",
      "[1.005525, 1.4624329, 0.31289548]\n",
      "[1.0429718, 1.4669616, 0.3832756]\n",
      "[1.0077691, 1.4554706, 0.3243746]\n",
      "[0.89534175, 1.4280999, 0.12689863]\n",
      "[0.9197595, 1.3958063, 0.20803376]\n",
      "[0.98956084, 1.4223853, 0.3210637]\n",
      "[0.9795263, 1.49312, 0.23026714]\n",
      "[1.0408874, 1.455587, 0.39053303]\n",
      "[1.0345246, 1.4043716, 0.42903665]\n",
      "[1.0793747, 1.432406, 0.49071786]\n",
      "[0.94833213, 1.4069729, 0.25408307]\n",
      "[0.9832674, 1.4243984, 0.3065458]\n",
      "[0.87860787, 1.4394038, 0.082239285]\n",
      "[0.97379297, 1.4477085, 0.26432472]\n",
      "[0.8670637, 1.3873916, 0.11120561]\n",
      "[0.95915025, 1.4140394, 0.26875725]\n",
      "[0.9902864, 1.4153678, 0.329732]\n",
      "[0.90128815, 1.4208727, 0.14626783]\n",
      "[0.9162237, 1.4030061, 0.19404641]\n",
      "[0.8563288, 1.376826, 0.10048076]\n",
      "[0.88994926, 1.4148531, 0.12974483]\n",
      "[0.91032594, 1.4385409, 0.14686646]\n",
      "[0.88393396, 1.4110355, 0.12164699]\n",
      "[0.9689796, 1.4436991, 0.2591365]\n",
      "[0.93664217, 1.4132521, 0.22497362]\n",
      "[0.8947091, 1.3951123, 0.15931292]\n",
      "[0.8788387, 1.4095784, 0.11317179]\n",
      "[0.8939086, 1.4136708, 0.13928762]\n",
      "[0.9283005, 1.4641494, 0.15766405]\n",
      "[0.9215724, 1.4266889, 0.18174183]\n",
      "[0.8703182, 1.4068812, 0.09911238]\n",
      "[0.9000902, 1.3987136, 0.16689539]\n",
      "[1.0244722, 1.4132389, 0.4012062]\n",
      "[0.90183336, 1.3492373, 0.22000545]\n",
      "[0.9465081, 1.4151714, 0.24349767]\n",
      "[0.875451, 1.3916461, 0.12498658]\n",
      "[0.89792573, 1.401215, 0.16044535]\n",
      "[0.9421221, 1.4708195, 0.17931187]\n",
      "[0.9160723, 1.3971792, 0.20093212]\n",
      "[0.97692686, 1.3630557, 0.35684037]\n",
      "[0.9884541, 1.4731954, 0.2698249]\n",
      "[0.860173, 1.39622, 0.09030238]\n",
      "[0.8810613, 1.4366163, 0.091742754]\n",
      "[0.8854674, 1.4058473, 0.13138184]\n",
      "[0.9336427, 1.3923864, 0.24125138]\n",
      "[0.8743668, 1.4405218, 0.07461614]\n",
      "[1.0219077, 1.4286646, 0.3816048]\n",
      "[0.9171347, 1.3839192, 0.21685112]\n",
      "[0.91468567, 1.4017487, 0.19416559]\n",
      "[0.9096009, 1.4505646, 0.13521554]\n",
      "[0.9207002, 1.4414791, 0.16653122]\n",
      "[1.0134108, 1.4083853, 0.3850777]\n",
      "[0.9099967, 1.460998, 0.12566742]\n",
      "[0.83923805, 1.3725623, 0.07261342]\n",
      "[0.87922263, 1.4279737, 0.097198345]\n",
      "[0.91064066, 1.4138254, 0.1742119]\n",
      "[0.8383597, 1.379567, 0.063941315]\n",
      "[0.8889568, 1.4133406, 0.1313986]\n",
      "[0.89708537, 1.3979697, 0.16306883]\n",
      "[0.99152744, 1.4518199, 0.298149]\n",
      "[0.92664224, 1.4715097, 0.14873269]\n",
      "[0.9119902, 1.3861678, 0.20480943]\n",
      "[0.9888682, 1.4496067, 0.2951635]\n",
      "[0.93173206, 1.4201682, 0.21036744]\n",
      "[0.90684426, 1.4358138, 0.14498621]\n",
      "[1.003793, 1.4187297, 0.35601217]\n",
      "[1.0111338, 1.3990877, 0.39038152]\n",
      "[0.99240327, 1.4415405, 0.31051397]\n",
      "[0.9106814, 1.4241672, 0.16448231]\n",
      "[0.9700413, 1.4464538, 0.26094848]\n",
      "[0.9400053, 1.4669535, 0.18040669]\n",
      "[0.8936963, 1.4491252, 0.10564524]\n",
      "[0.89950585, 1.3981891, 0.1682272]\n",
      "[0.94323367, 1.4426506, 0.21124604]\n",
      "[0.8410336, 1.3555369, 0.093981735]\n",
      "[0.8814009, 1.4145811, 0.11569445]\n",
      "[0.9063416, 1.4328356, 0.14734407]\n",
      "[0.8783915, 1.4110945, 0.1132098]\n",
      "[0.9919624, 1.3908055, 0.36067098]\n",
      "[1.0369174, 1.4216163, 0.41980508]\n",
      "[0.960469, 1.3852944, 0.3032687]\n",
      "[0.8480839, 1.4075072, 0.056327827]\n",
      "[0.96312803, 1.4476683, 0.24630097]\n",
      "[0.8233936, 1.3647114, 0.049839336]\n",
      "[0.943907, 1.4540277, 0.20160525]\n",
      "[0.85926044, 1.380583, 0.105817825]\n",
      "[0.84626555, 1.4139823, 0.046493307]\n",
      "[0.94159895, 1.422405, 0.22880486]\n",
      "[0.94364274, 1.4436977, 0.21167015]\n",
      "[0.914208, 1.4175253, 0.1790404]\n",
      "[0.89753383, 1.432325, 0.1309525]\n",
      "[0.8361742, 1.37859, 0.062024914]\n",
      "[0.8743238, 1.3922917, 0.12467848]\n",
      "[0.903088, 1.3685508, 0.2060056]\n",
      "[0.8764388, 1.4239595, 0.09736]\n",
      "[0.85997105, 1.4251368, 0.063309446]\n",
      "[0.87378573, 1.4214487, 0.09469132]\n",
      "[0.8421126, 1.3983502, 0.054511115]\n",
      "[0.8508543, 1.3945858, 0.07582982]\n",
      "[0.94124126, 1.4156754, 0.23559122]\n",
      "[0.92971677, 1.3821778, 0.24611491]\n",
      "[0.8643357, 1.4486597, 0.048947528]\n",
      "[0.8984912, 1.4336835, 0.13231324]\n",
      "[0.8367489, 1.3944461, 0.048147514]\n",
      "[0.9655706, 1.4243734, 0.27594742]\n",
      "[0.9296606, 1.4683233, 0.16026004]\n",
      "[0.8568417, 1.4050174, 0.07801102]\n",
      "[0.8877535, 1.4294875, 0.115448475]\n",
      "[0.9424604, 1.4465058, 0.20792907]\n",
      "[0.91218114, 1.4561174, 0.13784555]\n",
      "[0.9006381, 1.501145, 0.06982072]\n",
      "[0.858175, 1.4070671, 0.07906416]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93271863, 1.4344535, 0.2008587]\n",
      "[0.8318081, 1.3798126, 0.053772457]\n",
      "[0.9447155, 1.4218234, 0.23767027]\n",
      "[0.8865703, 1.3670175, 0.17627962]\n",
      "[0.84903854, 1.3684036, 0.099922866]\n",
      "[0.9449357, 1.4274201, 0.23279248]\n",
      "[0.9018521, 1.428623, 0.14551418]\n",
      "[0.9490514, 1.46156, 0.20706443]\n",
      "[0.83064735, 1.3281784, 0.10372459]\n",
      "[0.8590277, 1.4169012, 0.07184754]\n",
      "[0.96876293, 1.4382551, 0.2700479]\n",
      "[0.88658136, 1.4193282, 0.12469597]\n",
      "[0.93059134, 1.3886297, 0.2434997]\n",
      "[0.8895987, 1.39657, 0.1536583]\n",
      "[0.8688957, 1.4132872, 0.09561723]\n",
      "[0.9276795, 1.4328805, 0.1936716]\n",
      "[0.8600406, 1.3950293, 0.09632321]\n",
      "[0.91161925, 1.4615555, 0.13303375]\n",
      "[0.9077297, 1.3908076, 0.19608387]\n",
      "[1.039326, 1.4996051, 0.35056028]\n",
      "[0.8990393, 1.49244, 0.07723526]\n",
      "[0.95898026, 1.4760132, 0.21362877]\n",
      "[0.83877516, 1.4120436, 0.037274383]\n",
      "[0.9226861, 1.424116, 0.19311292]\n",
      "[0.9712648, 1.462036, 0.2524418]\n",
      "[0.9161403, 1.4718732, 0.13244843]\n",
      "[0.8643099, 1.4342909, 0.06646303]\n",
      "[0.92989296, 1.4397804, 0.1922318]\n",
      "[0.84677505, 1.4054078, 0.060458325]\n",
      "[0.92733365, 1.4374158, 0.1896578]\n",
      "[0.87680286, 1.4266871, 0.099416494]\n",
      "[0.82401544, 1.3988209, 0.021798188]\n",
      "[0.9114356, 1.386303, 0.20924482]\n",
      "[0.8969716, 1.4245403, 0.1421648]\n",
      "[0.90751743, 1.4352493, 0.15263174]\n",
      "[0.8950142, 1.4747132, 0.08824335]\n",
      "[0.8680259, 1.4386797, 0.07038182]\n",
      "[0.9129321, 1.4211203, 0.17783275]\n",
      "[0.8612766, 1.4128361, 0.082883745]\n",
      "[0.91860265, 1.4903551, 0.1200946]\n",
      "[0.9293409, 1.4774791, 0.15452446]\n",
      "[0.94342077, 1.442061, 0.21818021]\n",
      "[0.90132004, 1.4775524, 0.09856395]\n",
      "[0.96351117, 1.5024467, 0.1981267]\n",
      "[0.95560867, 1.3818643, 0.3029791]\n",
      "[0.86424434, 1.4140227, 0.08816373]\n",
      "[0.8818781, 1.3775325, 0.15999192]\n",
      "[0.9431755, 1.4436868, 0.2164998]\n",
      "[0.9740408, 1.4603745, 0.2616067]\n",
      "[0.9035879, 1.4412091, 0.13992631]\n",
      "[0.9430343, 1.4622178, 0.1978676]\n",
      "[0.8672072, 1.4219949, 0.08649126]\n",
      "[0.9321718, 1.4607615, 0.1777088]\n",
      "[0.92739683, 1.40976, 0.2192166]\n",
      "[0.8727894, 1.3916769, 0.12814051]\n",
      "[0.8566483, 1.3894348, 0.09815706]\n",
      "[0.8516185, 1.419102, 0.05848909]\n",
      "[0.84092474, 1.3878205, 0.06844496]\n",
      "[0.8824688, 1.3846073, 0.15481222]\n",
      "[0.8853598, 1.4412932, 0.10397549]\n",
      "[0.8569128, 1.4037592, 0.084686406]\n",
      "[0.86955696, 1.4439111, 0.069897726]\n",
      "[0.9744458, 1.475738, 0.24792802]\n",
      "[0.8896836, 1.4382343, 0.115989305]\n",
      "[0.86592215, 1.4262187, 0.080565505]\n",
      "[0.93444663, 1.4011127, 0.24280427]\n",
      "[0.96036386, 1.4275551, 0.2682824]\n",
      "[0.82428503, 1.4034479, 0.020318039]\n",
      "[0.89319575, 1.4165143, 0.14516026]\n",
      "[1.0175383, 1.4504038, 0.36004138]\n",
      "[0.8367727, 1.4243454, 0.024649143]\n",
      "[0.8507, 1.4335765, 0.04334841]\n",
      "[0.8303817, 1.4066846, 0.029677615]\n",
      "[0.81196475, 1.3717815, 0.027821068]\n",
      "[0.86568177, 1.3973444, 0.10976756]\n",
      "[0.8694465, 1.4052511, 0.109468676]\n",
      "[0.88507, 1.4157231, 0.13032404]\n",
      "[0.84058, 1.4167223, 0.04042514]\n",
      "[0.92458713, 1.4440122, 0.18122834]\n",
      "[0.942974, 1.4516606, 0.21043424]\n",
      "[0.9400889, 1.396264, 0.2601379]\n",
      "[0.9173147, 1.3852181, 0.22570878]\n",
      "[0.82863456, 1.3849614, 0.048669163]\n",
      "[0.9089337, 1.4181455, 0.17614207]\n",
      "[0.8694281, 1.4330635, 0.08226484]\n",
      "[0.9273309, 1.4325025, 0.19868028]\n",
      "[0.87736124, 1.4302291, 0.10106268]\n",
      "[1.0263325, 1.4428914, 0.3863926]\n",
      "[0.9055703, 1.4282894, 0.15952086]\n",
      "[0.9380614, 1.4172478, 0.23559302]\n",
      "[0.889504, 1.4295757, 0.12619677]\n",
      "[0.955086, 1.4315104, 0.25547156]\n",
      "[0.8922216, 1.4616908, 0.09960603]\n",
      "[0.8785779, 1.41733, 0.11672391]\n",
      "[0.8936208, 1.4295553, 0.1346302]\n",
      "[0.87903523, 1.4435488, 0.091516346]\n",
      "[0.8670346, 1.4095359, 0.10158363]\n",
      "[0.89279765, 1.4787825, 0.08392372]\n",
      "[1.0206096, 1.4750446, 0.3433512]\n",
      "[0.94918066, 1.4151381, 0.26046792]\n",
      "[0.8856846, 1.4626886, 0.08599515]\n",
      "[0.8768438, 1.4700919, 0.06098236]\n",
      "[0.86066806, 1.4040638, 0.094732136]\n",
      "[0.8750957, 1.4195311, 0.10819612]\n",
      "[0.83951396, 1.363967, 0.09267495]\n",
      "[0.87919456, 1.4315659, 0.10451573]\n",
      "[0.8548259, 1.4322493, 0.05517682]\n",
      "[0.89922374, 1.4282997, 0.1480065]\n",
      "[0.88296944, 1.4430318, 0.10085228]\n",
      "[0.879977, 1.4027599, 0.1352281]\n",
      "[0.8927368, 1.3998791, 0.1637164]\n",
      "[0.8746827, 1.4106433, 0.11693165]\n",
      "[0.86639434, 1.4149051, 0.09617922]\n",
      "[0.92329615, 1.4668698, 0.15810403]\n",
      "[0.8402265, 1.402691, 0.05623001]\n",
      "[0.9301815, 1.4323779, 0.20654166]\n",
      "[0.8242183, 1.3932855, 0.03379775]\n",
      "[0.8942383, 1.439361, 0.12785463]\n",
      "[0.96274656, 1.4503664, 0.25396]\n",
      "[0.8475352, 1.3691816, 0.104819566]\n",
      "[0.85903525, 1.4457386, 0.05136089]\n",
      "[0.8395299, 1.4350954, 0.023092158]\n",
      "[0.84281266, 1.3977228, 0.06713176]\n",
      "[0.84330153, 1.3874333, 0.07850356]\n",
      "[0.87680554, 1.4277427, 0.1053105]\n",
      "[0.91353136, 1.4062198, 0.20039427]\n",
      "[0.8182159, 1.3954239, 0.020667093]\n",
      "[0.9104066, 1.4639267, 0.13664997]\n",
      "[0.879652, 1.4069235, 0.13224582]\n",
      "[0.8589845, 1.4081484, 0.08978671]\n",
      "[0.9980731, 1.4795859, 0.29662493]\n",
      "[0.920367, 1.4392428, 0.18165232]\n",
      "[0.9197, 1.3917291, 0.22792915]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-162-023922430e30>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malphabot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(10_000):\n",
    "    picked_data = random.sample(complete_history, k=min(BATCH_SIZE, len(complete_history)))\n",
    "    #picked_data = complete_history[0:50]\n",
    "    picked_data = apply_simmetries(picked_data)\n",
    "    \n",
    "    state = []\n",
    "    policy = []\n",
    "    value = []\n",
    "    for step in picked_data:\n",
    "        policy.append(step.policy)\n",
    "        state.append(step.state)\n",
    "        value.append(step.value)\n",
    "\n",
    "    y = [np.zeros((len(state), 4)), np.zeros((len(state), 1))]\n",
    "    y[0] = policy\n",
    "    y[1] = value\n",
    "    \n",
    "    losses = alphabot.train_on_batch(np.array(state, dtype=np.float32), y)\n",
    "    print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T17:06:37.952985Z",
     "start_time": "2019-02-05T17:06:37.930920Z"
    },
    "autopy": 0
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.33652508, 0.        , 0.33197975, 0.3314952 ], dtype=float32),\n",
       " array([0.57352941, 0.        , 0.22058824, 0.20588235]),\n",
       " 1,\n",
       " array([[0.00925609]], dtype=float32))"
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step = complete_history[125]\n",
    "state = step.state\n",
    "value = step.value\n",
    "pol = step.policy\n",
    "policy, v = alphabot.predict(state[np.newaxis])\n",
    "policy = policy[0]\n",
    "\n",
    "mapp = np.full((6, 6), -1)\n",
    "mapp[state[..., 0] == 1] = 1\n",
    "mapp[state[..., 2] == 1] = 1\n",
    "\n",
    "valid_actions = emulator.Game(2).valid_actions(mapp, state, state[..., -1].all() == 1)\n",
    "if len(valid_actions) < 4:\n",
    "    missing_idx = [v for v in [0, 1, 2, 3] if v not in valid_actions]\n",
    "    policy[missing_idx] = 0\n",
    "             \n",
    "if sum(policy) > 0:\n",
    "    policy = policy / sum(policy)\n",
    "\n",
    "\n",
    "policy, pol, value, v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T19:18:34.666636Z",
     "start_time": "2019-02-06T19:18:32.262030Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(1):\n",
    "    states = simulate_game(10, 0.8, alphabot=alphabot, eval_g=True, return_state=True)\n",
    "\n",
    "maps = []\n",
    "for state in states:\n",
    "    mapp = state[..., 0]\n",
    "    mapp += state[..., 2] * 2\n",
    "    mapp[np.where(state[..., 1] == 1)] = 3\n",
    "    mapp[np.where(state[..., 3] == 1)] = 4\n",
    "    mapp = np.expand_dims(mapp, axis=-1)\n",
    "    mapp = np.tile(mapp, [1, 1, 3])\n",
    "        \n",
    "    idx, cols, c = np.where(mapp == 1)\n",
    "    mapp[idx, cols, :] = 0\n",
    "    mapp[idx, cols, 0] = 128\n",
    "    \n",
    "    idx, cols, c = np.where(mapp == 2)\n",
    "    mapp[idx, cols, :] = 0\n",
    "    mapp[idx, cols, 1] = 128\n",
    "    \n",
    "    idx, cols, c = np.where(mapp == 3)\n",
    "    mapp[idx, cols, :] = 0\n",
    "    mapp[idx, cols, 0] = 255\n",
    "    \n",
    "    idx, cols, c = np.where(mapp == 4)\n",
    "    mapp[idx, cols, :] = 0\n",
    "    mapp[idx, cols, 1] = 255\n",
    "    \n",
    "    maps.append(mapp)\n",
    "    \n",
    "maps = np.array(maps)\n",
    "\n",
    "write_gif(maps, './test.gif', fps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T17:07:10.177832Z",
     "start_time": "2019-02-05T17:07:10.163664Z"
    },
    "autopy": 0
   },
   "outputs": [],
   "source": [
    "logging.getLogger().setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T18:34:10.087411Z",
     "start_time": "2019-02-06T18:34:10.069107Z"
    },
    "autopy": 0
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T16:09:56.466989Z",
     "start_time": "2019-02-05T16:09:56.463191Z"
    },
    "autopy": 0
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]),\n",
       " array([0.        , 0.14814815, 0.33333333, 0.51851852]))"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_history[506].state[..., 2], complete_history[503].policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-03T12:53:38.883498Z",
     "start_time": "2019-02-03T12:53:38.877195Z"
    },
    "autopy": 0,
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([s.state for s in complete_history[506:1000:4]])[:, :, ::-1][0, ..., 2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
