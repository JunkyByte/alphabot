{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-24T15:41:51.491940Z",
     "start_time": "2018-11-24T15:41:50.432801Z"
    },
    "autopy": 2
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adryw/miniconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/adryw/miniconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pickle\n",
    "import keras\n",
    "from keras.models import Model, load_model, clone_model\n",
    "from keras.utils import multi_gpu_model\n",
    "from keras.layers import *\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.regularizers import l2\n",
    "from keras.losses import binary_crossentropy\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import random\n",
    "sys.path.append('src')  # Fix for jupyter\n",
    "import src.emulator as emulator\n",
    "import src.emulator_utils as emulator_utils\n",
    "import src.emulator_vis as emulator_vis\n",
    "%matplotlib inline\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "import multiprocessing\n",
    "from multiprocessing import Event, Queue, Pipe\n",
    "from multiprocessing import Process as Thread\n",
    "import os\n",
    "import logging\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autopy": 0
   },
   "source": [
    "# Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-24T15:41:51.565489Z",
     "start_time": "2018-11-24T15:41:51.561273Z"
    },
    "autopy": 0
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(filename='logging.log', level=logging.INFO, format='%(asctime)s %(message)s', filemode='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autopy": 0
   },
   "source": [
    "# Model Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-24T15:41:52.248838Z",
     "start_time": "2018-11-24T15:41:52.246392Z"
    },
    "autopy": 0
   },
   "outputs": [],
   "source": [
    "INPUT_SIZE = (16, 16, 5) # Map size fixed to 16x16 (2 to 3 players)\n",
    "N_ACTIONS = 4\n",
    "gpus = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autopy": 0
   },
   "source": [
    "# Define the Layers Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 784,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T00:53:19.803597Z",
     "start_time": "2018-11-25T00:53:19.776273Z"
    },
    "autopy": 0
   },
   "outputs": [],
   "source": [
    "filters = 48\n",
    "\n",
    "# Convolutional Block\n",
    "def conv_block(in_layer, name, filters=filters, kernel_size=(3,3), bn=True, relu=True):\n",
    "    l = Conv2D(filters, kernel_size, padding='same', name = name, kernel_regularizer=l2(1e-4),\n",
    "              kernel_initializer='truncated_normal')(in_layer)\n",
    "    if bn:\n",
    "        l = BatchNormalization(axis=3, name = name + '_bn')(l)\n",
    "    if relu:\n",
    "        l = Activation('relu', name = name + '_relu')(l)\n",
    "    \n",
    "    l = Dropout(0.3)(l)\n",
    "    return l\n",
    "\n",
    "# Residual Block\n",
    "def residual_conv(in_layer, idx, filters=filters, kernel_size=(3,3), bn=True, relu=True):\n",
    "    name = 'res_' + str(idx)\n",
    "    # Full conv block of pre-defined shape\n",
    "    l = conv_block(in_layer, name + '_conv1', filters, kernel_size=(3,3), bn=True, relu=True)\n",
    "    # Second block with skip connection\n",
    "    l = Conv2D(filters, kernel_size, padding='same', name = name + '_conv2', kernel_regularizer=l2(1e-4),\n",
    "              kernel_initializer='truncated_normal')(l)\n",
    "    if bn:\n",
    "        l = BatchNormalization(axis=3, name = name + '_conv2_bn')(l)\n",
    "    l = Concatenate()([in_layer, l]) # Skip conn.\n",
    "    if relu:\n",
    "        l = Activation('relu', name = name + '_relu')(l)\n",
    "        \n",
    "    l = Dropout(0.3)(l)\n",
    "    return l\n",
    "\n",
    "def value_head(in_layer):\n",
    "    l = conv_block(in_layer, 'value_head', filters=1, kernel_size=(1,1))\n",
    "    l = Flatten(name = 'value_flatten')(l)\n",
    "    l = Dense(64, name = 'value_dense',\n",
    "             kernel_initializer='truncated_normal')(l)\n",
    "    l = Activation('relu', name = 'value_relu')(l)\n",
    "    l = Dropout(0.3)(l)\n",
    "    l = BatchNormalization(axis=1, name = 'value_bn')(l)\n",
    "\n",
    "    l = Dense(1, name = 'value', activation='tanh')(l) # Value output\n",
    "    return l\n",
    "\n",
    "def policy_head(in_layer):\n",
    "    l = conv_block(in_layer, 'policy_head', filters=2, kernel_size=(1,1))\n",
    "    l = Flatten(name = 'policy_flatten')(l)\n",
    "    l = Dense(64, name='policy_dense', kernel_initializer='truncated_normal')(l)\n",
    "    l = Dropout(0.3)(l)\n",
    "    l = BatchNormalization(axis=1, name = 'policy_bn')(l)\n",
    "    \n",
    "    l = Dense(N_ACTIONS, name = 'policy', activation=None,\n",
    "              kernel_initializer='truncated_normal')(l) # Policy output\n",
    "    return l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autopy": 0
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 783,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T00:53:18.191990Z",
     "start_time": "2018-11-25T00:53:18.173886Z"
    },
    "autopy": 0
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    def declare_model():\n",
    "        n_residual = 8\n",
    "\n",
    "        input_layer = Input(INPUT_SIZE)\n",
    "        l = conv_block(input_layer, 'conv')\n",
    "        for i in range(n_residual):\n",
    "            l = residual_conv(l, idx=i + 1)\n",
    "\n",
    "        policy = policy_head(l)\n",
    "        \n",
    "        value = value_head(l)\n",
    "\n",
    "        alphabot = Model(input_layer, [policy, value])\n",
    "        return alphabot\n",
    "    \n",
    "    if gpus > 1:\n",
    "        with tf.device('/cpu:0'):\n",
    "            alphabot = declare_model()\n",
    "        alphabot_multi = multi_gpu_model(alphabot, gpus=gpus)\n",
    "        return alphabot_multi, alphabot\n",
    "    \n",
    "    alphabot = declare_model()\n",
    "    return alphabot, alphabot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-24T15:41:56.265581Z",
     "start_time": "2018-11-24T15:41:56.262104Z"
    },
    "autopy": 0
   },
   "outputs": [],
   "source": [
    "def softmax(z):\n",
    "    assert len(z.shape) == 2\n",
    "    s = np.max(z, axis=1)\n",
    "    s = s[:, np.newaxis] # necessary step to do broadcasting\n",
    "    e_x = np.exp(z - s)\n",
    "    div = np.sum(e_x, axis=1)\n",
    "    div = div[:, np.newaxis]\n",
    "    return e_x / div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-24T15:41:56.745727Z",
     "start_time": "2018-11-24T15:41:56.733971Z"
    },
    "autopy": 1
   },
   "outputs": [],
   "source": [
    "def pre_train():\n",
    "    #global complete_history\n",
    "    #complete_history = []\n",
    "    \n",
    "    logging.info('Starting pretraining')\n",
    "    for i in range(pretrain_games):\n",
    "        if i % n_games == 0 and i > 0:\n",
    "            logging.info('Simulated %s pretrain-games', n_games)\n",
    "            \n",
    "        games_buffer = [GameRecorder() for player in range(n_players)] # Create a place to store games\n",
    "        game = emulator.Game(n_players) # TODO: Wrap the following lines in a function\n",
    "        gmap = game.map # Access map manually on first step\n",
    "        gmap_old = None # First frame has no older map\n",
    "        p_alive = game.players_alive # Players alive\n",
    "        n_alive = game.count_alive()\n",
    "\n",
    "        def take_action_brain(game):\n",
    "            actions = []\n",
    "            for idx, s in enumerate(game.players_alive):\n",
    "                player_idx = idx\n",
    "                p_x, p_y = game.history[player_idx][-1]\n",
    "                empty = -1\n",
    "                size = INPUT_SIZE[0]\n",
    "                liberties = np.array([0, 0, 0, 0]) # Right, Down, Left, Up\n",
    "                liberties[0] = int(game.map[p_x % size, (p_y + 1) % size] == empty)\n",
    "                liberties[1] = int(game.map[(p_x + 1) % size, p_y % size] == empty)\n",
    "                liberties[2] = int(game.map[p_x % size, (p_y - 1) % size] == empty)\n",
    "                liberties[3] = int(game.map[(p_x - 1) % size, p_y % size] == empty)\n",
    "                if liberties.any() == 0:\n",
    "                    actions.append(np.random.randint(0, len(liberties)))\n",
    "                else:\n",
    "                    while True:\n",
    "                        x = np.random.randint(0, len(liberties))\n",
    "                        if np.random.random() < 0.35: # A small chance of getting the action without even trying\n",
    "                            actions.append(x)\n",
    "                            break\n",
    "                        if liberties[x] == 1:\n",
    "                            actions.append(x)\n",
    "                            break\n",
    "            return actions\n",
    "                \n",
    "        while True:\n",
    "            state = map_to_state(gmap, gmap_old, p_alive) # State for each player alive\n",
    "            chosen_action = take_action_brain(game)\n",
    "            \n",
    "            gmap_old = copy.copy(gmap)\n",
    "            gmap, p_alive_new, n_alive, reward, game_end = game.step(chosen_action)\n",
    "        \n",
    "            idx_alive = 0\n",
    "            for alive in p_alive: # Players which were alive at the start of the step\n",
    "                if alive == 0: # Player is dead, skip it\n",
    "                    continue\n",
    "                \n",
    "                games_buffer[idx_alive].store(state[idx_alive], reward[idx_alive], chosen_action[idx_alive])\n",
    "                idx_alive += 1\n",
    "            p_alive = copy.copy(p_alive_new)\n",
    "            \n",
    "            if game_end:\n",
    "                logging.debug('Game ended, rewards %s', reward)\n",
    "                break\n",
    "        \n",
    "        for g in games_buffer:\n",
    "            if len(g.actions_taken) == 0:\n",
    "                logging.debug('WHAT A 0 STEPS GAME')\n",
    "                continue\n",
    "\n",
    "            complete_history.append(g)\n",
    "    \n",
    "    sum_losses = 0\n",
    "    for i in range(pretrain_steps):\n",
    "        losses = train_model()\n",
    "        sum_losses += losses[0]\n",
    "        if i % 100 == 0 and i > 0:\n",
    "            logging.info('Pretrain step %s losses: %s', i, sum_losses / (i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-24T15:41:57.584994Z",
     "start_time": "2018-11-24T15:41:57.577228Z"
    },
    "autopy": 0
   },
   "outputs": [],
   "source": [
    "def simulate_games():\n",
    "    logging.debug('Starting Threads for parallel Games')\n",
    "    \n",
    "    parallel_sim() # Parallel Games\n",
    "    while not history_buffer.full():\n",
    "        indices, states = [], []\n",
    "        if processable_buffer.qsize() < num_threads * 2: # Wait until a bunch of requests are queued\n",
    "            continue\n",
    "\n",
    "        for i in range(processable_buffer.qsize()):\n",
    "            index, state = processable_buffer.get()\n",
    "            indices.append(index)\n",
    "            states.append(state)\n",
    "            \n",
    "        states = np.array(states, dtype=np.float64)\n",
    "        #print(states[:, :, :, 0])\n",
    "        predictions = alphabot.predict(states)\n",
    "        #print(predictions)\n",
    "        for i, pred in enumerate(tuple(zip(predictions[0], predictions[1]))):\n",
    "            pipes[indices[i]].send(dict(zip(alphabot.output_names, pred)))\n",
    "        # We have to predict until buffer is full\n",
    "    logging.info('Finished Simulating %s games', n_games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-24T15:41:57.977017Z",
     "start_time": "2018-11-24T15:41:57.969661Z"
    },
    "autopy": 0
   },
   "outputs": [],
   "source": [
    "def play_eval(log_game=False):\n",
    "    game = emulator.Game(n_players) # TODO: Wrap the following lines in a function\n",
    "    gmap = game.map # Access map manually on first step\n",
    "\n",
    "    gmap_old = None # First frame has no older map\n",
    "    p_alive = game.players_alive # Players alive\n",
    "    n_alive = game.count_alive()\n",
    "    \n",
    "    #maps = [] # Initialise buffer for log\n",
    "    #maps.append(copy.copy(gmap))\n",
    "    \n",
    "    while True:\n",
    "        assert n_alive == 2, 'Multi player eval is not implemented yet'\n",
    "        state = map_to_state(gmap, gmap_old, p_alive) # State for each player alive\n",
    "        \n",
    "        # The predictions from the candidate and the best bot\n",
    "        p0 = alphabot.predict(state[0][np.newaxis])\n",
    "        p1 = alphabot_best.predict(state[1][np.newaxis])\n",
    "        \n",
    "        # Split in value and policy\n",
    "        candidate_policy = p0[0]\n",
    "        candidate_value = p0[1]\n",
    "        best_policy = p1[0]\n",
    "        best_value = p1[1]\n",
    "        \n",
    "        logging.debug('Candidate Policy: %s Candidate Value: %s', candidate_policy, candidate_value)\n",
    "        logging.debug('Best Bot Policy: %s Best Bot Value: %s', best_policy, best_value)\n",
    "        \n",
    "        policy = [candidate_policy[0], best_policy[0]]\n",
    "        policy = softmax(np.array(policy)) # We softmax the policy logits\n",
    "        chosen_action = np.argmax(policy, axis=-1)\n",
    "        \n",
    "        gmap_old = copy.copy(gmap)\n",
    "        gmap, p_alive, n_alive, reward, game_end = game.step(chosen_action)\n",
    "        #maps.append(copy.copy(gmap))\n",
    "        \n",
    "        if game_end:\n",
    "            if sum(reward == -1) == 2:\n",
    "                return play_eval()\n",
    "            winner = np.where(np.array(p_alive) == 1)[0][0]\n",
    "            if log_game:\n",
    "                return maps\n",
    "\n",
    "            return winner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-24T15:41:58.977848Z",
     "start_time": "2018-11-24T15:41:58.971211Z"
    },
    "autopy": 0
   },
   "outputs": [],
   "source": [
    "def train_model():\n",
    "        # Get a BATCH_SIZE of games\n",
    "        picked_data = random.sample(complete_history, k=min(BATCH_SIZE, len(complete_history)))\n",
    "        # Get a State from each game selected\n",
    "        x = np.empty((len(picked_data), 16, 16, 4), dtype=np.float64)\n",
    "        actions_taken = []\n",
    "        rewards = []\n",
    "        for j, game in enumerate(picked_data):\n",
    "            index = np.random.randint(0, len(game.actions_taken)) # Get game length and generate index\n",
    "            action = game.actions_taken[index]\n",
    "            state = game.states[index]\n",
    "            #state, action = simmetries(state, action) # Apply random simmetry\n",
    "            x[j] = np.array(state, dtype=np.float64)\n",
    "            actions_taken.append(action)    \n",
    "            rewards.append(np.array(game.rewards[-1], dtype=np.float64))\n",
    "        \n",
    "        #rewards = np.array(rewards)\n",
    "        actions_taken = np.array(actions_taken)\n",
    "        y = alphabot.predict(x)\n",
    "        #y = [np.zeros((x.shape[0], 4)), np.zeros((x.shape[0], 1))]\n",
    "        logging.debug('The predict is %s', y)\n",
    "        \n",
    "        for idx, action in enumerate(actions_taken):\n",
    "            if rewards[idx] == -1: # Loss\n",
    "                #y[0][idx, :] = 1 # Every other actions is good\n",
    "                y[0][idx, action] = 0 # Selected is bad\n",
    "            else: # Win\n",
    "                y[0][idx, action] = 1 # Every action is bad except this one\n",
    "            y[1][idx, 0] = rewards[idx] # Policy is easier to manage\n",
    "        logging.debug('The label is %s', y)\n",
    "        losses = alphabot.train_on_batch(x, y)\n",
    "        return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-24T15:41:59.349801Z",
     "start_time": "2018-11-24T15:41:59.340258Z"
    },
    "autopy": 0
   },
   "outputs": [],
   "source": [
    "def training_cycle():\n",
    "    global alphabot\n",
    "    global alphabot_best\n",
    "    global total_improv\n",
    "    \n",
    "    # Simulate n_games (exception made by first interaction)\n",
    "    logging.info('Starting Training Cycle')\n",
    "    while len(complete_history) < k * n_games:\n",
    "        simulate_games()\n",
    "        # history_buffer contains the games, we store them inside complete history    \n",
    "        for g in range(history_buffer.qsize()):\n",
    "            complete_history.append(history_buffer.get())\n",
    "        stop_simulation() # We can now stop the simulation (will free the memory)\n",
    "    logging.debug('Complete history should be full, it contains %s elements', len(complete_history))\n",
    "    # Now we are ready for the training process\n",
    "    logging.info('Starting Model Training')\n",
    "    losses = [None, None, None] # For debug purpose\n",
    "    sum_loss = 0\n",
    "    cc = 1\n",
    "    for i in range(t_steps + 1):\n",
    "        if i % 100 == 0:\n",
    "            logging.info('Training Interaction: %s losses: %s', i, \n",
    "                         round(sum_loss / cc, 2)) # Works?\n",
    "\n",
    "        losses = train_model()\n",
    "        sum_loss += losses[0]\n",
    "        logging.debug('Losses: %s', losses)\n",
    "        \n",
    "        improved = False\n",
    "        evalued_step = False\n",
    "        cc += 1\n",
    "        if i % eval_steps == 0 and i > 0:\n",
    "            evalued_step = True\n",
    "            cc = 1 # Reset loss counter\n",
    "            sum_loss = 0\n",
    "            wins = {'candidate' : 0, 'best' : 0}\n",
    "            n_c = {0 : 'candidate', 1 : 'best'}\n",
    "            \n",
    "            logging.info('Starting self-play evaluation')    \n",
    "            for j in range(eval_games):\n",
    "                # 0 is Candidate, 1 is the (soon to be old) best\n",
    "                wins[n_c[play_eval()]] += 1 # add a win to the winner\n",
    "                if j % 100 == 0:\n",
    "                    logging.info('Win state Candidate: %s Best: %s', wins['candidate'], wins['best'])\n",
    "            win_ratio = wins['candidate'] / eval_games\n",
    "            if win_ratio > win_percent:\n",
    "                logging.info('Great! Our candidate won %s percent of games', round(win_ratio * 100, 2))\n",
    "                total_improv += 1\n",
    "                logging.info('Our bot got better %s times', total_improv)\n",
    "                improved = True\n",
    "                with open(r\"alphabot_best.pickle\", \"wb\") as output_file:\n",
    "                    pickle.dump(alphabot, output_file)\n",
    "                with open(r\"alphabot_best.pickle\", \"rb\") as input_file:\n",
    "                    alphabot_best = pickle.load(input_file)\n",
    "            else:\n",
    "                logging.info('Damn! Our candidate only won %s percent of games', round(win_ratio * 100, 2))            \n",
    "        if not improved and evalued_step:\n",
    "            logging.info('Not improved, cloning to best')\n",
    "            with open(r\"alphabot_best.pickle\", \"rb\") as input_file:\n",
    "                alphabot = pickle.load(input_file)\n",
    "            \n",
    "    del complete_history[:n_games] # Delete n oldest games from history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-24T15:42:00.317364Z",
     "start_time": "2018-11-24T15:42:00.311969Z"
    },
    "autopy": 0
   },
   "outputs": [],
   "source": [
    "def load_best(best_model):\n",
    "    global alphabot\n",
    "    global alphabot_best\n",
    "    alphabot_best = load_model(best_model)\n",
    "    alphabot.set_weights(alphabot_best.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-24T15:42:00.681770Z",
     "start_time": "2018-11-24T15:42:00.675017Z"
    },
    "autopy": 0
   },
   "outputs": [],
   "source": [
    "def train(cycles, best_model = None):\n",
    "    global alphabot_best\n",
    "    global alphabot\n",
    "    \n",
    "    if best_model != None:\n",
    "        with open(r\"alphabot_best.pickle\", \"rb\") as input_file:\n",
    "            alphabot_best = pickle.load(input_file)\n",
    "        with open(r\"alphabot_best.pickle\", \"rb\") as input_file:\n",
    "            alphabot = pickle.load(input_file)\n",
    "    else:\n",
    "        with open(r\"alphabot_best.pickle\", \"rb\") as input_file:\n",
    "            alphabot_best = pickle.load(input_file)\n",
    "\n",
    "    pre_train()\n",
    "    with open(r\"alphabot_best.pickle\", \"wb\") as output_file:\n",
    "        pickle.dump(alphabot, output_file)\n",
    "    \n",
    "    with open(r\"alphabot_best.pickle\", \"rb\") as input_file:\n",
    "        alphabot_best = pickle.load(input_file)\n",
    "    \n",
    "    complete_history = []\n",
    "    for i in range(cycles):\n",
    "        training_cycle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-24T15:42:02.043845Z",
     "start_time": "2018-11-24T15:42:02.040015Z"
    },
    "autopy": 0
   },
   "outputs": [],
   "source": [
    "class GameRecorder():\n",
    "    def __init__(self):\n",
    "        self.states = []\n",
    "        self.rewards = []\n",
    "        self.actions_taken = []\n",
    "        \n",
    "    def store(self, state, reward, action_taken):\n",
    "        self.states.append(state)\n",
    "        self.rewards.append(reward)\n",
    "        self.actions_taken.append(action_taken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-24T15:42:02.528165Z",
     "start_time": "2018-11-24T15:42:02.513590Z"
    },
    "autopy": 0
   },
   "outputs": [],
   "source": [
    "def ask_predict(idi, x):\n",
    "    # Adds to queue id and data from process\n",
    "    [processable_buffer.put((idi, xi)) for xi in x]\n",
    "\n",
    "def sim(process_id, pipe):\n",
    "    np.random.seed()\n",
    "    random.seed()\n",
    "    while True:\n",
    "        games_buffer = [GameRecorder() for player in range(n_players)] # Create a place to store games\n",
    "        \n",
    "        # Simulate the game, if a prediction is needed use ask_predict\n",
    "        game = emulator.Game(n_players) # TODO: Wrap the following lines in a function\n",
    "        gmap = game.map # Access map manually on first step\n",
    "        gmap_old = None # First frame has no older map\n",
    "        p_alive = game.players_alive # Players alive\n",
    "        n_alive = game.count_alive()\n",
    "\n",
    "        while True:\n",
    "            state = map_to_state(gmap, gmap_old, p_alive) # State for each player alive\n",
    "            ask_predict(process_id, state)\n",
    "            policy, value = [], []\n",
    "            for i in range(n_alive):\n",
    "                raw_prediction = pipe.recv() # Receive actions from main\n",
    "                policy.append(raw_prediction['policy'])\n",
    "                value.append(raw_prediction['value'])\n",
    "            \n",
    "            #print('BEFORE:', policy)\n",
    "            policy = softmax(np.array(policy)) # We softmax the policy logits\n",
    "            #print('AFTER:', policy)\n",
    "            #chosen_action = [np.random.choice(N_ACTIONS, p=act) for act in policy]\n",
    "            chosen_action = np.argmax(policy, axis=-1)\n",
    "            logging.debug('Choosen Actions %s Raw Actions %s', chosen_action, policy)\n",
    "            \n",
    "            gmap_old = copy.copy(gmap)\n",
    "            gmap, p_alive_new, n_alive, reward, game_end = game.step(chosen_action)\n",
    "        \n",
    "            idx_alive = 0\n",
    "            for alive in p_alive: # Players which were alive at the start of the step\n",
    "                if alive == 0: # Player is dead, skip it\n",
    "                    continue\n",
    "                \n",
    "                games_buffer[idx_alive].store(state[idx_alive], reward[idx_alive], chosen_action[idx_alive])\n",
    "                idx_alive += 1\n",
    "            p_alive = copy.copy(p_alive_new)\n",
    "            \n",
    "            if game_end:\n",
    "                logging.debug('Game ended, rewards %s', reward)\n",
    "                break\n",
    "        try:\n",
    "            for g in games_buffer:\n",
    "                # I didn't find a bug yet that makes some games be of 0 steps, gonna skip them for now\n",
    "                if len(g.actions_taken) == 0:\n",
    "                    logging.debug('WHAT A 0 STEPS GAME')\n",
    "                    continue\n",
    "                    \n",
    "                history_buffer.put_nowait(g)\n",
    "        except:\n",
    "            break\n",
    "                    \n",
    "def stop_simulation():\n",
    "    global workers\n",
    "    global history_buffer\n",
    "    global processable_buffer\n",
    "    global pipes\n",
    "    global child_pipes\n",
    "    \n",
    "    if 'workers' in globals() and len(workers) != 0:\n",
    "        for worker in workers:\n",
    "            worker.terminate()\n",
    "    workers = []\n",
    "    \n",
    "    for pipe in pipes:\n",
    "        pipe.close()\n",
    "    \n",
    "    for pipe in child_pipes:\n",
    "        pipe.close()\n",
    "    \n",
    "    \n",
    "    #for _ in range(history_buffer.qsize()):\n",
    "    #    try:\n",
    "    #        history_buffer.get_nowait()\n",
    "    #    except:\n",
    "    #        break\n",
    "            \n",
    "    #for _ in range(processable_buffer.qsize()):\n",
    "    #    try:\n",
    "    #        processable_buffer.get_nowait()\n",
    "    #    except:\n",
    "    #        break\n",
    "        \n",
    "    \n",
    "        \n",
    "    history_buffer.close()\n",
    "    processable_buffer.close()\n",
    "    \n",
    "    # Then we empty the queues\n",
    "    del history_buffer\n",
    "    del processable_buffer\n",
    "    del pipes\n",
    "    del child_pipes\n",
    "\n",
    "def parallel_sim():\n",
    "    global workers\n",
    "    global history_buffer\n",
    "    global processable_buffer\n",
    "    global pipes\n",
    "    global child_pipes\n",
    "    \n",
    "    if 'workers' in globals() and len(workers) != 0:\n",
    "        stop_simulation()\n",
    "    \n",
    "    history_buffer = Queue(n_games) # This numbers can be tweaked\n",
    "    processable_buffer = Queue(num_threads * n_players)\n",
    "    pipes = []\n",
    "    child_pipes = []\n",
    "    \n",
    "    workers = []\n",
    "    for i in range(num_threads):\n",
    "        parent_pipe, child_pipe = Pipe() # Pipe to communicate with childs\n",
    "        pipes.append(parent_pipe)\n",
    "        child_pipes.append(child_pipe)\n",
    "        \n",
    "        worker = Thread(target=sim, args=[i, child_pipe])\n",
    "        worker.daemon = False\n",
    "        worker.start()\n",
    "        workers.append(worker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-24T15:42:03.637299Z",
     "start_time": "2018-11-24T15:42:03.628392Z"
    },
    "autopy": 0
   },
   "outputs": [],
   "source": [
    "def simmetries(state, action):\n",
    "    # There are these simmetries:\n",
    "    # +90;+180:-90;-180 degrees rotations\n",
    "    # Flips\n",
    "    \n",
    "    def rotate_state(state, rot):\n",
    "        N = INPUT_SIZE[0] - 1\n",
    "        if rot == 0: # Rotation of 0 is simple\n",
    "            return state\n",
    "        \n",
    "        new_state = np.empty(INPUT_SIZE, dtype=np.int)\n",
    "        it = np.nditer(state, flags=['multi_index'])\n",
    "        \n",
    "        if rot == 3: # Rot of 90\n",
    "            while not it.finished:\n",
    "                x, y, c = it.multi_index\n",
    "                new_state[x, y, c] = state[y, N - x, c]\n",
    "                it.iternext()\n",
    "                \n",
    "        elif rot == 2: # Rot of 180\n",
    "            while not it.finished:\n",
    "                x, y, c = it.multi_index\n",
    "                new_state[x, y, c] = state[N - x, N - y, c]\n",
    "                it.iternext()\n",
    "        elif rot == 1: # Rot of 270\n",
    "            while not it.finished:\n",
    "                x, y, c = it.multi_index\n",
    "                new_state[x, y, c] = state[N - y, x, c]\n",
    "                it.iternext()\n",
    "        return new_state\n",
    "    \n",
    "    # First we apply a random rotation simmetry\n",
    "    simmetry = random.sample([0, 1, 2, 3], 1)[0]\n",
    "    #print(simmetry * 90)\n",
    "    #print(action, simmetry)\n",
    "    action = (action + simmetry) % N_ACTIONS\n",
    "    state = rotate_state(state, simmetry)\n",
    "    return state, action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 785,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T00:53:57.227142Z",
     "start_time": "2018-11-25T00:53:22.050902Z"
    },
    "autopy": 0,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________________________________________\n",
      "Layer (type)                        Output Shape             Param #       Connected to                         \n",
      "================================================================================================================\n",
      "input_9 (InputLayer)                (None, 16, 16, 5)        0                                                  \n",
      "________________________________________________________________________________________________________________\n",
      "conv (Conv2D)                       (None, 16, 16, 48)       2208          input_9[0][0]                        \n",
      "________________________________________________________________________________________________________________\n",
      "conv_bn (BatchNormalization)        (None, 16, 16, 48)       192           conv[0][0]                           \n",
      "________________________________________________________________________________________________________________\n",
      "conv_relu (Activation)              (None, 16, 16, 48)       0             conv_bn[0][0]                        \n",
      "________________________________________________________________________________________________________________\n",
      "dropout_166 (Dropout)               (None, 16, 16, 48)       0             conv_relu[0][0]                      \n",
      "________________________________________________________________________________________________________________\n",
      "res_1_conv1 (Conv2D)                (None, 16, 16, 48)       20784         dropout_166[0][0]                    \n",
      "________________________________________________________________________________________________________________\n",
      "res_1_conv1_bn (BatchNormalization) (None, 16, 16, 48)       192           res_1_conv1[0][0]                    \n",
      "________________________________________________________________________________________________________________\n",
      "res_1_conv1_relu (Activation)       (None, 16, 16, 48)       0             res_1_conv1_bn[0][0]                 \n",
      "________________________________________________________________________________________________________________\n",
      "dropout_167 (Dropout)               (None, 16, 16, 48)       0             res_1_conv1_relu[0][0]               \n",
      "________________________________________________________________________________________________________________\n",
      "res_1_conv2 (Conv2D)                (None, 16, 16, 48)       20784         dropout_167[0][0]                    \n",
      "________________________________________________________________________________________________________________\n",
      "res_1_conv2_bn (BatchNormalization) (None, 16, 16, 48)       192           res_1_conv2[0][0]                    \n",
      "________________________________________________________________________________________________________________\n",
      "concatenate_65 (Concatenate)        (None, 16, 16, 96)       0             dropout_166[0][0]                    \n",
      "                                                                           res_1_conv2_bn[0][0]                 \n",
      "________________________________________________________________________________________________________________\n",
      "res_1_relu (Activation)             (None, 16, 16, 96)       0             concatenate_65[0][0]                 \n",
      "________________________________________________________________________________________________________________\n",
      "dropout_168 (Dropout)               (None, 16, 16, 96)       0             res_1_relu[0][0]                     \n",
      "________________________________________________________________________________________________________________\n",
      "res_2_conv1 (Conv2D)                (None, 16, 16, 48)       41520         dropout_168[0][0]                    \n",
      "________________________________________________________________________________________________________________\n",
      "res_2_conv1_bn (BatchNormalization) (None, 16, 16, 48)       192           res_2_conv1[0][0]                    \n",
      "________________________________________________________________________________________________________________\n",
      "res_2_conv1_relu (Activation)       (None, 16, 16, 48)       0             res_2_conv1_bn[0][0]                 \n",
      "________________________________________________________________________________________________________________\n",
      "dropout_169 (Dropout)               (None, 16, 16, 48)       0             res_2_conv1_relu[0][0]               \n",
      "________________________________________________________________________________________________________________\n",
      "res_2_conv2 (Conv2D)                (None, 16, 16, 48)       20784         dropout_169[0][0]                    \n",
      "________________________________________________________________________________________________________________\n",
      "res_2_conv2_bn (BatchNormalization) (None, 16, 16, 48)       192           res_2_conv2[0][0]                    \n",
      "________________________________________________________________________________________________________________\n",
      "concatenate_66 (Concatenate)        (None, 16, 16, 144)      0             dropout_168[0][0]                    \n",
      "                                                                           res_2_conv2_bn[0][0]                 \n",
      "________________________________________________________________________________________________________________\n",
      "res_2_relu (Activation)             (None, 16, 16, 144)      0             concatenate_66[0][0]                 \n",
      "________________________________________________________________________________________________________________\n",
      "dropout_170 (Dropout)               (None, 16, 16, 144)      0             res_2_relu[0][0]                     \n",
      "________________________________________________________________________________________________________________\n",
      "res_3_conv1 (Conv2D)                (None, 16, 16, 48)       62256         dropout_170[0][0]                    \n",
      "________________________________________________________________________________________________________________\n",
      "res_3_conv1_bn (BatchNormalization) (None, 16, 16, 48)       192           res_3_conv1[0][0]                    \n",
      "________________________________________________________________________________________________________________\n",
      "res_3_conv1_relu (Activation)       (None, 16, 16, 48)       0             res_3_conv1_bn[0][0]                 \n",
      "________________________________________________________________________________________________________________\n",
      "dropout_171 (Dropout)               (None, 16, 16, 48)       0             res_3_conv1_relu[0][0]               \n",
      "________________________________________________________________________________________________________________\n",
      "res_3_conv2 (Conv2D)                (None, 16, 16, 48)       20784         dropout_171[0][0]                    \n",
      "________________________________________________________________________________________________________________\n",
      "res_3_conv2_bn (BatchNormalization) (None, 16, 16, 48)       192           res_3_conv2[0][0]                    \n",
      "________________________________________________________________________________________________________________\n",
      "concatenate_67 (Concatenate)        (None, 16, 16, 192)      0             dropout_170[0][0]                    \n",
      "                                                                           res_3_conv2_bn[0][0]                 \n",
      "________________________________________________________________________________________________________________\n",
      "res_3_relu (Activation)             (None, 16, 16, 192)      0             concatenate_67[0][0]                 \n",
      "________________________________________________________________________________________________________________\n",
      "dropout_172 (Dropout)               (None, 16, 16, 192)      0             res_3_relu[0][0]                     \n",
      "________________________________________________________________________________________________________________\n",
      "res_4_conv1 (Conv2D)                (None, 16, 16, 48)       82992         dropout_172[0][0]                    \n",
      "________________________________________________________________________________________________________________\n",
      "res_4_conv1_bn (BatchNormalization) (None, 16, 16, 48)       192           res_4_conv1[0][0]                    \n",
      "________________________________________________________________________________________________________________\n",
      "res_4_conv1_relu (Activation)       (None, 16, 16, 48)       0             res_4_conv1_bn[0][0]                 \n",
      "________________________________________________________________________________________________________________\n",
      "dropout_173 (Dropout)               (None, 16, 16, 48)       0             res_4_conv1_relu[0][0]               \n",
      "________________________________________________________________________________________________________________\n",
      "res_4_conv2 (Conv2D)                (None, 16, 16, 48)       20784         dropout_173[0][0]                    \n",
      "________________________________________________________________________________________________________________\n",
      "res_4_conv2_bn (BatchNormalization) (None, 16, 16, 48)       192           res_4_conv2[0][0]                    \n",
      "________________________________________________________________________________________________________________\n",
      "concatenate_68 (Concatenate)        (None, 16, 16, 240)      0             dropout_172[0][0]                    \n",
      "                                                                           res_4_conv2_bn[0][0]                 \n",
      "________________________________________________________________________________________________________________\n",
      "res_4_relu (Activation)             (None, 16, 16, 240)      0             concatenate_68[0][0]                 \n",
      "________________________________________________________________________________________________________________\n",
      "dropout_174 (Dropout)               (None, 16, 16, 240)      0             res_4_relu[0][0]                     \n",
      "________________________________________________________________________________________________________________\n",
      "res_5_conv1 (Conv2D)                (None, 16, 16, 48)       103728        dropout_174[0][0]                    \n",
      "________________________________________________________________________________________________________________\n",
      "res_5_conv1_bn (BatchNormalization) (None, 16, 16, 48)       192           res_5_conv1[0][0]                    \n",
      "________________________________________________________________________________________________________________\n",
      "res_5_conv1_relu (Activation)       (None, 16, 16, 48)       0             res_5_conv1_bn[0][0]                 \n",
      "________________________________________________________________________________________________________________\n",
      "dropout_175 (Dropout)               (None, 16, 16, 48)       0             res_5_conv1_relu[0][0]               \n",
      "________________________________________________________________________________________________________________\n",
      "res_5_conv2 (Conv2D)                (None, 16, 16, 48)       20784         dropout_175[0][0]                    \n",
      "________________________________________________________________________________________________________________\n",
      "res_5_conv2_bn (BatchNormalization) (None, 16, 16, 48)       192           res_5_conv2[0][0]                    \n",
      "________________________________________________________________________________________________________________\n",
      "concatenate_69 (Concatenate)        (None, 16, 16, 288)      0             dropout_174[0][0]                    \n",
      "                                                                           res_5_conv2_bn[0][0]                 \n",
      "________________________________________________________________________________________________________________\n",
      "res_5_relu (Activation)             (None, 16, 16, 288)      0             concatenate_69[0][0]                 \n",
      "________________________________________________________________________________________________________________\n",
      "dropout_176 (Dropout)               (None, 16, 16, 288)      0             res_5_relu[0][0]                     \n",
      "________________________________________________________________________________________________________________\n",
      "res_6_conv1 (Conv2D)                (None, 16, 16, 48)       124464        dropout_176[0][0]                    \n",
      "________________________________________________________________________________________________________________\n",
      "res_6_conv1_bn (BatchNormalization) (None, 16, 16, 48)       192           res_6_conv1[0][0]                    \n",
      "________________________________________________________________________________________________________________\n",
      "res_6_conv1_relu (Activation)       (None, 16, 16, 48)       0             res_6_conv1_bn[0][0]                 \n",
      "________________________________________________________________________________________________________________\n",
      "dropout_177 (Dropout)               (None, 16, 16, 48)       0             res_6_conv1_relu[0][0]               \n",
      "________________________________________________________________________________________________________________\n",
      "res_6_conv2 (Conv2D)                (None, 16, 16, 48)       20784         dropout_177[0][0]                    \n",
      "________________________________________________________________________________________________________________\n",
      "res_6_conv2_bn (BatchNormalization) (None, 16, 16, 48)       192           res_6_conv2[0][0]                    \n",
      "________________________________________________________________________________________________________________\n",
      "concatenate_70 (Concatenate)        (None, 16, 16, 336)      0             dropout_176[0][0]                    \n",
      "                                                                           res_6_conv2_bn[0][0]                 \n",
      "________________________________________________________________________________________________________________\n",
      "res_6_relu (Activation)             (None, 16, 16, 336)      0             concatenate_70[0][0]                 \n",
      "________________________________________________________________________________________________________________\n",
      "dropout_178 (Dropout)               (None, 16, 16, 336)      0             res_6_relu[0][0]                     \n",
      "________________________________________________________________________________________________________________\n",
      "res_7_conv1 (Conv2D)                (None, 16, 16, 48)       145200        dropout_178[0][0]                    \n",
      "________________________________________________________________________________________________________________\n",
      "res_7_conv1_bn (BatchNormalization) (None, 16, 16, 48)       192           res_7_conv1[0][0]                    \n",
      "________________________________________________________________________________________________________________\n",
      "res_7_conv1_relu (Activation)       (None, 16, 16, 48)       0             res_7_conv1_bn[0][0]                 \n",
      "________________________________________________________________________________________________________________\n",
      "dropout_179 (Dropout)               (None, 16, 16, 48)       0             res_7_conv1_relu[0][0]               \n",
      "________________________________________________________________________________________________________________\n",
      "res_7_conv2 (Conv2D)                (None, 16, 16, 48)       20784         dropout_179[0][0]                    \n",
      "________________________________________________________________________________________________________________\n",
      "res_7_conv2_bn (BatchNormalization) (None, 16, 16, 48)       192           res_7_conv2[0][0]                    \n",
      "________________________________________________________________________________________________________________\n",
      "concatenate_71 (Concatenate)        (None, 16, 16, 384)      0             dropout_178[0][0]                    \n",
      "                                                                           res_7_conv2_bn[0][0]                 \n",
      "________________________________________________________________________________________________________________\n",
      "res_7_relu (Activation)             (None, 16, 16, 384)      0             concatenate_71[0][0]                 \n",
      "________________________________________________________________________________________________________________\n",
      "dropout_180 (Dropout)               (None, 16, 16, 384)      0             res_7_relu[0][0]                     \n",
      "________________________________________________________________________________________________________________\n",
      "res_8_conv1 (Conv2D)                (None, 16, 16, 48)       165936        dropout_180[0][0]                    \n",
      "________________________________________________________________________________________________________________\n",
      "res_8_conv1_bn (BatchNormalization) (None, 16, 16, 48)       192           res_8_conv1[0][0]                    \n",
      "________________________________________________________________________________________________________________\n",
      "res_8_conv1_relu (Activation)       (None, 16, 16, 48)       0             res_8_conv1_bn[0][0]                 \n",
      "________________________________________________________________________________________________________________\n",
      "dropout_181 (Dropout)               (None, 16, 16, 48)       0             res_8_conv1_relu[0][0]               \n",
      "________________________________________________________________________________________________________________\n",
      "res_8_conv2 (Conv2D)                (None, 16, 16, 48)       20784         dropout_181[0][0]                    \n",
      "________________________________________________________________________________________________________________\n",
      "res_8_conv2_bn (BatchNormalization) (None, 16, 16, 48)       192           res_8_conv2[0][0]                    \n",
      "________________________________________________________________________________________________________________\n",
      "concatenate_72 (Concatenate)        (None, 16, 16, 432)      0             dropout_180[0][0]                    \n",
      "                                                                           res_8_conv2_bn[0][0]                 \n",
      "________________________________________________________________________________________________________________\n",
      "res_8_relu (Activation)             (None, 16, 16, 432)      0             concatenate_72[0][0]                 \n",
      "________________________________________________________________________________________________________________\n",
      "dropout_182 (Dropout)               (None, 16, 16, 432)      0             res_8_relu[0][0]                     \n",
      "________________________________________________________________________________________________________________\n",
      "value_head (Conv2D)                 (None, 16, 16, 1)        433           dropout_182[0][0]                    \n",
      "________________________________________________________________________________________________________________\n",
      "policy_head (Conv2D)                (None, 16, 16, 2)        866           dropout_182[0][0]                    \n",
      "________________________________________________________________________________________________________________\n",
      "value_head_bn (BatchNormalization)  (None, 16, 16, 1)        4             value_head[0][0]                     \n",
      "________________________________________________________________________________________________________________\n",
      "policy_head_bn (BatchNormalization) (None, 16, 16, 2)        8             policy_head[0][0]                    \n",
      "________________________________________________________________________________________________________________\n",
      "value_head_relu (Activation)        (None, 16, 16, 1)        0             value_head_bn[0][0]                  \n",
      "________________________________________________________________________________________________________________\n",
      "policy_head_relu (Activation)       (None, 16, 16, 2)        0             policy_head_bn[0][0]                 \n",
      "________________________________________________________________________________________________________________\n",
      "dropout_185 (Dropout)               (None, 16, 16, 1)        0             value_head_relu[0][0]                \n",
      "________________________________________________________________________________________________________________\n",
      "dropout_183 (Dropout)               (None, 16, 16, 2)        0             policy_head_relu[0][0]               \n",
      "________________________________________________________________________________________________________________\n",
      "value_flatten (Flatten)             (None, 256)              0             dropout_185[0][0]                    \n",
      "________________________________________________________________________________________________________________\n",
      "policy_flatten (Flatten)            (None, 512)              0             dropout_183[0][0]                    \n",
      "________________________________________________________________________________________________________________\n",
      "value_dense (Dense)                 (None, 64)               16448         value_flatten[0][0]                  \n",
      "________________________________________________________________________________________________________________\n",
      "policy_dense (Dense)                (None, 64)               32832         policy_flatten[0][0]                 \n",
      "________________________________________________________________________________________________________________\n",
      "value_relu (Activation)             (None, 64)               0             value_dense[0][0]                    \n",
      "________________________________________________________________________________________________________________\n",
      "dropout_184 (Dropout)               (None, 64)               0             policy_dense[0][0]                   \n",
      "________________________________________________________________________________________________________________\n",
      "dropout_186 (Dropout)               (None, 64)               0             value_relu[0][0]                     \n",
      "________________________________________________________________________________________________________________\n",
      "policy_bn (BatchNormalization)      (None, 64)               256           dropout_184[0][0]                    \n",
      "________________________________________________________________________________________________________________\n",
      "value_bn (BatchNormalization)       (None, 64)               256           dropout_186[0][0]                    \n",
      "________________________________________________________________________________________________________________\n",
      "policy (Dense)                      (None, 4)                260           policy_bn[0][0]                      \n",
      "________________________________________________________________________________________________________________\n",
      "value (Dense)                       (None, 1)                65            value_bn[0][0]                       \n",
      "================================================================================================================\n",
      "Total params: 970,052\n",
      "Trainable params: 968,158\n",
      "Non-trainable params: 1,894\n",
      "________________________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "alphabot, _ = create_model()\n",
    "alphabot.compile(optimizer=Adam(1e-4), \n",
    "                          loss={'value' : 'mse', 'policy' : 'categorical_crossentropy'},\n",
    "                          loss_weights={'value' : 0.1, 'policy' : 2.0})\n",
    "alphabot.summary(line_length=112)\n",
    "\n",
    "with open(r\"alphabot_best.pickle\", \"wb\") as output_file:\n",
    "    pickle.dump(alphabot, output_file)\n",
    "    \n",
    "with open(r\"alphabot_best.pickle\", \"rb\") as input_file:\n",
    "    alphabot_best = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-24T15:42:10.117222Z",
     "start_time": "2018-11-24T15:42:10.111670Z"
    },
    "autopy": 0
   },
   "outputs": [],
   "source": [
    "# History of games for training\n",
    "complete_history = []\n",
    "\n",
    "# Game Params\n",
    "n_players = 2\n",
    "n_games = 15_000 # Simulate N games before each training\n",
    "k = 6 # Games to be stored n_games * K\n",
    "\n",
    "# Simulation Params\n",
    "num_threads = 30\n",
    "\n",
    "# Training Params\n",
    "t_steps = 2000 # Steps of training\n",
    "eval_steps = 1000 # How many steps before evaluation\n",
    "eval_games = 500 # How many games to play to evaluate how's best model\n",
    "win_percent = 0.55 # Ratio of game won to become best model\n",
    "BATCH_SIZE = 384\n",
    "total_improv = 0\n",
    "pretrain_steps = 0 #750\n",
    "pretrain_games = 0 #30_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-13T22:25:17.962058Z",
     "start_time": "2018-11-13T22:22:31.142982Z"
    },
    "autopy": 0,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-0f412c53fc4b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcycles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcycles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-c2f2aaae46b6>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(cycles, best_model)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mcomplete_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcycles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mtraining_cycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-72701ac0f937>\u001b[0m in \u001b[0;36mtraining_cycle\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_games\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m                 \u001b[0;31m# 0 is Candidate, 1 is the (soon to be old) best\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m                 \u001b[0mwins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_c\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mplay_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;31m# add a win to the winner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Win state Candidate: %s Best: %s'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'candidate'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'best'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-e76da71a1a46>\u001b[0m in \u001b[0;36mplay_eval\u001b[0;34m(log_game)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# The predictions from the candidate and the best bot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mp0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malphabot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mp1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malphabot_best\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# Split in value and policy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1167\u001b[0m                                             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1169\u001b[0;31m                                             steps=steps)\n\u001b[0m\u001b[1;32m   1170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m    292\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2696\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2697\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_make_callable_from_options'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2698\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2699\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0mcandidate_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_keras_initialized'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m                     \u001b[0mcandidate_vars\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcandidate_vars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "complete_history = []\n",
    "cycles = 1000\n",
    "\n",
    "train(cycles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 794,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T00:54:32.795561Z",
     "start_time": "2018-11-25T00:54:32.771510Z"
    }
   },
   "outputs": [],
   "source": [
    "class MCTS():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.tree = []\n",
    "        self.P = {}\n",
    "        self.Q = {}\n",
    "        self.N = {}\n",
    "        self.alpha = 0.8\n",
    "    \n",
    "    def search(self, s, mapp, game, nnet):\n",
    "        logging.debug('Starting search')\n",
    "        s_k = s.tobytes()\n",
    "                \n",
    "        if game.game_ended():\n",
    "            logging.debug('Game Ended during search')\n",
    "            game.reward = 0\n",
    "            return -game.reward\n",
    "        \n",
    "        if s_k not in self.tree:\n",
    "            logging.debug('New state encountered')\n",
    "            self.tree.append(s_k)\n",
    "            policy, value = nnet.predict(s[np.newaxis])\n",
    "            self.P[s_k], v = policy[0], value[0]\n",
    "            self.Q[s_k] = np.zeros((4))\n",
    "            self.N[s_k] = np.zeros((4))\n",
    "            return -v\n",
    "        \n",
    "        max_u, best_a = -float('inf'), -1\n",
    "        logging.debug('Evaluating UCB')\n",
    "        for a in range(4): # The actions\n",
    "            u = self.Q[s_k][a] + self.alpha * self.P[s_k][a] * np.sqrt(np.sum(self.N[s_k]) / (1 + self.N[s_k][a]))\n",
    "            if u > max_u:\n",
    "                max_u = u\n",
    "                best_a = a\n",
    "        a = best_a\n",
    "        \n",
    "        new_map = copy.copy(mapp)\n",
    "        new_map = game.step(new_map, s, a)\n",
    "        turn = int(s[..., -1].all() == 1) # Whose turn is this?\n",
    "        \n",
    "        if turn == 1: # We update the state\n",
    "            logging.debug('Player 1 turn, updating the map')\n",
    "            sp = map_to_state(new_map, mapp, turn) # TODO: Map to state\n",
    "        else: # It's player 0 turn we don't update the state\n",
    "            logging.debug('Player 0 turn, not updating the map')\n",
    "            # But we have to change the point of view of it!\n",
    "            sp = copy.copy(s)\n",
    "            sp[..., -1] = 1\n",
    "            \n",
    "        mapp = copy.copy(new_map)\n",
    "        v = self.search(sp, new_map, game, nnet)\n",
    "        \n",
    "        self.Q[s_k][a] = (self.N[s_k][a] * self.Q[s_k][a] + v) / (self.N[s_k][a] + 1)\n",
    "        self.N[s_k][a] += 1\n",
    "        \n",
    "        return -v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T00:44:06.361939Z",
     "start_time": "2018-11-25T00:44:06.343773Z"
    }
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=4)\n",
    "np.set_printoptions(suppress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 803,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T00:54:57.303372Z",
     "start_time": "2018-11-25T00:54:57.284397Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.998, 0.001, 0.   , 0.001])"
      ]
     },
     "execution_count": 803,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tree.N[s.tobytes()]\n",
    "x / sum(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 805,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T00:55:08.469431Z",
     "start_time": "2018-11-25T00:55:08.287667Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.0004 -0.0765  0.     -0.0721]\n",
      "[-2.0254e-04  0.0000e+00  0.0000e+00 -9.6344e-05]\n",
      "[0.0005 0.     0.     0.    ]\n",
      "[-0.0004  0.      0.      0.    ]\n",
      "[0.0005 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[-0.0004  0.      0.      0.    ]\n",
      "[0.0005 0.     0.     0.0004]\n",
      "[-0.0004  0.      0.     -0.0006]\n",
      "[0.0005 0.     0.     0.0004]\n",
      "[-0.0004  0.      0.     -0.0004]\n",
      "[0.0007 0.     0.     0.0004]\n",
      "[-0.0004  0.      0.     -0.0005]\n",
      "[ 1.7732e-03  0.0000e+00  0.0000e+00 -8.8644e-05]\n",
      "[-7.7109e-04  0.0000e+00  0.0000e+00 -1.6495e-05]\n",
      "[0.0236 0.     0.     0.0007]\n",
      "[0.0019 0.     0.     0.    ]\n",
      "[-0.0023  0.      0.      0.0014]\n",
      "[0.0815 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[ 0.0006  0.      0.     -0.0007]\n",
      "[-0.0032  0.      0.      0.0005]\n",
      "[-0.0002  0.      0.     -0.0008]\n",
      "[0.0006 0.     0.     0.0028]\n",
      "[-4.7538e-05  0.0000e+00  0.0000e+00  4.2580e-03]\n",
      "[0.0006 0.     0.     0.0757]\n",
      "[-0.0018  0.      0.      0.0001]\n",
      "[ 0.0021  0.      0.     -0.0007]\n",
      "[-0.0019  0.      0.     -0.0002]\n",
      "[0.0185 0.     0.     0.0023]\n",
      "[-6.1703e-03  0.0000e+00  0.0000e+00  5.6854e-05]\n",
      "[-3.1279e-05  0.0000e+00  0.0000e+00  4.1667e-04]\n",
      "[-9.7878e-05  0.0000e+00  0.0000e+00  1.1799e-03]\n",
      "[-0.0014  0.      0.      0.0094]\n",
      "[-1.4723e-03  0.0000e+00  0.0000e+00 -2.7363e-05]\n",
      "[0.0073 0.     0.     0.0724]\n",
      "[-0.0036  0.      0.      0.    ]\n",
      "[0.0744 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[ 0.0015  0.      0.     -0.0019]\n",
      "[ 0.0091  0.      0.     -0.0015]\n",
      "[0.0009 0.     0.     0.016 ]\n",
      "[ 0.0037  0.      0.     -0.0012]\n",
      "[ 4.4756e-04  0.0000e+00  0.0000e+00 -7.3281e-05]\n",
      "[-5.7397e-05  0.0000e+00  0.0000e+00  0.0000e+00]\n",
      "[0.0004 0.     0.     0.    ]\n",
      "[-2.2814e-05  0.0000e+00  0.0000e+00  0.0000e+00]\n",
      "[0.0004 0.     0.     0.    ]\n",
      "[0.    0.    0.    0.027]\n",
      "[ 0.0004  0.      0.     -0.0002]\n",
      "[1.2893e-06 0.0000e+00 0.0000e+00 0.0000e+00]\n",
      "[0.0766 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[-0.0015  0.      0.     -0.0017]\n",
      "[0.     0.     0.     0.0274]\n",
      "[0.0779 0.     0.     0.    ]\n",
      "[ 0.      0.      0.     -0.0001]\n",
      "[0.0005 0.     0.     0.0007]\n",
      "[ 5.5723e-05  0.0000e+00  0.0000e+00 -4.2653e-04]\n",
      "[0.0225 0.     0.     0.0002]\n",
      "[0.0021 0.     0.     0.    ]\n",
      "[0.074 0.    0.    0.   ]\n",
      "[0. 0. 0. 0.]\n",
      "[0.0004 0.     0.     0.    ]\n",
      "[ 2.3901e-05  0.0000e+00  0.0000e+00 -1.1382e-03]\n",
      "[ 0.0004  0.      0.     -0.0011]\n",
      "[4.1269e-05 0.0000e+00 0.0000e+00 0.0000e+00]\n",
      "[0.0765 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[-0.0042  0.      0.      0.    ]\n",
      "[0.0835 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[0.0271 0.     0.     0.    ]\n",
      "[-0.0043  0.      0.      0.    ]\n",
      "[0.082 0.    0.    0.   ]\n",
      "[0. 0. 0. 0.]\n",
      "[-0.0021  0.      0.      0.0008]\n",
      "[0.0039 0.     0.     0.0709]\n",
      "[0.0638 0.     0.     0.    ]\n",
      "[-0.0003  0.      0.     -0.0002]\n",
      "[0.     0.     0.     0.0019]\n",
      "[0.0006 0.     0.     0.    ]\n",
      "[0.0025 0.     0.     0.    ]\n",
      "[-4.5360e-03  0.0000e+00  0.0000e+00 -5.4473e-05]\n",
      "[2.4580e-03 0.0000e+00 0.0000e+00 9.4081e-05]\n",
      "[-0.0008  0.      0.      0.0002]\n",
      "[0.0002 0.     0.     0.0072]\n",
      "[0.0008 0.     0.     0.    ]\n",
      "[ 0.0056  0.      0.     -0.0008]\n",
      "[0.0005 0.     0.     0.    ]\n",
      "[ 0.0103  0.      0.     -0.002 ]\n",
      "[0.0003 0.     0.     0.0068]\n",
      "[0.0019 0.     0.     0.0004]\n",
      "[ 5.4315e-04  0.0000e+00  0.0000e+00 -5.1243e-05]\n",
      "[-0.0012  0.      0.      0.005 ]\n",
      "[0.0032 0.     0.     0.    ]\n",
      "[-7.0846e-05  0.0000e+00  0.0000e+00  0.0000e+00]\n",
      "[0.0034 0.     0.     0.    ]\n",
      "[0.0002 0.     0.     0.    ]\n",
      "[0.0244 0.     0.     0.0003]\n",
      "[-0.0007  0.      0.      0.    ]\n",
      "[0.0738 0.     0.     0.    ]\n",
      "[-1.0058e-06  0.0000e+00  0.0000e+00  7.3693e-02]\n",
      "[0.0858 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[0.0732 0.     0.     0.    ]\n",
      "[0.028 0.    0.    0.   ]\n",
      "[0.0004 0.     0.     0.    ]\n",
      "[0.0866 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[-0.002   0.      0.      0.0095]\n",
      "[0.0001 0.     0.     0.0026]\n",
      "[0.0096 0.     0.     0.0005]\n",
      "[-0.0033  0.      0.      0.0808]\n",
      "[0.0766 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[ 0.0071  0.      0.     -0.004 ]\n",
      "[-0.0033  0.      0.      0.0003]\n",
      "[0.0023 0.     0.     0.0002]\n",
      "[ 0.0003  0.      0.     -0.0008]\n",
      "[0.0064 0.     0.     0.0007]\n",
      "[-0.0044  0.      0.      0.    ]\n",
      "[ 6.2195e-05  0.0000e+00  0.0000e+00 -2.7611e-05]\n",
      "[-0.0043  0.      0.      0.    ]\n",
      "[0.0843 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0.0088 0.     0.     0.    ]\n",
      "[-0.0011  0.      0.      0.    ]\n",
      "[0.0107 0.     0.     0.    ]\n",
      "[-0.0008  0.      0.      0.    ]\n",
      "[-0.0005  0.      0.      0.0011]\n",
      "[0.0154 0.     0.     0.    ]\n",
      "[0.0143 0.     0.     0.    ]\n",
      "[-0.0016  0.      0.     -0.0013]\n",
      "[0.0642 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[0.0037 0.     0.     0.    ]\n",
      "[0.0005 0.     0.     0.    ]\n",
      "[1.9577e-03 0.0000e+00 0.0000e+00 5.4779e-05]\n",
      "[-0.0008  0.      0.     -0.0027]\n",
      "[-0.0003  0.      0.      0.0063]\n",
      "[0.0143 0.     0.     0.    ]\n",
      "[-0.0007  0.      0.      0.    ]\n",
      "[0.0002 0.     0.     0.0002]\n",
      "[0.0046 0.     0.     0.    ]\n",
      "[0.0002 0.     0.     0.0003]\n",
      "[-0.0002  0.      0.      0.0228]\n",
      "[0.069 0.    0.    0.   ]\n",
      "[0. 0. 0. 0.]\n",
      "[9.71e-05 0.00e+00 0.00e+00 0.00e+00]\n",
      "[0.0708 0.     0.     0.    ]\n",
      "[ 0.002   0.      0.     -0.0001]\n",
      "[-0.0035  0.      0.      0.0002]\n",
      "[0.0886 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[0.0805 0.     0.     0.    ]\n",
      "[0.0805 0.     0.     0.    ]\n",
      "[0.023 0.    0.    0.   ]\n",
      "[-0.0017  0.      0.      0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[-0.001   0.      0.      0.0733]\n",
      "[0.0062 0.     0.     0.    ]\n",
      "[-6.9287e-04  0.0000e+00  0.0000e+00  7.1954e-05]\n",
      "[0.0156 0.     0.     0.    ]\n",
      "[-0.0007  0.      0.      0.    ]\n",
      "[0.0153 0.     0.     0.    ]\n",
      "[-0.0003  0.      0.     -0.0011]\n",
      "[0.0741 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[0.077 0.    0.    0.   ]\n",
      "[0. 0. 0. 0.]\n",
      "[0.0703 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[0.0021 0.     0.     0.    ]\n",
      "[0.078 0.    0.    0.   ]\n",
      "[ 0.0026  0.      0.     -0.0008]\n",
      "[0.0007 0.     0.     0.    ]\n",
      "[ 0.0035  0.      0.     -0.0022]\n",
      "[0.0004 0.     0.     0.    ]\n",
      "[2.8457e-06 0.0000e+00 0.0000e+00 0.0000e+00]\n",
      "[0.0006 0.     0.     0.    ]\n",
      "[1.8427e-06 0.0000e+00 0.0000e+00 0.0000e+00]\n",
      "[0.0006 0.     0.     0.    ]\n",
      "[1.0187e-05 0.0000e+00 0.0000e+00 0.0000e+00]\n",
      "[0.0007 0.     0.     0.0003]\n",
      "[-1.5394e-05  0.0000e+00  0.0000e+00  0.0000e+00]\n",
      "[0.0007 0.     0.     0.    ]\n",
      "[0.0156 0.     0.     0.    ]\n",
      "[0.0158 0.     0.     0.    ]\n",
      "[-0.002   0.      0.     -0.0015]\n",
      "[0.0726 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[0.0682 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[0.0007 0.     0.     0.0003]\n",
      "[-0.0004  0.      0.      0.0226]\n",
      "[0.0146 0.     0.     0.0011]\n",
      "[-0.0015  0.      0.      0.0775]\n",
      "[0.0731 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[ 0.0016  0.      0.     -0.0006]\n",
      "[-0.0002  0.      0.     -0.0002]\n",
      "[0.0274 0.     0.     0.0002]\n",
      "[0.0174 0.     0.     0.    ]\n",
      "[5.8611e-05 0.0000e+00 0.0000e+00 2.5479e-04]\n",
      "[0.0166 0.     0.     0.    ]\n",
      "[ 0.0029  0.      0.     -0.0009]\n",
      "[0. 0. 0. 0.]\n",
      "[-0.0049  0.      0.      0.0289]\n",
      "[0.0831 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[-0.0003  0.      0.      0.    ]\n",
      "[0.0001 0.     0.     0.004 ]\n",
      "[0.0726 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[0.0842 0.     0.     0.    ]\n",
      "[-0.0003  0.      0.      0.    ]\n",
      "[ 0.003   0.      0.     -0.0006]\n",
      "[-0.001   0.      0.     -0.0007]\n",
      "[-0.0005  0.      0.      0.    ]\n",
      "[0.0876 0.     0.     0.    ]\n",
      "[0.0245 0.     0.     0.    ]\n",
      "[-0.0015  0.      0.      0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[ 0.0008  0.      0.     -0.0003]\n",
      "[0.0834 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[0.0763 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[0.0075 0.     0.     0.001 ]\n",
      "[0.0008 0.     0.     0.    ]\n",
      "[0.0045 0.     0.     0.    ]\n",
      "[-0.001   0.      0.     -0.0009]\n",
      "[0.0062 0.     0.     0.    ]\n",
      "[-0.0011  0.      0.     -0.002 ]\n",
      "[-0.0015  0.      0.      0.0264]\n",
      "[0.0745 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[0.0235 0.     0.     0.    ]\n",
      "[-0.0003  0.      0.      0.    ]\n",
      "[0.0705 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[0.0274 0.     0.     0.    ]\n",
      "[0.0251 0.     0.     0.0009]\n",
      "[0.0789 0.     0.     0.    ]\n",
      "[0.0831 0.     0.     0.    ]\n",
      "[0.0039 0.     0.     0.    ]\n",
      "[ 0.001   0.      0.     -0.0016]\n",
      "[0.0021 0.     0.     0.    ]\n",
      "[0.0834 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[ 0.0114  0.      0.     -0.0016]\n",
      "[-0.0018  0.      0.      0.    ]\n",
      "[0.0029 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[0.0007 0.     0.     0.0787]\n",
      "[0.0262 0.     0.     0.    ]\n",
      "[-0.0003  0.      0.     -0.0006]\n",
      "[3.6175e-05 0.0000e+00 0.0000e+00 2.8053e-04]\n",
      "[0.0162 0.     0.     0.    ]\n",
      "[ 0.0046  0.      0.     -0.0005]\n",
      "[-0.0004  0.      0.      0.    ]\n",
      "[7.6058e-05 0.0000e+00 0.0000e+00 8.1441e-03]\n",
      "[-0.0025  0.      0.      0.    ]\n",
      "[0.0004 0.     0.     0.    ]\n",
      "[ 0.0003  0.      0.     -0.0001]\n",
      "[-0.0007  0.      0.      0.005 ]\n",
      "[-0.0002  0.      0.      0.0246]\n",
      "[-0.0022  0.      0.      0.    ]\n",
      "[0.0793 0.     0.     0.    ]\n",
      "[-0.0002  0.      0.      0.023 ]\n",
      "[0.0679 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[0.0225 0.     0.     0.    ]\n",
      "[-0.0016  0.      0.      0.    ]\n",
      "[0.0811 0.     0.     0.    ]\n",
      "[0.0005 0.     0.     0.    ]\n",
      "[0.0266 0.     0.     0.    ]\n",
      "[0.0276 0.     0.     0.    ]\n",
      "[-0.0008  0.      0.      0.    ]\n",
      "[0.028 0.    0.    0.   ]\n",
      "[-0.0037  0.      0.      0.    ]\n",
      "[0.0778 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[0.0005 0.     0.     0.    ]\n",
      "[0.0758 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[0.0245 0.     0.     0.    ]\n",
      "[-5.3894e-05  0.0000e+00  0.0000e+00  0.0000e+00]\n",
      "[0.0711 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[-5.1368e-05  0.0000e+00  0.0000e+00  0.0000e+00]\n",
      "[ 0.0008  0.      0.     -0.0007]\n",
      "[-0.0001  0.      0.      0.    ]\n",
      "[0.0014 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[0.0251 0.     0.     0.    ]\n",
      "[0.0002 0.     0.     0.    ]\n",
      "[0.0745 0.     0.     0.    ]\n",
      "[-0.0004  0.      0.      0.0252]\n",
      "[0. 0. 0. 0.]\n",
      "[ 0.      0.      0.     -0.0014]\n",
      "[0.0011 0.     0.     0.    ]\n",
      "[0.0715 0.     0.     0.    ]\n",
      "[0.072 0.    0.    0.   ]\n",
      "[-0.0009  0.      0.      0.0707]\n",
      "[0.07 0.   0.   0.  ]\n",
      "[0. 0. 0. 0.]\n",
      "[0.0755 0.     0.     0.    ]\n",
      "[0.0234 0.     0.     0.    ]\n",
      "[-0.0022  0.      0.      0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[ 0.0004  0.      0.     -0.0002]\n",
      "[0.0255 0.     0.     0.    ]\n",
      "[0.0823 0.     0.     0.    ]\n",
      "[-0.0006  0.      0.      0.0002]\n",
      "[0.0001 0.     0.     0.0857]\n",
      "[-0.0003  0.      0.      0.    ]\n",
      "[0.0042 0.     0.     0.    ]\n",
      "[-0.0004  0.      0.      0.0051]\n",
      "[0.0819 0.     0.     0.    ]\n",
      "[0.0852 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0.0006 0.     0.     0.0769]\n",
      "[0.0256 0.     0.     0.    ]\n",
      "[-0.0005  0.      0.     -0.0008]\n",
      "[0.0833 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[0.0842 0.     0.     0.    ]\n",
      "[-0.0037  0.      0.      0.    ]\n",
      "[0.0005 0.     0.     0.0638]\n",
      "[0.0612 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0.0789 0.     0.     0.    ]\n",
      "[-0.0008  0.      0.      0.0058]\n",
      "[0.0007 0.     0.     0.0881]\n",
      "[0.027 0.    0.    0.   ]\n",
      "[-0.0011  0.      0.      0.    ]\n",
      "[0.0277 0.     0.     0.    ]\n",
      "[-0.0038  0.      0.      0.0007]\n",
      "[0.0786 0.     0.     0.    ]\n",
      "[-0.0008  0.      0.      0.0001]\n",
      "[0.0828 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[-0.0008  0.      0.      0.0002]\n",
      "[0. 0. 0. 0.]\n",
      "[-0.0008  0.      0.      0.0096]\n",
      "[-0.0002  0.      0.      0.0003]\n",
      "[0.     0.     0.     0.0003]\n",
      "[ 2.8055e-02  0.0000e+00  0.0000e+00 -1.6878e-05]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0.0001 0.     0.     0.    ]\n",
      "[0.0897 0.     0.     0.    ]\n",
      "[0.0807 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[-0.0029  0.      0.      0.    ]\n",
      "[0.0865 0.     0.     0.    ]\n",
      "[0.0055 0.     0.     0.0002]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[ 0.0011  0.      0.     -0.0004]\n",
      "[0.0009 0.     0.     0.0719]\n",
      "[-0.0006  0.      0.      0.0034]\n",
      "[0.0845 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[0.0698 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[ 0.0007  0.      0.     -0.0002]\n",
      "[-0.0018  0.      0.      0.0234]\n",
      "[0.0735 0.     0.     0.    ]\n",
      "[-0.0013  0.      0.      0.007 ]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0.0066 0.     0.     0.    ]\n",
      "[0.0008 0.     0.     0.    ]\n",
      "[0.0097 0.     0.     0.    ]\n",
      "[0.0076 0.     0.     0.    ]\n",
      "[-0.0037  0.      0.     -0.0006]\n",
      "[0.0757 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[-1.3819e-03  0.0000e+00  0.0000e+00  5.2691e-05]\n",
      "[-0.0001  0.      0.     -0.0009]\n",
      "[-0.002   0.      0.      0.0222]\n",
      "[9.6329e-05 0.0000e+00 0.0000e+00 0.0000e+00]\n",
      "[0. 0. 0. 0.]\n",
      "[0.0719 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0.0784 0.     0.     0.    ]\n",
      "[-0.0003  0.      0.     -0.0012]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[-0.0018  0.      0.      0.    ]\n",
      "[0.0707 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[0.0912 0.     0.     0.    ]\n",
      "[0.0009 0.     0.     0.    ]\n",
      "[0.0146 0.     0.     0.    ]\n",
      "[0.0007 0.     0.     0.0856]\n",
      "[0.0269 0.     0.     0.    ]\n",
      "[0.0008 0.     0.     0.0863]\n",
      "[0.0263 0.     0.     0.    ]\n",
      "[-0.0011  0.      0.      0.    ]\n",
      "[0.027 0.    0.    0.   ]\n",
      "[-0.0003  0.      0.      0.0122]\n",
      "[0.0002 0.     0.     0.    ]\n",
      "[0.0774 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[-0.0006  0.      0.      0.0266]\n",
      "[0.0691 0.     0.     0.    ]\n",
      "[0.0697 0.     0.     0.    ]\n",
      "[-0.0005  0.      0.      0.0225]\n",
      "[0.0649 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0.0774 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[0.0888 0.     0.     0.    ]\n",
      "[0.     0.     0.     0.0234]\n",
      "[-0.0005  0.      0.      0.0166]\n",
      "[0.0805 0.     0.     0.    ]\n",
      "[0.0006 0.     0.     0.    ]\n",
      "[0.0808 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0.0753 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[-0.0001  0.      0.      0.0002]\n",
      "[0.0786 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[0.0892 0.     0.     0.    ]\n",
      "[0.0006 0.     0.     0.    ]\n",
      "[0.0783 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0.0823 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0.0007 0.     0.     0.0095]\n",
      "[0.0007 0.     0.     0.    ]\n",
      "[0.0788 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0.0841 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[-0.0011  0.      0.      0.0003]\n",
      "[0.0852 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[ 0.03    0.      0.     -0.0028]\n",
      "[0.0046 0.     0.     0.    ]\n",
      "[0.0015 0.     0.     0.    ]\n",
      "[-0.0018  0.      0.      0.    ]\n",
      "[ 0.0081  0.      0.     -0.0012]\n",
      "[1.3645e-04 0.0000e+00 0.0000e+00 2.7232e-05]\n",
      "[0.0677 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[-0.0013  0.      0.     -0.0005]\n",
      "[0.071 0.    0.    0.   ]\n",
      "[0. 0. 0. 0.]\n",
      "[0.0004 0.     0.     0.0147]\n",
      "[0.0908 0.     0.     0.    ]\n",
      "[0.0911 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0.0007 0.     0.     0.0002]\n",
      "[0.0817 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[-0.0012  0.      0.      0.0844]\n",
      "[0.0828 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[0.0728 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[-3.6646e-05  0.0000e+00  0.0000e+00 -8.7805e-04]\n",
      "[0. 0. 0. 0.]\n",
      "[ 0.0259  0.      0.     -0.0026]\n",
      "[-0.003  0.     0.     0.   ]\n",
      "[0.0805 0.     0.     0.    ]\n",
      "[0.0793 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[-0.001  0.     0.     0.   ]\n",
      "[0.0732 0.     0.     0.    ]\n",
      "[0.0241 0.     0.     0.    ]\n",
      "[-0.0022  0.      0.      0.    ]\n",
      "[0.0738 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[0.0867 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[-0.0009  0.      0.      0.0185]\n",
      "[0. 0. 0. 0.]\n",
      "[0.0008 0.     0.     0.0285]\n",
      "[0.0823 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[0.0002 0.     0.     0.0862]\n",
      "[0. 0. 0. 0.]\n",
      "[0.0724 0.     0.     0.    ]\n",
      "[0.0693 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[-0.0012  0.      0.      0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[0.0017 0.     0.     0.0758]\n",
      "[0.0732 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[0.022 0.    0.    0.   ]\n",
      "[0.0292 0.     0.     0.    ]\n",
      "[0.0273 0.     0.     0.    ]\n",
      "[-0.0025  0.      0.      0.    ]\n",
      "[-0.0017  0.      0.      0.0002]\n",
      "[0.008  0.     0.     0.0004]\n",
      "[-0.0011  0.      0.      0.0002]\n",
      "[0.08 0.   0.   0.  ]\n",
      "[0.0821 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[-0.0011  0.      0.      0.    ]\n",
      "[0.0833 0.     0.     0.    ]\n",
      "[0.0879 0.     0.     0.    ]\n",
      "[0.0013 0.     0.     0.    ]\n",
      "[0.0639 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0.0736 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[0.0736 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0.0795 0.     0.     0.    ]\n",
      "[0.0752 0.     0.     0.    ]\n",
      "[0.0717 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[0.0869 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[0.0004 0.     0.     0.    ]\n",
      "[-0.0024  0.      0.      0.0769]\n",
      "[0.0757 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[0.0868 0.     0.     0.    ]\n",
      "[0.0001 0.     0.     0.    ]\n",
      "[0.0757 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[3.3211e-05 0.0000e+00 0.0000e+00 0.0000e+00]\n",
      "[0. 0. 0. 0.]\n",
      "[-0.0022  0.      0.      0.    ]\n",
      "[0.0741 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[0.0836 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[ 4.7751e-05  0.0000e+00  0.0000e+00 -2.1603e-03]\n",
      "[0.0894 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[-0.0013  0.      0.      0.    ]\n",
      "[0.0685 0.     0.     0.    ]\n",
      "[-0.0002  0.      0.      0.0105]\n",
      "[0.0004 0.     0.     0.0793]\n",
      "[0.0787 0.     0.     0.    ]\n",
      "[0.0008 0.     0.     0.0004]\n",
      "[0.0774 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[ 0.0245  0.      0.     -0.0013]\n",
      "[9.4198e-05 0.0000e+00 0.0000e+00 0.0000e+00]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[ 0.0016  0.      0.     -0.001 ]\n",
      "[ 5.7039e-04  0.0000e+00  0.0000e+00 -5.1792e-05]\n",
      "[-0.0003  0.      0.      0.0053]\n",
      "[0.0005 0.     0.     0.0266]\n",
      "[-0.0023  0.      0.      0.0042]\n",
      "[0.0009 0.     0.     0.0126]\n",
      "[ 0.0038  0.      0.     -0.0013]\n",
      "[0.0797 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[0.0751 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[-0.0004  0.      0.      0.017 ]\n",
      "[0.0804 0.     0.     0.    ]\n",
      "[0.0002 0.     0.     0.0009]\n",
      "[0.0109 0.     0.     0.    ]\n",
      "[-0.0002  0.      0.      0.    ]\n",
      "[0.0043 0.     0.     0.    ]\n",
      "[-0.0004  0.      0.      0.    ]\n",
      "[0.0053 0.     0.     0.    ]\n",
      "[-0.0004  0.      0.      0.    ]\n",
      "[0.0063 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[-0.0018  0.      0.     -0.0016]\n",
      "[0.0776 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[0.0289 0.     0.     0.    ]\n",
      "[-0.0014  0.      0.      0.    ]\n",
      "[0.0185 0.     0.     0.    ]\n",
      "[-0.0039  0.      0.      0.    ]\n",
      "[0.0822 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[-0.0036  0.      0.      0.0013]\n",
      "[0.0822 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[-0.0043  0.      0.      0.0153]\n",
      "[0.0794 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[-0.0005  0.      0.      0.    ]\n",
      "[0.0247 0.     0.     0.    ]\n",
      "[-0.0001  0.      0.      0.    ]\n",
      "[0.0695 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[0.0255 0.     0.     0.    ]\n",
      "[0.0019 0.     0.     0.    ]\n",
      "[0.0817 0.     0.     0.    ]\n",
      "[0.0803 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[-0.0009  0.      0.      0.    ]\n",
      "[0.0074 0.     0.     0.    ]\n",
      "[-0.0013  0.      0.      0.    ]\n",
      "[0.0092 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[-0.0028  0.      0.      0.    ]\n",
      "[0.0297 0.     0.     0.    ]\n",
      "[-0.0023  0.      0.      0.    ]\n",
      "[0.0881 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[-0.0011  0.      0.      0.    ]\n",
      "[0.0111 0.     0.     0.    ]\n",
      "[-0.0014  0.      0.     -0.0012]\n",
      "[0.0008 0.     0.     0.0912]\n",
      "[0.0292 0.     0.     0.    ]\n",
      "[0.     0.     0.     0.0747]\n",
      "[0.0013 0.     0.     0.0003]\n",
      "[0.0758 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[-0.001  0.     0.     0.   ]\n",
      "[0.077 0.    0.    0.   ]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[2.3349e-02 0.0000e+00 0.0000e+00 6.5925e-06]\n",
      "[0.001 0.    0.    0.   ]\n",
      "[0.0776 0.     0.     0.    ]\n",
      "[0.0002 0.     0.     0.0248]\n",
      "[0.0719 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[0.0004 0.     0.     0.    ]\n",
      "[0.0712 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0.0877 0.     0.     0.    ]\n",
      "[0.0722 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0.0001 0.     0.     0.0753]\n",
      "[0.0786 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[-0.0012  0.      0.      0.    ]\n",
      "[0.     0.     0.     0.0707]\n",
      "[-0.0025  0.      0.      0.    ]\n",
      "[2.3786e-03 0.0000e+00 0.0000e+00 1.3637e-05]\n",
      "[-0.0043  0.      0.      0.    ]\n",
      "[0.0716 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[0.     0.     0.     0.0062]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0.0877 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0.0759 0.     0.     0.    ]\n",
      "[0.018 0.    0.    0.   ]\n",
      "[ 0.      0.      0.     -0.0016]\n",
      "[-5.9251e-05  0.0000e+00  0.0000e+00  2.5505e-02]\n",
      "[0.     0.     0.     0.0251]\n",
      "[0.0701 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[-0.0032  0.      0.      0.    ]\n",
      "[0.0706 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[0.0801 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[-0.0042  0.      0.      0.    ]\n",
      "[0.0685 0.     0.     0.    ]\n",
      "[0.0057 0.     0.     0.    ]\n",
      "[0.0016 0.     0.     0.    ]\n",
      "[ 0.0127  0.      0.     -0.002 ]\n",
      "[0.0008 0.     0.     0.0015]\n",
      "[0.0418 0.     0.     0.    ]\n",
      "[0.0301 0.     0.     0.    ]\n",
      "[-0.0036  0.      0.      0.    ]\n",
      "[0.0884 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0.084 0.    0.    0.   ]\n",
      "[0.     0.     0.     0.0723]\n",
      "[0.0011 0.     0.     0.0005]\n",
      "[0.0735 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[-0.0038  0.      0.      0.008 ]\n",
      "[0.0761 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[ 2.1065e-04  0.0000e+00  0.0000e+00 -4.8115e-05]\n",
      "[0.0689 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[0.0144 0.     0.     0.    ]\n",
      "[-0.0003  0.      0.     -0.0013]\n",
      "[0.0682 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[0.0701 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0.075 0.    0.    0.   ]\n",
      "[0. 0. 0. 0.]\n",
      "[0.0716 0.     0.     0.    ]\n",
      "[0.0697 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[-0.003   0.      0.      0.0006]\n",
      "[0.0738 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[-0.0018  0.      0.      0.0143]\n",
      "[0.0756 0.     0.     0.    ]\n",
      "[-0.0013  0.      0.      0.0149]\n",
      "[0.0711 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[0.0656 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[-0.0027  0.      0.      0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[-0.001   0.      0.     -0.0014]\n",
      "[0. 0. 0. 0.]\n",
      "[0.011 0.    0.    0.   ]\n",
      "[-0.0009  0.      0.      0.    ]\n",
      "[0.0146 0.     0.     0.    ]\n",
      "[-0.0005  0.      0.      0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[-0.0039  0.      0.      0.    ]\n",
      "[0.0733 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[-0.0001  0.      0.      0.0011]\n",
      "[0.0701 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[0.0247 0.     0.     0.    ]\n",
      "[-0.0027  0.      0.      0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[0.0234 0.     0.     0.    ]\n",
      "[-0.0015  0.      0.      0.    ]\n",
      "[0.0654 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0.074 0.    0.    0.   ]\n",
      "[0. 0. 0. 0.]\n",
      "[0.0684 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[ 0.0007  0.      0.     -0.0027]\n",
      "[0.0671 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[0.0727 0.     0.     0.    ]\n",
      "[0.0775 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0.0738 0.     0.     0.    ]\n",
      "[0.0746 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0.0691 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[0.0905 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[0.0702 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[-0.0036  0.      0.      0.    ]\n",
      "[0.0707 0.     0.     0.    ]\n",
      "[0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "for x, y in tree.N.items():\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 801,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T00:54:57.110419Z",
     "start_time": "2018-11-25T00:54:48.879415Z"
    },
    "autopy": 1,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "game = emulator.Game(2)\n",
    "mapp = game.reset()\n",
    "s = map_to_state(mapp, None, 0)\n",
    "tree = MCTS()\n",
    "\n",
    "t = time.time()\n",
    "for i in range(1_000):\n",
    "    tree.search(s, mapp, game, alphabot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-24T19:23:49.082225Z",
     "start_time": "2018-11-24T19:23:49.058686Z"
    }
   },
   "outputs": [],
   "source": [
    "def map_to_state(gmap, gmap_old, turn):\n",
    "    if type(gmap_old) != np.ndarray:\n",
    "        gmap_old = np.full_like(gmap, -1)\n",
    "    \n",
    "    states = np.empty(INPUT_SIZE, dtype=np.int)\n",
    "    \n",
    "    states = process_map(gmap, gmap_old, turn)\n",
    "    return states\n",
    "\n",
    "def process_map(gmap, gmap_old, idx):\n",
    "    pov_0 = np.zeros((*INPUT_SIZE[:2], 1), dtype=np.int)\n",
    "    pov_0_last = np.zeros((*INPUT_SIZE[:2], 1), dtype=np.int)\n",
    "    pov_1 = np.zeros((*INPUT_SIZE[:2], 1), dtype=np.int)\n",
    "    pov_1_last = np.zeros((*INPUT_SIZE[:2], 1), dtype=np.int)\n",
    "    \n",
    "    pov_0[np.where(gmap == 0)] = 1 # Set to 1 where player 0 is\n",
    "    pov_0_last[np.where(gmap_old == 0)] = 1\n",
    "    \n",
    "    pov_1[np.where(gmap == 1)] = 1 # Set to  1 where player 1 is\n",
    "    pov_1_last[np.where(gmap_old == 1)] = 1\n",
    "    \n",
    "    pov_0_last = pov_0 - pov_0_last\n",
    "    pov_1_last = pov_1 - pov_1_last\n",
    "\n",
    "    turn_m = np.full((*INPUT_SIZE[:2], 1), dtype=np.int, fill_value=idx)\n",
    "    \n",
    "    return np.concatenate([pov_0, pov_0_last, pov_1, pov_1_last, turn_m], axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-24T15:42:10.370761Z",
     "start_time": "2018-11-24T15:42:10.352769Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
